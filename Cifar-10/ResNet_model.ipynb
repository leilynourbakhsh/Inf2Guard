{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import shutil\n",
    "import time\n",
    "import random\n",
    "import copy\n",
    "\n",
    "\n",
    "import torch\n",
    "from sklearn.metrics import precision_score,recall_score\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torchvision.transforms import ToTensor, Normalize, Compose\n",
    "\n",
    "import torchmetrics\n",
    "\n",
    "#from torchinfo import summary\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader, sampler\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.nn.init as init\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.utils.data import random_split\n",
    "from torch.utils.data import TensorDataset, random_split\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import shutil\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torchvision import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.anomaly_mode.set_detect_anomaly at 0x1ee7b866f28>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "torch.autograd.set_detect_anomaly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super(CustomBlock, self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels)\n",
    "        )\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        out = self.layers(x)\n",
    "        out += self.shortcut(identity)\n",
    "        out = nn.ReLU(inplace=True)(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureExtractor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FeatureExtractor, self).__init__()\n",
    "        resnet18 = models.resnet18(pretrained=True)\n",
    "        resnet18.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "\n",
    "        self.layers = nn.Sequential(\n",
    "            resnet18.conv1,\n",
    "            resnet18.bn1,\n",
    "            resnet18.relu,\n",
    "            resnet18.maxpool,\n",
    "            resnet18.layer1[0],\n",
    "            resnet18.layer1[1],\n",
    "            #CustomBlock(64, 64),  # Added custom block to layer1\n",
    "            resnet18.layer2[0],\n",
    "            resnet18.layer2[1],\n",
    "            resnet18.layer3[0],\n",
    "            resnet18.layer3[1],\n",
    "            resnet18.layer4[0],\n",
    "            \n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 6559168\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the model\n",
    "model =  FeatureExtractor()\n",
    "\n",
    "# Count the number of parameters\n",
    "num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"Number of parameters: {num_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers.0.weight - 1728\n",
      "layers.1.weight - 64\n",
      "layers.1.bias - 64\n",
      "layers.4.conv1.weight - 36864\n",
      "layers.4.bn1.weight - 64\n",
      "layers.4.bn1.bias - 64\n",
      "layers.4.conv2.weight - 36864\n",
      "layers.4.bn2.weight - 64\n",
      "layers.4.bn2.bias - 64\n",
      "layers.5.conv1.weight - 36864\n",
      "layers.5.bn1.weight - 64\n",
      "layers.5.bn1.bias - 64\n",
      "layers.5.conv2.weight - 36864\n",
      "layers.5.bn2.weight - 64\n",
      "layers.5.bn2.bias - 64\n",
      "layers.6.layers.0.weight - 36864\n",
      "layers.6.layers.1.weight - 64\n",
      "layers.6.layers.1.bias - 64\n",
      "layers.6.layers.3.weight - 36864\n",
      "layers.6.layers.4.weight - 64\n",
      "layers.6.layers.4.bias - 64\n",
      "layers.6.layers.6.weight - 36864\n",
      "layers.6.layers.7.weight - 64\n",
      "layers.6.layers.7.bias - 64\n",
      "layers.7.conv1.weight - 73728\n",
      "layers.7.bn1.weight - 128\n",
      "layers.7.bn1.bias - 128\n",
      "layers.7.conv2.weight - 147456\n",
      "layers.7.bn2.weight - 128\n",
      "layers.7.bn2.bias - 128\n",
      "layers.7.downsample.0.weight - 8192\n",
      "layers.7.downsample.1.weight - 128\n",
      "layers.7.downsample.1.bias - 128\n",
      "layers.8.conv1.weight - 147456\n",
      "layers.8.bn1.weight - 128\n",
      "layers.8.bn1.bias - 128\n",
      "layers.8.conv2.weight - 147456\n",
      "layers.8.bn2.weight - 128\n",
      "layers.8.bn2.bias - 128\n",
      "layers.9.conv1.weight - 294912\n",
      "layers.9.bn1.weight - 256\n",
      "layers.9.bn1.bias - 256\n",
      "layers.9.conv2.weight - 589824\n",
      "layers.9.bn2.weight - 256\n",
      "layers.9.bn2.bias - 256\n",
      "layers.9.downsample.0.weight - 32768\n",
      "layers.9.downsample.1.weight - 256\n",
      "layers.9.downsample.1.bias - 256\n",
      "layers.10.conv1.weight - 589824\n",
      "layers.10.bn1.weight - 256\n",
      "layers.10.bn1.bias - 256\n",
      "layers.10.conv2.weight - 589824\n",
      "layers.10.bn2.weight - 256\n",
      "layers.10.bn2.bias - 256\n",
      "layers.11.conv1.weight - 1179648\n",
      "layers.11.bn1.weight - 512\n",
      "layers.11.bn1.bias - 512\n",
      "layers.11.conv2.weight - 2359296\n",
      "layers.11.bn2.weight - 512\n",
      "layers.11.bn2.bias - 512\n",
      "layers.11.downsample.0.weight - 131072\n",
      "layers.11.downsample.1.weight - 512\n",
      "layers.11.downsample.1.bias - 512\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the model\n",
    "model = FeatureExtractor()\n",
    "\n",
    "# Count the number of parameters\n",
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(f\"{name} - {param.numel()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Predictor(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(Predictor, self).__init__()\n",
    "        resnet18 = models.resnet18(pretrained=True)\n",
    "        self.layers = nn.Sequential(\n",
    "            resnet18.layer4[1],\n",
    "            resnet18.avgpool,\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(resnet18.fc.in_features, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 4725770\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the model\n",
    "model =  Predictor()\n",
    "\n",
    "# Count the number of parameters\n",
    "num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"Number of parameters: {num_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers.0.conv1.weight - 2359296\n",
      "layers.0.bn1.weight - 512\n",
      "layers.0.bn1.bias - 512\n",
      "layers.0.conv2.weight - 2359296\n",
      "layers.0.bn2.weight - 512\n",
      "layers.0.bn2.bias - 512\n",
      "layers.3.weight - 5120\n",
      "layers.3.bias - 10\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the model\n",
    "model = Predictor()\n",
    "\n",
    "# Count the number of parameters\n",
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(f\"{name} - {param.numel()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attacker(nn.Module):\n",
    "    def __init__(self, num_classes=1):\n",
    "        super(Attacker, self).__init__()\n",
    "        resnet18 = models.resnet18(pretrained=True)\n",
    "        self.layers = nn.Sequential(\n",
    "            resnet18.layer4[1],\n",
    "            resnet18.avgpool,\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(resnet18.fc.in_features, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layers(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 4721153\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the model\n",
    "model =  Attacker()\n",
    "\n",
    "# Count the number of parameters\n",
    "num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"Number of parameters: {num_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers.0.conv1.weight - 2359296\n",
      "layers.0.bn1.weight - 512\n",
      "layers.0.bn1.bias - 512\n",
      "layers.0.conv2.weight - 2359296\n",
      "layers.0.bn2.weight - 512\n",
      "layers.0.bn2.bias - 512\n",
      "layers.3.weight - 512\n",
      "layers.3.bias - 1\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the model\n",
    "model = Attacker()\n",
    "\n",
    "# Count the number of parameters\n",
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(f\"{name} - {param.numel()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomTensorDataset(Dataset):\n",
    "    def __init__(self, tensors, transform=None):\n",
    "        assert all(tensors[0].shape[0] == tensor.shape[0] for tensor in tensors)\n",
    "        self.tensors = tensors\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        X = self.tensors[0][index]\n",
    "        if self.transform is not None:\n",
    "            X = self.transform(X)\n",
    "        return X, tuple(self.tensors[i][index] for i in range(1, len(self.tensors)))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.tensors[0].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000\n"
     ]
    }
   ],
   "source": [
    "tfms = Compose([\n",
    "    ToTensor(),\n",
    "    Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "batch_size = 100\n",
    "\n",
    "\n",
    "#50k clf_trainds\n",
    "clf_trainds = CIFAR10(root='PyTorch-StudioGAN/data/', transform=tfms)\n",
    "print(len(clf_trainds))\n",
    "#clf_train_idx = 25k\n",
    "#clf_test_idx = 25k\n",
    "clf_train_idx, clf_test_idx = train_test_split(\n",
    "    np.arange(len(clf_trainds.targets)), test_size=0.5, shuffle=True, stratify=clf_trainds.targets\n",
    ")\n",
    "train_sampler = sampler.SubsetRandomSampler(clf_train_idx)\n",
    "test_sampler = sampler.SubsetRandomSampler(clf_test_idx)\n",
    "\n",
    "#creating clf_train and clf_test dataloader\n",
    "clf_train_dl = DataLoader(clf_trainds, batch_size=batch_size, sampler=train_sampler)\n",
    "clf_test_dl = DataLoader(clf_trainds, batch_size=batch_size, sampler=test_sampler)\n",
    "\n",
    "#creating attacker dataset\n",
    "y_true_atk = [t for t in clf_trainds.targets]\n",
    "#25k 0 and 25k 1\n",
    "y_atk = np.zeros(len(clf_trainds), dtype=int)\n",
    "y_atk[clf_train_idx.tolist()] = 1\n",
    "\n",
    "atk_trainds = CustomTensorDataset(\n",
    "    tensors=(clf_trainds.data,torch.tensor(y_true_atk), torch.tensor(y_atk)),\n",
    "    transform=tfms\n",
    ")\n",
    "atk_train_idx, atk_test_idx = train_test_split(\n",
    "    np.arange(len(atk_trainds.tensors[2].tolist())), test_size=0.2, shuffle=True, stratify=atk_trainds.tensors[2].tolist()\n",
    ")\n",
    "atk_train_sampler = sampler.SubsetRandomSampler(atk_train_idx)\n",
    "atk_test_sampler = sampler.SubsetRandomSampler(atk_test_idx)\n",
    "\n",
    "atk_train_dl = DataLoader(atk_trainds, batch_size=batch_size, sampler=atk_train_sampler)\n",
    "atk_test_dl = DataLoader(atk_trainds, batch_size=batch_size, sampler=atk_test_sampler)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def adjust_learning_rate(epoch, init_lr=0.001):\n",
    "    schedule = [12]\n",
    "    cur_lr = init_lr\n",
    "    for schedule_epoch in schedule:\n",
    "        if epoch >= schedule_epoch:\n",
    "            cur_lr *= 0.1\n",
    "    return cur_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pretraining FE+CF\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "train_loss = []\n",
    "test_loss = []\n",
    "test_acc = []\n",
    "\n",
    "def train_FE_CF2(FE, CF, data_train_loader, current_lr, vis=None):\n",
    "    FE.train()\n",
    "    CF.train()\n",
    "    FE_optimizer = optim.Adam(FE.parameters(), lr=current_lr, weight_decay=1e-4)\n",
    "    CF_optimizer = optim.Adam(CF.parameters(), lr=current_lr, weight_decay=1e-4)\n",
    "\n",
    "    loss_CF = 0\n",
    "    for i, (images, labels) in enumerate(data_train_loader):\n",
    "        if torch.cuda.is_available():\n",
    "            images, labels = images.cuda(), labels.cuda()\n",
    "\n",
    "        features = FE(images)\n",
    "        # feed only private images to the classifier\n",
    "        output_CF = CF(features)\n",
    "        loss_CF = criterion(output_CF, labels)\n",
    "        \n",
    "\n",
    "        FE_optimizer.zero_grad()\n",
    "        CF_optimizer.zero_grad()\n",
    "        loss_CF.backward()\n",
    "        CF_optimizer.step()\n",
    "        FE_optimizer.step()\n",
    "        if i % 100 == 0:\n",
    "            print('Epoch: {} [{}/{} ({:.0f}%)]\\tLoss Classifier: {:.6f}\\t'.format(\n",
    "                i, i * len(images), len(data_train_loader.dataset),\n",
    "                100. * i / len(data_train_loader), loss_CF.item()))\n",
    "\n",
    "    return FE, CF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_FE_CF2(FE, CF, data_test_loader):\n",
    "    FE.eval()\n",
    "    CF.eval()\n",
    "\n",
    "    avg_loss = 0\n",
    "    avg_acc = 0\n",
    "    counter = 0\n",
    "    #size= len(data_test_loader)//2\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (images, labels) in enumerate(data_test_loader):\n",
    "            if torch.cuda.is_available():\n",
    "                images, labels = images.cuda(), labels.cuda()\n",
    "            features = FE(images)\n",
    "            #classfier_features= features[privlabe==1]\n",
    "            output = CF(features)\n",
    "            avg_loss += criterion(output, labels).sum()\n",
    "            pred = output.detach().max(1)[1]\n",
    "            avg_acc += pred.eq(labels.view_as(pred)).sum()\n",
    "            counter += 1\n",
    "\n",
    "    avg_loss /= counter\n",
    "    avg_loss = avg_loss.detach().cpu().item()\n",
    "    avg_acc = float(avg_acc) / len(data_test_loader)\n",
    "    print('Test Avg. Loss: %f, Accuracy: %f' % (avg_loss, avg_acc))\n",
    "    test_loss.append(avg_loss)\n",
    "    test_acc.append(avg_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_atk_loss=[]  # list to store loss values\n",
    "def eval_clf(fe, clf, clf_test_dl, clf_criterion, device):\n",
    "    fe.eval()\n",
    "    clf.eval()\n",
    "    acc = torchmetrics.Accuracy().to(device)\n",
    "    loss = []\n",
    "    with torch.no_grad():\n",
    "        for (X, y) in clf_test_dl:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            features = fe(X)\n",
    "            clf_y = clf(features)\n",
    "            loss.append(clf_criterion(clf_y, y).item())\n",
    "            test_atk_loss.append(loss)  # add loss to list\n",
    "            acc(clf_y, y)\n",
    "    loss = np.asarray(loss).mean()\n",
    "    print(f'Classifier Loss: {loss} | Classifier Accuracy: {acc.compute()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a directory to save models\n",
    "save_dir = os.path.join(os.getcwd(), 'resnet')\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# define the file name for each model\n",
    "fe_model_file = os.path.join(save_dir, 'FE.pth')\n",
    "cf_model_file = os.path.join(save_dir, 'CF.pth')\n",
    "inf_model_file=os.path.join(save_dir,'INF.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_epoch=300\n",
    "lr=0.001\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "clf_criterion = nn.CrossEntropyLoss().to(device)\n",
    "def get_FE_CF():\n",
    "    FE = FeatureExtractor()\n",
    "    CF = Predictor()\n",
    "    if torch.cuda.is_available():\n",
    "        if torch.cuda.device_count() > 1:\n",
    "            FE = torch.nn.DataParallel(FE)\n",
    "            CF = torch.nn.DataParallel(CF)\n",
    "        FE = FE.cuda()\n",
    "        CF = CF.cuda()\n",
    "    try:\n",
    "        for epoch in range(total_epoch):\n",
    "            print(\"epoch %d\" % epoch)\n",
    "            current_lr = adjust_learning_rate(epoch, lr)\n",
    "            FE, CF = train_FE_CF2(FE, CF, clf_train_dl, current_lr, vis=None)\n",
    "            #test_FE_CF2(FE, CF, clf_test_dl)\n",
    "            eval_clf(FE,CF,clf_test_dl,clf_criterion,device)\n",
    "    except KeyboardInterrupt:\n",
    "        pass\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        torch.save(FE.module, \"Models/mix/pre_train/FE.pth\")\n",
    "        torch.save(CF.module, \"Models/mix/pre_train/CF.pth\")\n",
    "    else:\n",
    "        torch.save(FE, fe_model_file)\n",
    "        torch.save(CF, cf_model_file)\n",
    "\n",
    "    return FE, CF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 2.814837\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 1.375778\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.989575\t\n",
      "Classifier Loss: 1.1336134631633759 | Classifier Accuracy: 0.6074000000953674\n",
      "epoch 1\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 1.046663\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.710478\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.888275\t\n",
      "Classifier Loss: 1.024956937789917 | Classifier Accuracy: 0.65447998046875\n",
      "epoch 2\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.498657\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.579172\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.805810\t\n",
      "Classifier Loss: 0.8832351121902465 | Classifier Accuracy: 0.703719973564148\n",
      "epoch 3\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.485019\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.534567\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.719772\t\n",
      "Classifier Loss: 0.9378385593891144 | Classifier Accuracy: 0.6999199986457825\n",
      "epoch 4\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.413641\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.416111\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.417750\t\n",
      "Classifier Loss: 0.7478742601871491 | Classifier Accuracy: 0.7656800150871277\n",
      "epoch 5\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.232477\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.276788\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.199162\t\n",
      "Classifier Loss: 0.7204880510568619 | Classifier Accuracy: 0.7776399850845337\n",
      "epoch 6\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.140425\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.297900\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.228033\t\n",
      "Classifier Loss: 0.784055964231491 | Classifier Accuracy: 0.7724800109863281\n",
      "epoch 7\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.123892\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.180506\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.144668\t\n",
      "Classifier Loss: 0.8718674429655076 | Classifier Accuracy: 0.7612400054931641\n",
      "epoch 8\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.111039\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.281074\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.239357\t\n",
      "Classifier Loss: 0.84877503490448 | Classifier Accuracy: 0.7719200253486633\n",
      "epoch 9\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.054692\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.283742\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.161346\t\n",
      "Classifier Loss: 0.9023030698299408 | Classifier Accuracy: 0.77156001329422\n",
      "epoch 10\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.087575\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.103937\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.076225\t\n",
      "Classifier Loss: 0.9134541597366334 | Classifier Accuracy: 0.7683200240135193\n",
      "epoch 11\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.064321\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.056314\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.117190\t\n",
      "Classifier Loss: 0.950655428647995 | Classifier Accuracy: 0.7633200287818909\n",
      "epoch 12\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.106565\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.050478\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.012373\t\n",
      "Classifier Loss: 0.8151449893712998 | Classifier Accuracy: 0.8037599921226501\n",
      "epoch 13\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.002714\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.022434\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.029892\t\n",
      "Classifier Loss: 0.9176606024503708 | Classifier Accuracy: 0.8053600192070007\n",
      "epoch 14\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.002143\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.001508\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.001734\t\n",
      "Classifier Loss: 0.9940237885713578 | Classifier Accuracy: 0.802079975605011\n",
      "epoch 15\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000742\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.005724\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.000463\t\n",
      "Classifier Loss: 1.0386178940534592 | Classifier Accuracy: 0.8036800026893616\n",
      "epoch 16\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000287\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.000464\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.000268\t\n",
      "Classifier Loss: 1.0892242203950881 | Classifier Accuracy: 0.8022800087928772\n",
      "epoch 17\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000467\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.000337\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.000256\t\n",
      "Classifier Loss: 1.0786064109802247 | Classifier Accuracy: 0.8021199703216553\n",
      "epoch 18\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.002029\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.007140\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.000415\t\n",
      "Classifier Loss: 1.078926124572754 | Classifier Accuracy: 0.8078799843788147\n",
      "epoch 19\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000389\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.000312\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.012711\t\n",
      "Classifier Loss: 1.0968849165439605 | Classifier Accuracy: 0.8042799830436707\n",
      "epoch 20\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000299\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.000385\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.000453\t\n",
      "Classifier Loss: 1.1148318001031876 | Classifier Accuracy: 0.8027600049972534\n",
      "epoch 21\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.012028\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.000789\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.001151\t\n",
      "Classifier Loss: 1.0749758573770523 | Classifier Accuracy: 0.805840015411377\n",
      "epoch 22\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000430\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.001490\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.000243\t\n",
      "Classifier Loss: 1.0884578598737717 | Classifier Accuracy: 0.8059200048446655\n",
      "epoch 23\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000368\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.001720\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.001404\t\n",
      "Classifier Loss: 1.1024758820533753 | Classifier Accuracy: 0.8019599914550781\n",
      "epoch 24\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000190\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.003002\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.000215\t\n",
      "Classifier Loss: 1.1069238569736481 | Classifier Accuracy: 0.7998800277709961\n",
      "epoch 25\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000350\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.000281\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.020428\t\n",
      "Classifier Loss: 1.1027607259750367 | Classifier Accuracy: 0.7975999712944031\n",
      "epoch 26\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.002065\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.000360\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.000703\t\n",
      "Classifier Loss: 1.090038878440857 | Classifier Accuracy: 0.802839994430542\n",
      "epoch 27\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000270\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.000441\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.000191\t\n",
      "Classifier Loss: 1.102710900068283 | Classifier Accuracy: 0.7983999848365784\n",
      "epoch 28\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000269\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.000342\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.005082\t\n",
      "Classifier Loss: 1.1228716492652893 | Classifier Accuracy: 0.7965599894523621\n",
      "epoch 29\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000329\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.000404\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.002477\t\n",
      "Classifier Loss: 1.086760316848755 | Classifier Accuracy: 0.8018800020217896\n",
      "epoch 30\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000277\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.004767\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.000355\t\n",
      "Classifier Loss: 1.1252138060331345 | Classifier Accuracy: 0.7997999787330627\n",
      "epoch 31\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000758\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.000406\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.000786\t\n",
      "Classifier Loss: 1.1197535514831543 | Classifier Accuracy: 0.7986400127410889\n",
      "epoch 32\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000556\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.001785\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.000351\t\n",
      "Classifier Loss: 1.1091200227737428 | Classifier Accuracy: 0.799239993095398\n",
      "epoch 33\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000187\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.000414\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.000445\t\n",
      "Classifier Loss: 1.121142489671707 | Classifier Accuracy: 0.7960799932479858\n",
      "epoch 34\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000435\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.000462\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.000827\t\n",
      "Classifier Loss: 1.075621915102005 | Classifier Accuracy: 0.800000011920929\n",
      "epoch 35\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000470\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.000260\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.000403\t\n",
      "Classifier Loss: 1.1177831654548644 | Classifier Accuracy: 0.7978399991989136\n",
      "epoch 36\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000307\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.000488\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.000415\t\n",
      "Classifier Loss: 1.1099219135046006 | Classifier Accuracy: 0.7965999841690063\n",
      "epoch 37\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000551\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.002098\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.000726\t\n",
      "Classifier Loss: 1.1103432794809343 | Classifier Accuracy: 0.7964000105857849\n",
      "epoch 38\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.001065\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.000600\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.000611\t\n",
      "Classifier Loss: 1.0872028414011001 | Classifier Accuracy: 0.8001599907875061\n",
      "epoch 39\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000285\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.000431\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.003229\t\n",
      "Classifier Loss: 1.1126671056747437 | Classifier Accuracy: 0.7984399795532227\n",
      "epoch 40\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.004158\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.006036\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.000527\t\n",
      "Classifier Loss: 1.1172308374643325 | Classifier Accuracy: 0.7977200150489807\n",
      "epoch 41\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.001663\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.000396\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.000285\t\n",
      "Classifier Loss: 1.1116491932868957 | Classifier Accuracy: 0.7968800067901611\n",
      "epoch 42\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.003014\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.000560\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.001182\t\n",
      "Classifier Loss: 1.0812751888036727 | Classifier Accuracy: 0.7972400188446045\n",
      "epoch 43\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000659\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.000228\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.002394\t\n",
      "Classifier Loss: 1.1099829716682434 | Classifier Accuracy: 0.7997599840164185\n",
      "epoch 44\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000234\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.003677\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.000260\t\n",
      "Classifier Loss: 1.1035847611427307 | Classifier Accuracy: 0.7991200089454651\n",
      "epoch 45\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000620\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.000356\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.000452\t\n",
      "Classifier Loss: 1.1195367925167083 | Classifier Accuracy: 0.7990000247955322\n",
      "epoch 46\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000272\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.000796\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.000499\t\n",
      "Classifier Loss: 1.1019418693780898 | Classifier Accuracy: 0.8039600253105164\n",
      "epoch 47\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000265\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.000295\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.032279\t\n",
      "Classifier Loss: 1.094700768828392 | Classifier Accuracy: 0.7965599894523621\n",
      "epoch 48\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000498\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.001475\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.000544\t\n",
      "Classifier Loss: 1.071511053442955 | Classifier Accuracy: 0.7976800203323364\n",
      "epoch 49\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000408\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.019880\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.000404\t\n",
      "Classifier Loss: 1.1182543969154357 | Classifier Accuracy: 0.7936000227928162\n",
      "epoch 50\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000974\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.001287\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.001049\t\n",
      "Classifier Loss: 1.1331873514652253 | Classifier Accuracy: 0.7958400249481201\n",
      "epoch 51\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.002863\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.001278\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.000594\t\n",
      "Classifier Loss: 1.1516076416969299 | Classifier Accuracy: 0.7896400094032288\n",
      "epoch 52\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000498\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.001936\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.001566\t\n",
      "Classifier Loss: 1.1367302412986755 | Classifier Accuracy: 0.791159987449646\n",
      "epoch 53\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000415\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.000915\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.001979\t\n",
      "Classifier Loss: 1.1390272594690323 | Classifier Accuracy: 0.7906399965286255\n",
      "epoch 54\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000622\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.000556\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.000338\t\n",
      "Classifier Loss: 1.1470589418411254 | Classifier Accuracy: 0.7942399978637695\n",
      "epoch 55\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000930\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.000458\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.000489\t\n",
      "Classifier Loss: 1.1401155631542206 | Classifier Accuracy: 0.7969200015068054\n",
      "epoch 56\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.001099\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.000676\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.000530\t\n",
      "Classifier Loss: 1.1557918957471847 | Classifier Accuracy: 0.7932400107383728\n",
      "epoch 57\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000634\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.002110\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.000579\t\n",
      "Classifier Loss: 1.1284547989368439 | Classifier Accuracy: 0.7968400120735168\n",
      "epoch 58\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000380\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.000540\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.002200\t\n",
      "Classifier Loss: 1.1333662981987 | Classifier Accuracy: 0.7911199927330017\n",
      "epoch 59\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000396\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.000482\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.001283\t\n",
      "Classifier Loss: 1.1265061910152436 | Classifier Accuracy: 0.7924000024795532\n",
      "epoch 60\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.015958\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.000824\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.015908\t\n",
      "Classifier Loss: 1.1445661152601243 | Classifier Accuracy: 0.7943199872970581\n",
      "epoch 61\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000476\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.000305\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.000739\t\n",
      "Classifier Loss: 1.2044276916980743 | Classifier Accuracy: 0.7936400175094604\n",
      "epoch 62\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.011347\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.000751\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.000191\t\n",
      "Classifier Loss: 1.141157939195633 | Classifier Accuracy: 0.7924000024795532\n",
      "epoch 63\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.011189\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.000461\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.000320\t\n",
      "Classifier Loss: 1.1442633306980132 | Classifier Accuracy: 0.7968400120735168\n",
      "epoch 64\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000266\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.000645\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.000524\t\n",
      "Classifier Loss: 1.1476449661254884 | Classifier Accuracy: 0.7922800183296204\n",
      "epoch 65\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000346\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.000654\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.001577\t\n",
      "Classifier Loss: 1.1293323714733123 | Classifier Accuracy: 0.7963600158691406\n",
      "epoch 66\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.001017\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.020215\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.000347\t\n",
      "Classifier Loss: 1.1047133939266205 | Classifier Accuracy: 0.7975199818611145\n",
      "epoch 67\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000842\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.000536\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.022062\t\n",
      "Classifier Loss: 1.1612804629802704 | Classifier Accuracy: 0.7879999876022339\n",
      "epoch 68\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.002103\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.002888\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.005747\t\n",
      "Classifier Loss: 1.1605924063920974 | Classifier Accuracy: 0.7924399971961975\n",
      "epoch 69\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.007185\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.000597\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.000435\t\n",
      "Classifier Loss: 1.1307503715753555 | Classifier Accuracy: 0.7946400046348572\n",
      "epoch 70\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000263\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.002714\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.000708\t\n",
      "Classifier Loss: 1.1713377737998962 | Classifier Accuracy: 0.7939599752426147\n",
      "epoch 71\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.002885\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.000274\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.000544\t\n",
      "Classifier Loss: 1.1478659026622773 | Classifier Accuracy: 0.7912799715995789\n",
      "epoch 72\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.005771\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.001247\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.000347\t\n",
      "Classifier Loss: 1.1424106913805008 | Classifier Accuracy: 0.7917199730873108\n",
      "epoch 73\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.002461\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.002322\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.000998\t\n",
      "Classifier Loss: 1.1499440299272536 | Classifier Accuracy: 0.7966399788856506\n",
      "epoch 74\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000565\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.000204\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.005821\t\n",
      "Classifier Loss: 1.117595564723015 | Classifier Accuracy: 0.787880003452301\n",
      "epoch 75\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.007516\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.000451\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.006243\t\n",
      "Classifier Loss: 1.120209674835205 | Classifier Accuracy: 0.7925199866294861\n",
      "epoch 76\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000504\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.000226\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.045203\t\n",
      "Classifier Loss: 1.153508939743042 | Classifier Accuracy: 0.7937600016593933\n",
      "epoch 77\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000396\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.000431\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.002111\t\n",
      "Classifier Loss: 1.1502713534832 | Classifier Accuracy: 0.7915599942207336\n",
      "epoch 78\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.004120\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.001241\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.000818\t\n",
      "Classifier Loss: 1.2245280320644378 | Classifier Accuracy: 0.7850800156593323\n",
      "epoch 79\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.001292\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.025657\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.000362\t\n",
      "Classifier Loss: 1.18417769664526 | Classifier Accuracy: 0.7863600254058838\n",
      "epoch 80\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.001048\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.001863\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.002557\t\n",
      "Classifier Loss: 1.1486920201778412 | Classifier Accuracy: 0.7922400236129761\n",
      "epoch 81\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.003713\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.000344\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.000380\t\n",
      "Classifier Loss: 1.1423054518699647 | Classifier Accuracy: 0.7924000024795532\n",
      "epoch 82\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000623\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.000795\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.003581\t\n",
      "Classifier Loss: 1.1434320088624954 | Classifier Accuracy: 0.7937999963760376\n",
      "epoch 83\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000740\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.000675\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.000619\t\n",
      "Classifier Loss: 1.1541819260120392 | Classifier Accuracy: 0.7948799729347229\n",
      "epoch 84\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000260\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.000319\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.000527\t\n",
      "Classifier Loss: 1.1415753467082976 | Classifier Accuracy: 0.7972400188446045\n",
      "epoch 85\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.006939\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.000241\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.005638\t\n",
      "Classifier Loss: 1.1741775226593019 | Classifier Accuracy: 0.7909600138664246\n",
      "epoch 86\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000504\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.005007\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.012716\t\n",
      "Classifier Loss: 1.1031146128177642 | Classifier Accuracy: 0.7925999760627747\n",
      "epoch 87\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000826\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.000587\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.000447\t\n",
      "Classifier Loss: 1.1253515703678132 | Classifier Accuracy: 0.7947999835014343\n",
      "epoch 88\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000349\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.002070\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.002592\t\n",
      "Classifier Loss: 1.147092142701149 | Classifier Accuracy: 0.7942000031471252\n",
      "epoch 89\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000253\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.000739\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.014896\t\n",
      "Classifier Loss: 1.1528031642436982 | Classifier Accuracy: 0.7888799905776978\n",
      "epoch 90\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.001349\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.000337\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.000272\t\n",
      "Classifier Loss: 1.1972616344690323 | Classifier Accuracy: 0.7893199920654297\n",
      "epoch 91\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.023189\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.000335\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.002652\t\n",
      "Classifier Loss: 1.1878557879924774 | Classifier Accuracy: 0.7925199866294861\n",
      "epoch 92\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000845\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.001421\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.000779\t\n",
      "Classifier Loss: 1.1244585208892823 | Classifier Accuracy: 0.7947199940681458\n",
      "epoch 93\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.001231\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.000693\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.000328\t\n",
      "Classifier Loss: 1.1771962058544159 | Classifier Accuracy: 0.7918000221252441\n",
      "epoch 94\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.001202\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.000631\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.031950\t\n",
      "Classifier Loss: 1.169340162873268 | Classifier Accuracy: 0.7916399836540222\n",
      "epoch 95\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000569\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.001027\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.000476\t\n",
      "Classifier Loss: 1.1453058695793152 | Classifier Accuracy: 0.792680025100708\n",
      "epoch 96\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000614\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.000414\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.000768\t\n",
      "Classifier Loss: 1.1611613073348999 | Classifier Accuracy: 0.7894799709320068\n",
      "epoch 97\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.001163\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.000433\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.001437\t\n",
      "Classifier Loss: 1.1620062959194184 | Classifier Accuracy: 0.7889999747276306\n",
      "epoch 98\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.001042\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.000549\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.000825\t\n",
      "Classifier Loss: 1.1764884321689606 | Classifier Accuracy: 0.7920399904251099\n",
      "epoch 99\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.005767\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.000800\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.000372\t\n",
      "Classifier Loss: 1.1903995275497437 | Classifier Accuracy: 0.7905200123786926\n",
      "epoch 100\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.004519\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.000354\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.000840\t\n",
      "Classifier Loss: 1.159143586874008 | Classifier Accuracy: 0.7912399768829346\n",
      "epoch 101\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000485\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.005529\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.001782\t\n",
      "Classifier Loss: 1.243417363166809 | Classifier Accuracy: 0.7852399945259094\n",
      "epoch 102\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.007440\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.000709\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.000580\t\n",
      "Classifier Loss: 1.1895252735614776 | Classifier Accuracy: 0.7912799715995789\n",
      "epoch 103\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000273\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.000752\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.060142\t\n",
      "Classifier Loss: 1.1821909635066985 | Classifier Accuracy: 0.789359986782074\n",
      "epoch 104\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000623\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.024571\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.013935\t\n",
      "Classifier Loss: 1.1232563171386718 | Classifier Accuracy: 0.7940400242805481\n",
      "epoch 105\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.001223\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.000535\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.000467\t\n",
      "Classifier Loss: 1.1603661732673645 | Classifier Accuracy: 0.7947199940681458\n",
      "epoch 106\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000834\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.000391\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.001821\t\n",
      "Classifier Loss: 1.1817816281318665 | Classifier Accuracy: 0.7909600138664246\n",
      "epoch 107\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.002348\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.003088\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.001814\t\n",
      "Classifier Loss: 1.1814530038833617 | Classifier Accuracy: 0.7920399904251099\n",
      "epoch 108\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000373\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.000592\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.000423\t\n",
      "Classifier Loss: 1.210747533082962 | Classifier Accuracy: 0.7854800224304199\n",
      "epoch 109\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000282\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.000526\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.000512\t\n",
      "Classifier Loss: 1.1918135346174241 | Classifier Accuracy: 0.7913600206375122\n",
      "epoch 110\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000454\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.000318\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.000901\t\n",
      "Classifier Loss: 1.153404928445816 | Classifier Accuracy: 0.7879999876022339\n",
      "epoch 111\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000496\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.002197\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.000455\t\n",
      "Classifier Loss: 1.2000776064395904 | Classifier Accuracy: 0.789080023765564\n",
      "epoch 112\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.010487\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.000568\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.012450\t\n",
      "Classifier Loss: 1.1927483642101289 | Classifier Accuracy: 0.7880799770355225\n",
      "epoch 113\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000690\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.008185\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.000401\t\n",
      "Classifier Loss: 1.1592741749286652 | Classifier Accuracy: 0.7875199913978577\n",
      "epoch 114\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000369\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.000407\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.002518\t\n",
      "Classifier Loss: 1.2246642217636108 | Classifier Accuracy: 0.7884799838066101\n",
      "epoch 115\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000737\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.038827\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.001915\t\n",
      "Classifier Loss: 1.247014776468277 | Classifier Accuracy: 0.7855600118637085\n",
      "epoch 116\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.010578\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.000528\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.000904\t\n",
      "Classifier Loss: 1.1715495040416717 | Classifier Accuracy: 0.7876399755477905\n",
      "epoch 117\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.001478\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.000363\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.000257\t\n",
      "Classifier Loss: 1.1952144819498063 | Classifier Accuracy: 0.7874000072479248\n",
      "epoch 118\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.003500\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.004574\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.000964\t\n",
      "Classifier Loss: 1.1573968260288239 | Classifier Accuracy: 0.7885199785232544\n",
      "epoch 119\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.002504\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.001260\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.002651\t\n",
      "Classifier Loss: 1.1649885940551759 | Classifier Accuracy: 0.7922800183296204\n",
      "epoch 120\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000582\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.000937\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.003135\t\n",
      "Classifier Loss: 1.177315775156021 | Classifier Accuracy: 0.7876399755477905\n",
      "epoch 121\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.001061\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.000366\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.000640\t\n",
      "Classifier Loss: 1.223613240480423 | Classifier Accuracy: 0.7871599793434143\n",
      "epoch 122\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.050059\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.016592\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.004613\t\n",
      "Classifier Loss: 1.1947930150032045 | Classifier Accuracy: 0.7849599719047546\n",
      "epoch 123\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.009143\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.047180\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.000421\t\n",
      "Classifier Loss: 1.1905116443634034 | Classifier Accuracy: 0.7884799838066101\n",
      "epoch 124\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000690\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.036819\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.002193\t\n",
      "Classifier Loss: 1.2071394197940826 | Classifier Accuracy: 0.7907599806785583\n",
      "epoch 125\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000377\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.000339\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.062498\t\n",
      "Classifier Loss: 1.244817037820816 | Classifier Accuracy: 0.7837600111961365\n",
      "epoch 126\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.001109\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.000331\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.000390\t\n",
      "Classifier Loss: 1.1999110517501832 | Classifier Accuracy: 0.78711998462677\n",
      "epoch 127\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000644\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.000587\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.000287\t\n",
      "Classifier Loss: 1.2012211236953736 | Classifier Accuracy: 0.788919985294342\n",
      "epoch 128\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000853\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.002754\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.020140\t\n",
      "Classifier Loss: 1.1809885621070861 | Classifier Accuracy: 0.7930399775505066\n",
      "epoch 129\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000461\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.001620\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.004334\t\n",
      "Classifier Loss: 1.2454741139411927 | Classifier Accuracy: 0.7837200164794922\n",
      "epoch 130\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.001244\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.000758\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.018630\t\n",
      "Classifier Loss: 1.2197437558174133 | Classifier Accuracy: 0.7866799831390381\n",
      "epoch 131\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000428\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.038710\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.000410\t\n",
      "Classifier Loss: 1.2075839802026749 | Classifier Accuracy: 0.789359986782074\n",
      "epoch 132\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000578\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.000366\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.000603\t\n",
      "Classifier Loss: 1.1867961013317108 | Classifier Accuracy: 0.7928799986839294\n",
      "epoch 133\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.007257\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.000532\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.004851\t\n",
      "Classifier Loss: 1.2421255233287811 | Classifier Accuracy: 0.7819600105285645\n",
      "epoch 134\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000494\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.000929\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.003024\t\n",
      "Classifier Loss: 1.185117158651352 | Classifier Accuracy: 0.7891600131988525\n",
      "epoch 135\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000668\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.027830\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.000425\t\n",
      "Classifier Loss: 1.1669251997470855 | Classifier Accuracy: 0.7888399958610535\n",
      "epoch 136\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000973\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.000485\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.001113\t\n",
      "Classifier Loss: 1.2040230207443237 | Classifier Accuracy: 0.7900800108909607\n",
      "epoch 137\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000337\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.000664\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.001054\t\n",
      "Classifier Loss: 1.234095355987549 | Classifier Accuracy: 0.7870399951934814\n",
      "epoch 138\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000676\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.000756\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.000358\t\n",
      "Classifier Loss: 1.2090164511203765 | Classifier Accuracy: 0.7906000018119812\n",
      "epoch 139\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.011826\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.000404\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.000676\t\n",
      "Classifier Loss: 1.2239176669120788 | Classifier Accuracy: 0.7876799702644348\n",
      "epoch 140\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000662\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.012786\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.000392\t\n",
      "Classifier Loss: 1.145925229907036 | Classifier Accuracy: 0.7912399768829346\n",
      "epoch 141\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.002780\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.000564\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.003275\t\n",
      "Classifier Loss: 1.1725853056907654 | Classifier Accuracy: 0.7915199995040894\n",
      "epoch 142\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000480\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.000560\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.001725\t\n",
      "Classifier Loss: 1.216095589160919 | Classifier Accuracy: 0.7848399877548218\n",
      "epoch 143\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000689\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.059625\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.000714\t\n",
      "Classifier Loss: 1.2185335927009582 | Classifier Accuracy: 0.7850800156593323\n",
      "epoch 144\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000503\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.000570\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.054631\t\n",
      "Classifier Loss: 1.1844399144649507 | Classifier Accuracy: 0.7881199717521667\n",
      "epoch 145\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000419\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.005295\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.001904\t\n",
      "Classifier Loss: 1.2078223583698273 | Classifier Accuracy: 0.7867199778556824\n",
      "epoch 146\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.004240\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.005172\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.000489\t\n",
      "Classifier Loss: 1.1723907153606414 | Classifier Accuracy: 0.7878400087356567\n",
      "epoch 147\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000326\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.000340\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.000281\t\n",
      "Classifier Loss: 1.2227279477119446 | Classifier Accuracy: 0.7843599915504456\n",
      "epoch 148\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.001395\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.010019\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.001005\t\n",
      "Classifier Loss: 1.2763932943344116 | Classifier Accuracy: 0.7839199900627136\n",
      "epoch 149\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000765\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.000462\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.001166\t\n",
      "Classifier Loss: 1.23249445271492 | Classifier Accuracy: 0.7855600118637085\n",
      "epoch 150\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000409\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.029075\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.000274\t\n",
      "Classifier Loss: 1.2308128328323364 | Classifier Accuracy: 0.7896400094032288\n",
      "epoch 151\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000345\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.001365\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.000483\t\n",
      "Classifier Loss: 1.2258282287120819 | Classifier Accuracy: 0.7889999747276306\n",
      "epoch 152\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000326\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.000731\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.018656\t\n",
      "Classifier Loss: 1.2364562494754792 | Classifier Accuracy: 0.7831599712371826\n",
      "epoch 153\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.002735\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.001358\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.000334\t\n",
      "Classifier Loss: 1.195266103029251 | Classifier Accuracy: 0.7869200110435486\n",
      "epoch 154\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000854\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.002958\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.000603\t\n",
      "Classifier Loss: 1.18804816198349 | Classifier Accuracy: 0.7945600152015686\n",
      "epoch 155\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000557\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.000691\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.000779\t\n",
      "Classifier Loss: 1.2107422024011611 | Classifier Accuracy: 0.7895200252532959\n",
      "epoch 156\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.001014\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.001519\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.035385\t\n",
      "Classifier Loss: 1.1767065019607543 | Classifier Accuracy: 0.7878000140190125\n",
      "epoch 157\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.007538\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.022295\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.002067\t\n",
      "Classifier Loss: 1.132644377708435 | Classifier Accuracy: 0.7899600267410278\n",
      "epoch 158\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.004554\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.000727\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.001781\t\n",
      "Classifier Loss: 1.2179139549732207 | Classifier Accuracy: 0.7886800169944763\n",
      "epoch 159\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000600\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.000361\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.041677\t\n",
      "Classifier Loss: 1.2265961244106294 | Classifier Accuracy: 0.7881199717521667\n",
      "epoch 160\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.003881\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.000771\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.003398\t\n",
      "Classifier Loss: 1.2049598956108094 | Classifier Accuracy: 0.7828400135040283\n",
      "epoch 161\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.002293\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.000909\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.001134\t\n",
      "Classifier Loss: 1.2277410604953767 | Classifier Accuracy: 0.7861199975013733\n",
      "epoch 162\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.001312\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.000439\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.000296\t\n",
      "Classifier Loss: 1.2142692377567292 | Classifier Accuracy: 0.7889599800109863\n",
      "epoch 163\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000420\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.000760\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.019251\t\n",
      "Classifier Loss: 1.1958688769340515 | Classifier Accuracy: 0.7869200110435486\n",
      "epoch 164\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.002256\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.000565\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.000530\t\n",
      "Classifier Loss: 1.1887696509361267 | Classifier Accuracy: 0.7909200191497803\n",
      "epoch 165\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.011373\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.000356\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.000809\t\n",
      "Classifier Loss: 1.2507330305576325 | Classifier Accuracy: 0.7864400148391724\n",
      "epoch 166\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000486\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.093348\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.002169\t\n",
      "Classifier Loss: 1.2162491917610168 | Classifier Accuracy: 0.7907199859619141\n",
      "epoch 167\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.001507\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.000328\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.000523\t\n",
      "Classifier Loss: 1.2014039034843444 | Classifier Accuracy: 0.7914800047874451\n",
      "epoch 168\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000590\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.001319\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.000990\t\n",
      "Classifier Loss: 1.2229522436857223 | Classifier Accuracy: 0.7825999855995178\n",
      "epoch 169\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000622\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.041426\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.000334\t\n",
      "Classifier Loss: 1.228350923061371 | Classifier Accuracy: 0.7899600267410278\n",
      "epoch 170\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.001226\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.000534\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.001215\t\n",
      "Classifier Loss: 1.2076784237623215 | Classifier Accuracy: 0.7927200198173523\n",
      "epoch 171\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000468\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.000528\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.000277\t\n",
      "Classifier Loss: 1.181263861656189 | Classifier Accuracy: 0.7847599983215332\n",
      "epoch 172\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.002328\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.000822\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.004968\t\n",
      "Classifier Loss: 1.1752106531858444 | Classifier Accuracy: 0.7905200123786926\n",
      "epoch 173\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.021659\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.001566\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.000834\t\n",
      "Classifier Loss: 1.2338487911224365 | Classifier Accuracy: 0.7842000126838684\n",
      "epoch 174\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000431\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.002262\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.005080\t\n",
      "Classifier Loss: 1.2045190653800963 | Classifier Accuracy: 0.7903199791908264\n",
      "epoch 175\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000379\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.000270\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.000771\t\n",
      "Classifier Loss: 1.2456518681049347 | Classifier Accuracy: 0.7887600064277649\n",
      "epoch 176\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.004226\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.001081\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.041036\t\n",
      "Classifier Loss: 1.2104111781120301 | Classifier Accuracy: 0.7873600125312805\n",
      "epoch 177\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.007901\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.001647\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.000967\t\n",
      "Classifier Loss: 1.1880529572963714 | Classifier Accuracy: 0.790120005607605\n",
      "epoch 178\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.005694\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.000335\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.000394\t\n",
      "Classifier Loss: 1.2153311834335327 | Classifier Accuracy: 0.7868000268936157\n",
      "epoch 179\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.023614\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.000778\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.002036\t\n",
      "Classifier Loss: 1.1931725387573242 | Classifier Accuracy: 0.7887200117111206\n",
      "epoch 180\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000634\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.000993\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.000542\t\n",
      "Classifier Loss: 1.2286322953701019 | Classifier Accuracy: 0.7858800292015076\n",
      "epoch 181\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000457\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.000566\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.000379\t\n",
      "Classifier Loss: 1.2163779532909393 | Classifier Accuracy: 0.7879199981689453\n",
      "epoch 182\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000305\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.000787\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.002456\t\n",
      "Classifier Loss: 1.2158923993110657 | Classifier Accuracy: 0.7870799899101257\n",
      "epoch 183\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.001718\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.000760\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.000899\t\n",
      "Classifier Loss: 1.1885199921131133 | Classifier Accuracy: 0.7906799912452698\n",
      "epoch 184\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000782\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.000595\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.000972\t\n",
      "Classifier Loss: 1.2102843338251115 | Classifier Accuracy: 0.7916799783706665\n",
      "epoch 185\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000250\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.004501\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.001535\t\n",
      "Classifier Loss: 1.2035869579315186 | Classifier Accuracy: 0.7888399958610535\n",
      "epoch 186\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.001339\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.000762\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.021165\t\n",
      "Classifier Loss: 1.217647274017334 | Classifier Accuracy: 0.7922800183296204\n",
      "epoch 187\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000289\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.000942\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.002291\t\n",
      "Classifier Loss: 1.2398289160728455 | Classifier Accuracy: 0.7825599908828735\n",
      "epoch 188\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.002482\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.000302\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.002086\t\n",
      "Classifier Loss: 1.226993747472763 | Classifier Accuracy: 0.7886800169944763\n",
      "epoch 189\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.003340\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.001889\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.007936\t\n",
      "Classifier Loss: 1.1620748372077943 | Classifier Accuracy: 0.790440022945404\n",
      "epoch 190\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.002457\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.000263\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.011612\t\n",
      "Classifier Loss: 1.2366453897953034 | Classifier Accuracy: 0.7851200103759766\n",
      "epoch 191\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.001401\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.001253\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.018114\t\n",
      "Classifier Loss: 1.2351435978412628 | Classifier Accuracy: 0.7847200036048889\n",
      "epoch 192\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.001465\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.000425\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.006192\t\n",
      "Classifier Loss: 1.2060798597335816 | Classifier Accuracy: 0.7857999801635742\n",
      "epoch 193\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000477\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.003573\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.000504\t\n",
      "Classifier Loss: 1.2344027268886566 | Classifier Accuracy: 0.7907599806785583\n",
      "epoch 194\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000400\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.005479\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.000436\t\n",
      "Classifier Loss: 1.225275183916092 | Classifier Accuracy: 0.7859200239181519\n",
      "epoch 195\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.015171\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.005682\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.000780\t\n",
      "Classifier Loss: 1.2569331645965576 | Classifier Accuracy: 0.7879199981689453\n",
      "epoch 196\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000485\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.000489\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.000610\t\n",
      "Classifier Loss: 1.2164849758148193 | Classifier Accuracy: 0.7872400283813477\n",
      "epoch 197\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.001529\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.001470\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.001135\t\n",
      "Classifier Loss: 1.2072028670310975 | Classifier Accuracy: 0.7876799702644348\n",
      "epoch 198\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.002777\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.017249\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.000475\t\n",
      "Classifier Loss: 1.1903829674720765 | Classifier Accuracy: 0.7904000282287598\n",
      "epoch 199\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000787\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.002456\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.000512\t\n",
      "Classifier Loss: 1.2008063373565674 | Classifier Accuracy: 0.7887600064277649\n",
      "epoch 200\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000519\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.024628\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.000990\t\n",
      "Classifier Loss: 1.1798747898340225 | Classifier Accuracy: 0.7918800115585327\n",
      "epoch 201\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000718\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.003502\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.002352\t\n",
      "Classifier Loss: 1.2030262100696563 | Classifier Accuracy: 0.7917600274085999\n",
      "epoch 202\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000513\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.000226\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.000935\t\n",
      "Classifier Loss: 1.2324235904216767 | Classifier Accuracy: 0.7906799912452698\n",
      "epoch 203\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.003727\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.001173\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.000303\t\n",
      "Classifier Loss: 1.1958142147064208 | Classifier Accuracy: 0.7893999814987183\n",
      "epoch 204\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000528\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.000428\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.001199\t\n",
      "Classifier Loss: 1.1565852150917053 | Classifier Accuracy: 0.7904000282287598\n",
      "epoch 205\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000897\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.000471\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.002982\t\n",
      "Classifier Loss: 1.2430128571987151 | Classifier Accuracy: 0.7878400087356567\n",
      "epoch 206\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.001228\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.004342\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.002892\t\n",
      "Classifier Loss: 1.1918270497322083 | Classifier Accuracy: 0.7874799966812134\n",
      "epoch 207\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000382\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.000463\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.005586\t\n",
      "Classifier Loss: 1.2385349674224853 | Classifier Accuracy: 0.7851200103759766\n",
      "epoch 208\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000436\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.000500\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.000497\t\n",
      "Classifier Loss: 1.2076544361114503 | Classifier Accuracy: 0.7869200110435486\n",
      "epoch 209\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000800\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.000675\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.000349\t\n",
      "Classifier Loss: 1.2066403226852418 | Classifier Accuracy: 0.7905600070953369\n",
      "epoch 210\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.001179\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.000331\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.000455\t\n",
      "Classifier Loss: 1.2156304035186767 | Classifier Accuracy: 0.7860400080680847\n",
      "epoch 211\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.001091\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.000353\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.000722\t\n",
      "Classifier Loss: 1.2018148415088654 | Classifier Accuracy: 0.7908400297164917\n",
      "epoch 212\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000397\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.000800\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.000843\t\n",
      "Classifier Loss: 1.2019115478992461 | Classifier Accuracy: 0.7849199771881104\n",
      "epoch 213\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000797\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.001729\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.003260\t\n",
      "Classifier Loss: 1.2096372228860854 | Classifier Accuracy: 0.7895200252532959\n",
      "epoch 214\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.001694\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.000615\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.000541\t\n",
      "Classifier Loss: 1.2413783814907073 | Classifier Accuracy: 0.787880003452301\n",
      "epoch 215\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.001480\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.000425\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.002729\t\n",
      "Classifier Loss: 1.256909175157547 | Classifier Accuracy: 0.7839599847793579\n",
      "epoch 216\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.013144\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.000378\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.001141\t\n",
      "Classifier Loss: 1.21342613363266 | Classifier Accuracy: 0.78711998462677\n",
      "epoch 217\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000669\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.000327\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.000829\t\n",
      "Classifier Loss: 1.2334115116596223 | Classifier Accuracy: 0.7855200171470642\n",
      "epoch 218\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000585\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.007474\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.004728\t\n",
      "Classifier Loss: 1.2021523373126983 | Classifier Accuracy: 0.7907999753952026\n",
      "epoch 219\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000531\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.001807\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.000276\t\n",
      "Classifier Loss: 1.274500871181488 | Classifier Accuracy: 0.7878400087356567\n",
      "epoch 220\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.001107\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.000463\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.000964\t\n",
      "Classifier Loss: 1.2616829035282136 | Classifier Accuracy: 0.788320004940033\n",
      "epoch 221\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.033472\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.000935\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.002176\t\n",
      "Classifier Loss: 1.2068394012451171 | Classifier Accuracy: 0.7884399890899658\n",
      "epoch 222\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000336\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.000727\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.000380\t\n",
      "Classifier Loss: 1.3145088031291963 | Classifier Accuracy: 0.7840399742126465\n",
      "epoch 223\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.001618\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.001696\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.000339\t\n",
      "Classifier Loss: 1.2589371249675751 | Classifier Accuracy: 0.7868000268936157\n",
      "epoch 224\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.016583\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.000542\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.044921\t\n",
      "Classifier Loss: 1.2091876866817475 | Classifier Accuracy: 0.7865599989891052\n",
      "epoch 225\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000893\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.000329\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.000383\t\n",
      "Classifier Loss: 1.233626237154007 | Classifier Accuracy: 0.7826799750328064\n",
      "epoch 226\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000644\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.000557\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.000483\t\n",
      "Classifier Loss: 1.2779549777507782 | Classifier Accuracy: 0.781719982624054\n",
      "epoch 227\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.008301\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.009612\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.025898\t\n",
      "Classifier Loss: 1.2357520592212676 | Classifier Accuracy: 0.7897199988365173\n",
      "epoch 228\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000482\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.000321\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.026617\t\n",
      "Classifier Loss: 1.199137431383133 | Classifier Accuracy: 0.7881199717521667\n",
      "epoch 229\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.002113\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.000584\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.002422\t\n",
      "Classifier Loss: 1.2328656680583954 | Classifier Accuracy: 0.7849199771881104\n",
      "epoch 230\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000301\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.000379\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.000926\t\n",
      "Classifier Loss: 1.2607057580947876 | Classifier Accuracy: 0.7847999930381775\n",
      "epoch 231\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.002814\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.000425\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.001836\t\n",
      "Classifier Loss: 1.246105171442032 | Classifier Accuracy: 0.7880799770355225\n",
      "epoch 232\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000505\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.000704\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.001861\t\n",
      "Classifier Loss: 1.2043759660720825 | Classifier Accuracy: 0.7854400277137756\n",
      "epoch 233\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.013154\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.005224\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.014090\t\n",
      "Classifier Loss: 1.2180775694847108 | Classifier Accuracy: 0.7831599712371826\n",
      "epoch 234\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000365\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.000525\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.002238\t\n",
      "Classifier Loss: 1.2903668768405914 | Classifier Accuracy: 0.781719982624054\n",
      "epoch 235\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000440\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.000454\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.001006\t\n",
      "Classifier Loss: 1.2453777906894683 | Classifier Accuracy: 0.7879599928855896\n",
      "epoch 236\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000584\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.003477\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.000637\t\n",
      "Classifier Loss: 1.2542137711048127 | Classifier Accuracy: 0.7803999781608582\n",
      "epoch 237\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.005091\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.001170\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.020817\t\n",
      "Classifier Loss: 1.1943027663230896 | Classifier Accuracy: 0.7886800169944763\n",
      "epoch 238\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.001665\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.000383\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.000489\t\n",
      "Classifier Loss: 1.2683519744873046 | Classifier Accuracy: 0.7812399864196777\n",
      "epoch 239\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.012495\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.000499\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.000473\t\n",
      "Classifier Loss: 1.2116813026666642 | Classifier Accuracy: 0.7851200103759766\n",
      "epoch 240\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.015916\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.000311\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.000362\t\n",
      "Classifier Loss: 1.2416090717315673 | Classifier Accuracy: 0.7836800217628479\n",
      "epoch 241\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.002025\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.001131\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.013558\t\n",
      "Classifier Loss: 1.2169955604076386 | Classifier Accuracy: 0.7864400148391724\n",
      "epoch 242\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000389\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.005621\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.000418\t\n",
      "Classifier Loss: 1.268994910955429 | Classifier Accuracy: 0.7813199758529663\n",
      "epoch 243\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.001430\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.000299\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.002011\t\n",
      "Classifier Loss: 1.2497940149307252 | Classifier Accuracy: 0.786080002784729\n",
      "epoch 244\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000749\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.000351\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.000635\t\n",
      "Classifier Loss: 1.2889815685749053 | Classifier Accuracy: 0.7833600044250488\n",
      "epoch 245\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.025233\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.008772\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.006693\t\n",
      "Classifier Loss: 1.2446219310760498 | Classifier Accuracy: 0.7882800102233887\n",
      "epoch 246\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000451\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.000874\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.006606\t\n",
      "Classifier Loss: 1.2337392370700837 | Classifier Accuracy: 0.7839999794960022\n",
      "epoch 247\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000604\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.028845\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.000344\t\n",
      "Classifier Loss: 1.229325788974762 | Classifier Accuracy: 0.7816799879074097\n",
      "epoch 248\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.002411\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.000755\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.000447\t\n",
      "Classifier Loss: 1.2455012166500092 | Classifier Accuracy: 0.7871999740600586\n",
      "epoch 249\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000349\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.001165\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.000684\t\n",
      "Classifier Loss: 1.2820751314163208 | Classifier Accuracy: 0.7821199893951416\n",
      "epoch 250\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.001236\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.023066\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.000608\t\n",
      "Classifier Loss: 1.2792673134803771 | Classifier Accuracy: 0.7825199961662292\n",
      "epoch 251\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000551\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.000592\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.002981\t\n",
      "Classifier Loss: 1.2222721509933472 | Classifier Accuracy: 0.7848399877548218\n",
      "epoch 252\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000590\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.001032\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.001000\t\n",
      "Classifier Loss: 1.2269503045082093 | Classifier Accuracy: 0.7882400155067444\n",
      "epoch 253\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000500\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.000436\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.000542\t\n",
      "Classifier Loss: 1.302155790090561 | Classifier Accuracy: 0.7839199900627136\n",
      "epoch 254\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000362\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.002191\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.000254\t\n",
      "Classifier Loss: 1.2140383496284486 | Classifier Accuracy: 0.7888000011444092\n",
      "epoch 255\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000254\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.007121\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.000827\t\n",
      "Classifier Loss: 1.206222796678543 | Classifier Accuracy: 0.7887200117111206\n",
      "epoch 256\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000403\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.000282\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.006662\t\n",
      "Classifier Loss: 1.3071121582984924 | Classifier Accuracy: 0.7766000032424927\n",
      "epoch 257\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.005991\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.000667\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.033593\t\n",
      "Classifier Loss: 1.2350681676864623 | Classifier Accuracy: 0.7855600118637085\n",
      "epoch 258\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000525\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.000499\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.001150\t\n",
      "Classifier Loss: 1.2216927843093872 | Classifier Accuracy: 0.7876799702644348\n",
      "epoch 259\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000891\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.000623\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.002135\t\n",
      "Classifier Loss: 1.2302761306762695 | Classifier Accuracy: 0.7865599989891052\n",
      "epoch 260\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.001867\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.000464\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.000263\t\n",
      "Classifier Loss: 1.219385402917862 | Classifier Accuracy: 0.7854800224304199\n",
      "epoch 261\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000899\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.025244\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.017696\t\n",
      "Classifier Loss: 1.2248768353462218 | Classifier Accuracy: 0.7852399945259094\n",
      "epoch 262\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000665\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.000710\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.015295\t\n",
      "Classifier Loss: 1.261855131626129 | Classifier Accuracy: 0.7865999937057495\n",
      "epoch 263\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.003383\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.000372\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.054862\t\n",
      "Classifier Loss: 1.2241563754081726 | Classifier Accuracy: 0.790440022945404\n",
      "epoch 264\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.002497\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.001775\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.001428\t\n",
      "Classifier Loss: 1.202260093688965 | Classifier Accuracy: 0.7831599712371826\n",
      "epoch 265\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.001454\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.003910\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.045340\t\n",
      "Classifier Loss: 1.2189751617908477 | Classifier Accuracy: 0.784280002117157\n",
      "epoch 266\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000315\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.012921\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.000892\t\n",
      "Classifier Loss: 1.2394838349819184 | Classifier Accuracy: 0.7854400277137756\n",
      "epoch 267\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.001839\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.007403\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.001221\t\n",
      "Classifier Loss: 1.2084007059335709 | Classifier Accuracy: 0.7860400080680847\n",
      "epoch 268\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000345\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.001382\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.001989\t\n",
      "Classifier Loss: 1.2519298448562621 | Classifier Accuracy: 0.7829200029373169\n",
      "epoch 269\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000979\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.000487\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.000605\t\n",
      "Classifier Loss: 1.2518787120580672 | Classifier Accuracy: 0.7873200178146362\n",
      "epoch 270\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000437\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.012809\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.062183\t\n",
      "Classifier Loss: 1.2088273031711578 | Classifier Accuracy: 0.785319983959198\n",
      "epoch 271\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.001117\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.001226\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.000909\t\n",
      "Classifier Loss: 1.263528832912445 | Classifier Accuracy: 0.7853999733924866\n",
      "epoch 272\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000387\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.000597\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.060146\t\n",
      "Classifier Loss: 1.2318022739887238 | Classifier Accuracy: 0.7901600003242493\n",
      "epoch 273\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000451\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.000304\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.003862\t\n",
      "Classifier Loss: 1.3426149542331696 | Classifier Accuracy: 0.7779200077056885\n",
      "epoch 274\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.001844\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.003303\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.000677\t\n",
      "Classifier Loss: 1.245455526471138 | Classifier Accuracy: 0.7866799831390381\n",
      "epoch 275\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.001832\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.000489\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.008263\t\n",
      "Classifier Loss: 1.169565663099289 | Classifier Accuracy: 0.7864400148391724\n",
      "epoch 276\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.003598\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.003544\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.000320\t\n",
      "Classifier Loss: 1.2078908640146255 | Classifier Accuracy: 0.7888399958610535\n",
      "epoch 277\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000341\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.000621\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.034240\t\n",
      "Classifier Loss: 1.2209327731132507 | Classifier Accuracy: 0.7864800095558167\n",
      "epoch 278\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.020104\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.000784\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.004084\t\n",
      "Classifier Loss: 1.2538242886066437 | Classifier Accuracy: 0.7814000248908997\n",
      "epoch 279\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.006166\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.000851\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.002284\t\n",
      "Classifier Loss: 1.2800367313623429 | Classifier Accuracy: 0.7833600044250488\n",
      "epoch 280\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000378\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.022110\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.000423\t\n",
      "Classifier Loss: 1.253239319562912 | Classifier Accuracy: 0.7806000113487244\n",
      "epoch 281\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000591\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.060392\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.000331\t\n",
      "Classifier Loss: 1.2230550446510315 | Classifier Accuracy: 0.7865599989891052\n",
      "epoch 282\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.002277\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.000695\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.002058\t\n",
      "Classifier Loss: 1.2724561426639558 | Classifier Accuracy: 0.7833200097084045\n",
      "epoch 283\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000567\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.000961\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.016541\t\n",
      "Classifier Loss: 1.2594556968212127 | Classifier Accuracy: 0.78711998462677\n",
      "epoch 284\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000284\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.000381\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.000816\t\n",
      "Classifier Loss: 1.2315503029823303 | Classifier Accuracy: 0.7859600186347961\n",
      "epoch 285\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000929\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.000263\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.007999\t\n",
      "Classifier Loss: 1.3322702662944794 | Classifier Accuracy: 0.780239999294281\n",
      "epoch 286\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.080975\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.001843\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.000693\t\n",
      "Classifier Loss: 1.2867970588207245 | Classifier Accuracy: 0.7842400074005127\n",
      "epoch 287\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.007353\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.028978\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.000386\t\n",
      "Classifier Loss: 1.2640289018154145 | Classifier Accuracy: 0.7841200232505798\n",
      "epoch 288\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000316\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.001420\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.007202\t\n",
      "Classifier Loss: 1.2183104946613312 | Classifier Accuracy: 0.7855200171470642\n",
      "epoch 289\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000467\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.001298\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.009565\t\n",
      "Classifier Loss: 1.243211793065071 | Classifier Accuracy: 0.7851999998092651\n",
      "epoch 290\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.002212\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.016825\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.000457\t\n",
      "Classifier Loss: 1.2143689243793487 | Classifier Accuracy: 0.7881600260734558\n",
      "epoch 291\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.004586\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.002270\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.002406\t\n",
      "Classifier Loss: 1.244426786184311 | Classifier Accuracy: 0.7845199704170227\n",
      "epoch 292\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000547\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.000331\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.003411\t\n",
      "Classifier Loss: 1.2282591443061828 | Classifier Accuracy: 0.7825999855995178\n",
      "epoch 293\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.001248\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.000462\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.000441\t\n",
      "Classifier Loss: 1.2235255770683289 | Classifier Accuracy: 0.7840800285339355\n",
      "epoch 294\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000997\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.000393\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.000613\t\n",
      "Classifier Loss: 1.229728883266449 | Classifier Accuracy: 0.7847200036048889\n",
      "epoch 295\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000408\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.000505\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.016100\t\n",
      "Classifier Loss: 1.2477285358905792 | Classifier Accuracy: 0.7795600295066833\n",
      "epoch 296\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.003290\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.002492\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.002085\t\n",
      "Classifier Loss: 1.2353855829238891 | Classifier Accuracy: 0.7856400012969971\n",
      "epoch 297\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000688\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.000478\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.027832\t\n",
      "Classifier Loss: 1.2192599780559539 | Classifier Accuracy: 0.786080002784729\n",
      "epoch 298\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000384\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.000899\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.000509\t\n",
      "Classifier Loss: 1.2472234365940094 | Classifier Accuracy: 0.7838000059127808\n",
      "epoch 299\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000331\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss Classifier: 0.000328\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss Classifier: 0.048024\t\n",
      "Classifier Loss: 1.230647763967514 | Classifier Accuracy: 0.785040020942688\n"
     ]
    }
   ],
   "source": [
    "#overfitting on data\n",
    "FE, CF = get_FE_CF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "    # plot loss values to see overfittig\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(test_atk_loss)\n",
    "plt.title('Test Loss')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freeze(model):\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad_(False) \n",
    "    model.eval()\n",
    "\n",
    "def unfreeze(model):\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad_(True)\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_precision_recall(outputs, labels):\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    predicted = predicted.cpu().numpy()\n",
    "    labels = labels.cpu().numpy()\n",
    "    precision = precision_score(labels, predicted, average='macro',zero_division=0)\n",
    "    recall = recall_score(labels, predicted, average='macro')\n",
    "    return precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train pretrained FE+attacker\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "atk_criterion = nn.BCEWithLogitsLoss().to(device)\n",
    "train_loss = []\n",
    "test_loss = []\n",
    "test_acc = []\n",
    "#list for saving features \n",
    "#feature_list = []\n",
    "#for plotting\n",
    "#train_losses = []\n",
    "def train_FE_INF(FE, INF, data_train_loader, current_lr,device, vis=None):\n",
    "    INF.train()\n",
    "    #FE_optimizer = optim.Adam(FE.parameters(), lr=current_lr, weight_decay=1e-4)\n",
    "    INF_optimizer = optim.Adam(INF.parameters(), lr=current_lr, weight_decay=1e-4)\n",
    "\n",
    "    loss_INF = 0\n",
    "    running_precision=0\n",
    "    running_recall=0\n",
    "    freeze(FE)\n",
    "    for i,(X, (y1, y2)) in enumerate(atk_train_dl):\n",
    "        #if torch.cuda.is_available():\n",
    "        X, y1,y2= X.to(device), y1.to(device),y2.to(device)\n",
    "        features = FE(X)\n",
    "        #for plotting T-SNE\n",
    "        #feature_list.append(features.detach().cpu().numpy())\n",
    "        # feed them to the inf model\n",
    "        pred_private_labels = INF(features)\n",
    "        #pred_private_labels= torch.round(pred_private_labels)\n",
    "        #y2=y2.float()\n",
    "        y2 = y2.unsqueeze(1)\n",
    "        loss_INF =atk_criterion(pred_private_labels,y2.float())\n",
    "        ######\n",
    "        #train_losses.append(loss_INF.item())\n",
    "        precision, recall = get_precision_recall(pred_private_labels,y2)\n",
    "        #FE_optimizer.zero_grad()\n",
    "        INF_optimizer.zero_grad()\n",
    "        loss_INF.backward()\n",
    "        INF_optimizer.step()\n",
    "        #FE_optimizer.step()\n",
    "\n",
    "        running_precision+= precision\n",
    "        running_recall += recall\n",
    "        \n",
    "        if i % 100 == 0:\n",
    "            print('Epoch: {} [{}/{} ({:.0f}%)]\\tLoss attacker: {:.6f}\\t Precision attacker: {:.6f}\\t recall attacler: {:.6f}\\t'.format(\n",
    "                i, i * len(X), len(data_train_loader.dataset),\n",
    "                100. * i / len(data_train_loader), loss_INF.detach().item(),\n",
    "                running_precision/100,\n",
    "                running_recall/100\n",
    "                 ))\n",
    "        running_recall=0\n",
    "        running_precision=0\n",
    "    unfreeze(FE)\n",
    "\n",
    "    return FE, INF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "INF_test_loss=[]\n",
    "INF_test_acc=[]\n",
    "loss_fn = nn.BCEWithLogitsLoss().to(device)\n",
    "def test_FE_INF(FE, INF_model, data_test_loader,device):\n",
    "    FE.eval()\n",
    "    INF_model.eval()\n",
    "\n",
    "    avg_loss = 0\n",
    "    avg_acc = 0\n",
    "    counter = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (X,(y1,y2)) in enumerate(data_test_loader):\n",
    "            #if torch.cuda.is_available():\n",
    "            X,y1,y2=X.to(device),y1.to(device),y2.to(device)\n",
    "#           private_labels,n=private_labels_gaining(labels)\n",
    "            features = FE(X)\n",
    "            output = INF_model(features)\n",
    "            #output=torch.round(output)\n",
    "            #y2=y2.float()\n",
    "            y2= y2.unsqueeze(1)\n",
    "            avg_loss += loss_fn(output, y2.float()).sum()\n",
    "            pred = output.detach() > 0.5\n",
    "            avg_acc += pred.eq(y2.view_as(pred)).sum()\n",
    "            counter += 1\n",
    "            \n",
    "    avg_loss /= counter\n",
    "    avg_loss = avg_loss.detach().cpu().item()\n",
    "    #print(privlabels)\n",
    "    avg_acc = float(avg_acc) / len(data_test_loader)\n",
    "    print('Test Avg. Loss: %f, Accuracy: %f' % (avg_loss, avg_acc))\n",
    "    INF_test_loss.append(avg_loss)\n",
    "    INF_test_acc.append(avg_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_epoch=100\n",
    "lr=0.001\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "def get_FE_INF():\n",
    "    FE = torch.load(fe_model_file)\n",
    "    INF = Attacker()\n",
    "    if torch.cuda.is_available():\n",
    "        FE = FE.cuda()\n",
    "        INF = INF.cuda()\n",
    "    try:\n",
    "        for epoch in range(total_epoch):\n",
    "            print(\"epoch %d\" % epoch)\n",
    "            current_lr = adjust_learning_rate(epoch, lr)\n",
    "            FE, INF = train_FE_INF(FE, INF, atk_train_dl, current_lr, device,vis=None)\n",
    "            test_FE_INF(FE, INF, atk_test_dl,device)\n",
    "    except KeyboardInterrupt:\n",
    "        pass\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        torch.save(FE.module, \"Models/mix/pre_train/FE.pth\")\n",
    "        torch.save(INF.module, \"Models/mix/pre_train/CF.pth\")\n",
    "    else:\n",
    "        #torch.save(FE, fe_model_file)\n",
    "        torch.save(INF, inf_model_file)\n",
    "    return FE, INF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss attacker: 0.794103\t Precision attacker: 0.002750\t recall attacler: 0.005000\t\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss attacker: 0.694185\t Precision attacker: 0.002450\t recall attacler: 0.005000\t\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss attacker: 0.690535\t Precision attacker: 0.003100\t recall attacler: 0.005000\t\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss attacker: 0.686288\t Precision attacker: 0.002500\t recall attacler: 0.005000\t\n",
      "Test Avg. Loss: 0.680479, Accuracy: 54.520000\n",
      "epoch 1\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss attacker: 0.682801\t Precision attacker: 0.002600\t recall attacler: 0.005000\t\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss attacker: 0.688476\t Precision attacker: 0.002550\t recall attacler: 0.005000\t\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss attacker: 0.648947\t Precision attacker: 0.001950\t recall attacler: 0.005000\t\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss attacker: 0.654534\t Precision attacker: 0.002350\t recall attacler: 0.005000\t\n",
      "Test Avg. Loss: 0.675114, Accuracy: 56.880000\n",
      "epoch 2\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss attacker: 0.688270\t Precision attacker: 0.002950\t recall attacler: 0.005000\t\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss attacker: 0.658506\t Precision attacker: 0.002250\t recall attacler: 0.005000\t\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss attacker: 0.656343\t Precision attacker: 0.002550\t recall attacler: 0.005000\t\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss attacker: 0.682231\t Precision attacker: 0.002650\t recall attacler: 0.005000\t\n",
      "Test Avg. Loss: 0.670416, Accuracy: 57.520000\n",
      "epoch 3\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss attacker: 0.666786\t Precision attacker: 0.002250\t recall attacler: 0.005000\t\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss attacker: 0.632434\t Precision attacker: 0.002450\t recall attacler: 0.005000\t\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss attacker: 0.636051\t Precision attacker: 0.002350\t recall attacler: 0.005000\t\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss attacker: 0.640704\t Precision attacker: 0.002100\t recall attacler: 0.005000\t\n",
      "Test Avg. Loss: 0.669081, Accuracy: 59.610000\n",
      "epoch 4\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss attacker: 0.639372\t Precision attacker: 0.002300\t recall attacler: 0.005000\t\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss attacker: 0.682149\t Precision attacker: 0.002550\t recall attacler: 0.005000\t\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss attacker: 0.668950\t Precision attacker: 0.002300\t recall attacler: 0.005000\t\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss attacker: 0.673358\t Precision attacker: 0.002600\t recall attacler: 0.005000\t\n",
      "Test Avg. Loss: 0.666843, Accuracy: 60.760000\n",
      "epoch 5\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss attacker: 0.703791\t Precision attacker: 0.002650\t recall attacler: 0.005000\t\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss attacker: 0.661105\t Precision attacker: 0.002550\t recall attacler: 0.005000\t\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss attacker: 0.633687\t Precision attacker: 0.002150\t recall attacler: 0.005000\t\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss attacker: 0.651487\t Precision attacker: 0.002500\t recall attacler: 0.005000\t\n",
      "Test Avg. Loss: 0.666316, Accuracy: 61.270000\n",
      "epoch 6\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss attacker: 0.654885\t Precision attacker: 0.002250\t recall attacler: 0.005000\t\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss attacker: 0.649344\t Precision attacker: 0.002600\t recall attacler: 0.005000\t\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss attacker: 0.675143\t Precision attacker: 0.002900\t recall attacler: 0.005000\t\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss attacker: 0.670210\t Precision attacker: 0.002750\t recall attacler: 0.005000\t\n",
      "Test Avg. Loss: 0.665238, Accuracy: 61.050000\n",
      "epoch 7\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss attacker: 0.645888\t Precision attacker: 0.002350\t recall attacler: 0.005000\t\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss attacker: 0.639791\t Precision attacker: 0.002300\t recall attacler: 0.005000\t\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss attacker: 0.677875\t Precision attacker: 0.002550\t recall attacler: 0.005000\t\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss attacker: 0.693422\t Precision attacker: 0.002450\t recall attacler: 0.005000\t\n",
      "Test Avg. Loss: 0.665752, Accuracy: 62.060000\n",
      "epoch 8\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss attacker: 0.628378\t Precision attacker: 0.002200\t recall attacler: 0.005000\t\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss attacker: 0.666304\t Precision attacker: 0.002700\t recall attacler: 0.005000\t\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss attacker: 0.633730\t Precision attacker: 0.002400\t recall attacler: 0.005000\t\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss attacker: 0.676226\t Precision attacker: 0.002400\t recall attacler: 0.005000\t\n",
      "Test Avg. Loss: 0.665424, Accuracy: 60.970000\n",
      "epoch 9\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss attacker: 0.658620\t Precision attacker: 0.002200\t recall attacler: 0.005000\t\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss attacker: 0.650434\t Precision attacker: 0.002500\t recall attacler: 0.005000\t\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss attacker: 0.648814\t Precision attacker: 0.002750\t recall attacler: 0.005000\t\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss attacker: 0.691577\t Precision attacker: 0.002650\t recall attacler: 0.005000\t\n",
      "Test Avg. Loss: 0.666028, Accuracy: 61.970000\n",
      "epoch 10\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss attacker: 0.643309\t Precision attacker: 0.002150\t recall attacler: 0.005000\t\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss attacker: 0.681604\t Precision attacker: 0.002750\t recall attacler: 0.005000\t\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss attacker: 0.680849\t Precision attacker: 0.002750\t recall attacler: 0.005000\t\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss attacker: 0.629506\t Precision attacker: 0.002350\t recall attacler: 0.005000\t\n",
      "Test Avg. Loss: 0.666907, Accuracy: 61.120000\n",
      "epoch 11\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss attacker: 0.666356\t Precision attacker: 0.002250\t recall attacler: 0.005000\t\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss attacker: 0.642176\t Precision attacker: 0.002600\t recall attacler: 0.005000\t\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss attacker: 0.629543\t Precision attacker: 0.002050\t recall attacler: 0.005000\t\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss attacker: 0.706468\t Precision attacker: 0.002950\t recall attacler: 0.005000\t\n",
      "Test Avg. Loss: 0.666615, Accuracy: 61.820000\n",
      "epoch 12\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss attacker: 0.629128\t Precision attacker: 0.002450\t recall attacler: 0.005000\t\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss attacker: 0.684319\t Precision attacker: 0.003100\t recall attacler: 0.005000\t\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss attacker: 0.644381\t Precision attacker: 0.002400\t recall attacler: 0.005000\t\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss attacker: 0.627268\t Precision attacker: 0.002500\t recall attacler: 0.005000\t\n",
      "Test Avg. Loss: 0.663092, Accuracy: 62.940000\n",
      "epoch 13\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss attacker: 0.673276\t Precision attacker: 0.002800\t recall attacler: 0.005000\t\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss attacker: 0.610576\t Precision attacker: 0.002050\t recall attacler: 0.005000\t\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss attacker: 0.613309\t Precision attacker: 0.002250\t recall attacler: 0.005000\t\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss attacker: 0.662368\t Precision attacker: 0.002450\t recall attacler: 0.005000\t\n",
      "Test Avg. Loss: 0.663408, Accuracy: 62.920000\n",
      "epoch 14\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss attacker: 0.636016\t Precision attacker: 0.002250\t recall attacler: 0.005000\t\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss attacker: 0.646734\t Precision attacker: 0.002550\t recall attacler: 0.005000\t\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss attacker: 0.659740\t Precision attacker: 0.002700\t recall attacler: 0.005000\t\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss attacker: 0.646082\t Precision attacker: 0.002750\t recall attacler: 0.005000\t\n",
      "Test Avg. Loss: 0.662848, Accuracy: 62.860000\n",
      "epoch 15\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss attacker: 0.632993\t Precision attacker: 0.002450\t recall attacler: 0.005000\t\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss attacker: 0.630392\t Precision attacker: 0.002500\t recall attacler: 0.005000\t\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss attacker: 0.664351\t Precision attacker: 0.002450\t recall attacler: 0.005000\t\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss attacker: 0.643002\t Precision attacker: 0.002500\t recall attacler: 0.005000\t\n",
      "Test Avg. Loss: 0.662864, Accuracy: 63.060000\n",
      "epoch 16\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss attacker: 0.649398\t Precision attacker: 0.002300\t recall attacler: 0.005000\t\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss attacker: 0.621762\t Precision attacker: 0.002250\t recall attacler: 0.005000\t\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss attacker: 0.641068\t Precision attacker: 0.002900\t recall attacler: 0.005000\t\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss attacker: 0.663116\t Precision attacker: 0.002750\t recall attacler: 0.005000\t\n",
      "Test Avg. Loss: 0.664283, Accuracy: 62.900000\n",
      "epoch 17\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss attacker: 0.678336\t Precision attacker: 0.002550\t recall attacler: 0.005000\t\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss attacker: 0.656442\t Precision attacker: 0.002600\t recall attacler: 0.005000\t\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss attacker: 0.602977\t Precision attacker: 0.002400\t recall attacler: 0.005000\t\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss attacker: 0.650068\t Precision attacker: 0.002400\t recall attacler: 0.005000\t\n",
      "Test Avg. Loss: 0.664175, Accuracy: 63.370000\n",
      "epoch 18\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss attacker: 0.676092\t Precision attacker: 0.002750\t recall attacler: 0.005000\t\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss attacker: 0.597731\t Precision attacker: 0.002050\t recall attacler: 0.005000\t\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss attacker: 0.665082\t Precision attacker: 0.002750\t recall attacler: 0.005000\t\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss attacker: 0.624739\t Precision attacker: 0.002300\t recall attacler: 0.005000\t\n",
      "Test Avg. Loss: 0.663670, Accuracy: 62.920000\n",
      "epoch 19\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss attacker: 0.605847\t Precision attacker: 0.002150\t recall attacler: 0.005000\t\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss attacker: 0.637372\t Precision attacker: 0.002600\t recall attacler: 0.005000\t\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss attacker: 0.631496\t Precision attacker: 0.002500\t recall attacler: 0.005000\t\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss attacker: 0.641053\t Precision attacker: 0.002300\t recall attacler: 0.005000\t\n",
      "Test Avg. Loss: 0.663180, Accuracy: 62.960000\n",
      "epoch 20\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss attacker: 0.672450\t Precision attacker: 0.002600\t recall attacler: 0.005000\t\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss attacker: 0.658290\t Precision attacker: 0.002500\t recall attacler: 0.005000\t\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss attacker: 0.598996\t Precision attacker: 0.002300\t recall attacler: 0.005000\t\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss attacker: 0.624859\t Precision attacker: 0.002350\t recall attacler: 0.005000\t\n",
      "Test Avg. Loss: 0.663953, Accuracy: 63.220000\n",
      "epoch 21\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss attacker: 0.630972\t Precision attacker: 0.002500\t recall attacler: 0.005000\t\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss attacker: 0.626295\t Precision attacker: 0.002500\t recall attacler: 0.005000\t\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss attacker: 0.637664\t Precision attacker: 0.002200\t recall attacler: 0.005000\t\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss attacker: 0.630835\t Precision attacker: 0.002200\t recall attacler: 0.005000\t\n",
      "Test Avg. Loss: 0.663521, Accuracy: 62.830000\n",
      "epoch 22\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss attacker: 0.599161\t Precision attacker: 0.002150\t recall attacler: 0.005000\t\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss attacker: 0.647354\t Precision attacker: 0.002500\t recall attacler: 0.005000\t\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss attacker: 0.647576\t Precision attacker: 0.002600\t recall attacler: 0.005000\t\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss attacker: 0.662702\t Precision attacker: 0.002550\t recall attacler: 0.005000\t\n",
      "Test Avg. Loss: 0.664241, Accuracy: 62.730000\n",
      "epoch 23\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss attacker: 0.602330\t Precision attacker: 0.002350\t recall attacler: 0.005000\t\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss attacker: 0.632728\t Precision attacker: 0.002500\t recall attacler: 0.005000\t\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss attacker: 0.633414\t Precision attacker: 0.002650\t recall attacler: 0.005000\t\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss attacker: 0.623881\t Precision attacker: 0.002700\t recall attacler: 0.005000\t\n",
      "Test Avg. Loss: 0.664615, Accuracy: 62.840000\n",
      "epoch 24\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss attacker: 0.650560\t Precision attacker: 0.002650\t recall attacler: 0.005000\t\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss attacker: 0.612825\t Precision attacker: 0.002600\t recall attacler: 0.005000\t\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss attacker: 0.628701\t Precision attacker: 0.002450\t recall attacler: 0.005000\t\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss attacker: 0.672961\t Precision attacker: 0.002350\t recall attacler: 0.005000\t\n",
      "Test Avg. Loss: 0.663970, Accuracy: 62.970000\n",
      "epoch 25\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss attacker: 0.622034\t Precision attacker: 0.002400\t recall attacler: 0.005000\t\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss attacker: 0.612519\t Precision attacker: 0.002300\t recall attacler: 0.005000\t\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss attacker: 0.621622\t Precision attacker: 0.002700\t recall attacler: 0.005000\t\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss attacker: 0.622648\t Precision attacker: 0.002550\t recall attacler: 0.005000\t\n",
      "Test Avg. Loss: 0.664738, Accuracy: 62.630000\n",
      "epoch 26\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss attacker: 0.632867\t Precision attacker: 0.002550\t recall attacler: 0.005000\t\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss attacker: 0.670238\t Precision attacker: 0.002600\t recall attacler: 0.005000\t\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss attacker: 0.601622\t Precision attacker: 0.002250\t recall attacler: 0.005000\t\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss attacker: 0.621108\t Precision attacker: 0.002300\t recall attacler: 0.005000\t\n",
      "Test Avg. Loss: 0.664462, Accuracy: 62.770000\n",
      "epoch 27\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss attacker: 0.621502\t Precision attacker: 0.002500\t recall attacler: 0.005000\t\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss attacker: 0.637069\t Precision attacker: 0.002550\t recall attacler: 0.005000\t\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss attacker: 0.625107\t Precision attacker: 0.002750\t recall attacler: 0.005000\t\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss attacker: 0.663756\t Precision attacker: 0.002550\t recall attacler: 0.005000\t\n",
      "Test Avg. Loss: 0.665213, Accuracy: 62.940000\n",
      "epoch 28\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss attacker: 0.635524\t Precision attacker: 0.002550\t recall attacler: 0.005000\t\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss attacker: 0.597596\t Precision attacker: 0.001900\t recall attacler: 0.005000\t\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss attacker: 0.631361\t Precision attacker: 0.002450\t recall attacler: 0.005000\t\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss attacker: 0.663972\t Precision attacker: 0.002550\t recall attacler: 0.005000\t\n",
      "Test Avg. Loss: 0.664626, Accuracy: 62.680000\n",
      "epoch 29\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss attacker: 0.608420\t Precision attacker: 0.002500\t recall attacler: 0.005000\t\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss attacker: 0.631038\t Precision attacker: 0.002450\t recall attacler: 0.005000\t\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss attacker: 0.639353\t Precision attacker: 0.002400\t recall attacler: 0.005000\t\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss attacker: 0.587567\t Precision attacker: 0.002450\t recall attacler: 0.005000\t\n",
      "Test Avg. Loss: 0.664823, Accuracy: 62.780000\n",
      "epoch 30\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss attacker: 0.625541\t Precision attacker: 0.002250\t recall attacler: 0.005000\t\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss attacker: 0.613163\t Precision attacker: 0.002050\t recall attacler: 0.005000\t\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss attacker: 0.655906\t Precision attacker: 0.002700\t recall attacler: 0.005000\t\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss attacker: 0.633373\t Precision attacker: 0.002650\t recall attacler: 0.005000\t\n",
      "Test Avg. Loss: 0.665081, Accuracy: 62.920000\n",
      "epoch 31\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss attacker: 0.611037\t Precision attacker: 0.002150\t recall attacler: 0.005000\t\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss attacker: 0.686884\t Precision attacker: 0.002850\t recall attacler: 0.005000\t\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss attacker: 0.644099\t Precision attacker: 0.002650\t recall attacler: 0.005000\t\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss attacker: 0.607146\t Precision attacker: 0.002400\t recall attacler: 0.005000\t\n",
      "Test Avg. Loss: 0.665378, Accuracy: 62.950000\n",
      "epoch 32\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss attacker: 0.603056\t Precision attacker: 0.002150\t recall attacler: 0.005000\t\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss attacker: 0.630013\t Precision attacker: 0.002350\t recall attacler: 0.005000\t\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss attacker: 0.651055\t Precision attacker: 0.002850\t recall attacler: 0.005000\t\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss attacker: 0.664368\t Precision attacker: 0.002850\t recall attacler: 0.005000\t\n",
      "Test Avg. Loss: 0.666051, Accuracy: 62.660000\n",
      "epoch 33\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss attacker: 0.600716\t Precision attacker: 0.002100\t recall attacler: 0.005000\t\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss attacker: 0.604723\t Precision attacker: 0.002200\t recall attacler: 0.005000\t\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss attacker: 0.639983\t Precision attacker: 0.002350\t recall attacler: 0.005000\t\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss attacker: 0.645551\t Precision attacker: 0.003150\t recall attacler: 0.005000\t\n",
      "Test Avg. Loss: 0.666535, Accuracy: 63.190000\n",
      "epoch 34\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss attacker: 0.588904\t Precision attacker: 0.002150\t recall attacler: 0.005000\t\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss attacker: 0.639405\t Precision attacker: 0.002750\t recall attacler: 0.005000\t\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss attacker: 0.632888\t Precision attacker: 0.002300\t recall attacler: 0.005000\t\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss attacker: 0.622364\t Precision attacker: 0.002700\t recall attacler: 0.005000\t\n",
      "Test Avg. Loss: 0.665949, Accuracy: 63.010000\n",
      "epoch 35\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss attacker: 0.658093\t Precision attacker: 0.002800\t recall attacler: 0.005000\t\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss attacker: 0.603540\t Precision attacker: 0.002450\t recall attacler: 0.005000\t\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss attacker: 0.588689\t Precision attacker: 0.002200\t recall attacler: 0.005000\t\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss attacker: 0.644807\t Precision attacker: 0.002500\t recall attacler: 0.005000\t\n",
      "Test Avg. Loss: 0.665497, Accuracy: 62.940000\n",
      "epoch 36\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss attacker: 0.607214\t Precision attacker: 0.002250\t recall attacler: 0.005000\t\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss attacker: 0.637889\t Precision attacker: 0.002650\t recall attacler: 0.005000\t\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss attacker: 0.649895\t Precision attacker: 0.002500\t recall attacler: 0.005000\t\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss attacker: 0.661206\t Precision attacker: 0.003150\t recall attacler: 0.005000\t\n",
      "Test Avg. Loss: 0.665813, Accuracy: 63.260000\n",
      "epoch 37\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss attacker: 0.586996\t Precision attacker: 0.002400\t recall attacler: 0.005000\t\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss attacker: 0.626675\t Precision attacker: 0.002600\t recall attacler: 0.005000\t\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss attacker: 0.647645\t Precision attacker: 0.002800\t recall attacler: 0.005000\t\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss attacker: 0.650901\t Precision attacker: 0.002650\t recall attacler: 0.005000\t\n",
      "Test Avg. Loss: 0.667409, Accuracy: 63.220000\n",
      "epoch 38\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss attacker: 0.588275\t Precision attacker: 0.002500\t recall attacler: 0.005000\t\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss attacker: 0.662258\t Precision attacker: 0.002600\t recall attacler: 0.005000\t\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss attacker: 0.597047\t Precision attacker: 0.002550\t recall attacler: 0.005000\t\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss attacker: 0.623520\t Precision attacker: 0.002400\t recall attacler: 0.005000\t\n",
      "Test Avg. Loss: 0.666575, Accuracy: 63.760000\n",
      "epoch 39\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss attacker: 0.631922\t Precision attacker: 0.002600\t recall attacler: 0.005000\t\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss attacker: 0.636058\t Precision attacker: 0.002650\t recall attacler: 0.005000\t\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss attacker: 0.626656\t Precision attacker: 0.002600\t recall attacler: 0.005000\t\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss attacker: 0.620929\t Precision attacker: 0.002950\t recall attacler: 0.005000\t\n",
      "Test Avg. Loss: 0.667014, Accuracy: 63.280000\n",
      "epoch 40\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss attacker: 0.632202\t Precision attacker: 0.002450\t recall attacler: 0.005000\t\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss attacker: 0.645038\t Precision attacker: 0.002800\t recall attacler: 0.005000\t\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss attacker: 0.618536\t Precision attacker: 0.002500\t recall attacler: 0.005000\t\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss attacker: 0.609747\t Precision attacker: 0.002950\t recall attacler: 0.005000\t\n",
      "Test Avg. Loss: 0.667336, Accuracy: 63.110000\n",
      "epoch 41\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss attacker: 0.595758\t Precision attacker: 0.002000\t recall attacler: 0.005000\t\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss attacker: 0.642224\t Precision attacker: 0.002250\t recall attacler: 0.005000\t\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss attacker: 0.636435\t Precision attacker: 0.002850\t recall attacler: 0.005000\t\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss attacker: 0.635812\t Precision attacker: 0.002800\t recall attacler: 0.005000\t\n",
      "Test Avg. Loss: 0.668039, Accuracy: 62.890000\n",
      "epoch 42\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss attacker: 0.599618\t Precision attacker: 0.002350\t recall attacler: 0.005000\t\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss attacker: 0.644369\t Precision attacker: 0.002600\t recall attacler: 0.005000\t\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss attacker: 0.619988\t Precision attacker: 0.002600\t recall attacler: 0.005000\t\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss attacker: 0.612766\t Precision attacker: 0.002350\t recall attacler: 0.005000\t\n",
      "Test Avg. Loss: 0.668538, Accuracy: 62.970000\n",
      "epoch 43\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss attacker: 0.617724\t Precision attacker: 0.002600\t recall attacler: 0.005000\t\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss attacker: 0.602674\t Precision attacker: 0.002350\t recall attacler: 0.005000\t\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss attacker: 0.649547\t Precision attacker: 0.002650\t recall attacler: 0.005000\t\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss attacker: 0.654249\t Precision attacker: 0.002550\t recall attacler: 0.005000\t\n",
      "Test Avg. Loss: 0.666158, Accuracy: 63.140000\n",
      "epoch 44\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss attacker: 0.626433\t Precision attacker: 0.002250\t recall attacler: 0.005000\t\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss attacker: 0.661860\t Precision attacker: 0.002550\t recall attacler: 0.005000\t\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss attacker: 0.611591\t Precision attacker: 0.002450\t recall attacler: 0.005000\t\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss attacker: 0.609274\t Precision attacker: 0.002650\t recall attacler: 0.005000\t\n",
      "Test Avg. Loss: 0.668236, Accuracy: 63.020000\n",
      "epoch 45\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss attacker: 0.604555\t Precision attacker: 0.002500\t recall attacler: 0.005000\t\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss attacker: 0.644257\t Precision attacker: 0.002500\t recall attacler: 0.005000\t\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss attacker: 0.607323\t Precision attacker: 0.002050\t recall attacler: 0.005000\t\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss attacker: 0.593292\t Precision attacker: 0.002200\t recall attacler: 0.005000\t\n",
      "Test Avg. Loss: 0.667215, Accuracy: 62.840000\n",
      "epoch 46\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss attacker: 0.646438\t Precision attacker: 0.002550\t recall attacler: 0.005000\t\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss attacker: 0.613182\t Precision attacker: 0.002400\t recall attacler: 0.005000\t\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss attacker: 0.592586\t Precision attacker: 0.002400\t recall attacler: 0.005000\t\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss attacker: 0.595196\t Precision attacker: 0.002300\t recall attacler: 0.005000\t\n",
      "Test Avg. Loss: 0.667892, Accuracy: 62.990000\n",
      "epoch 47\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss attacker: 0.629374\t Precision attacker: 0.002750\t recall attacler: 0.005000\t\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss attacker: 0.598321\t Precision attacker: 0.002400\t recall attacler: 0.005000\t\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss attacker: 0.653344\t Precision attacker: 0.002900\t recall attacler: 0.005000\t\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss attacker: 0.616582\t Precision attacker: 0.002600\t recall attacler: 0.005000\t\n",
      "Test Avg. Loss: 0.668855, Accuracy: 62.850000\n",
      "epoch 48\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss attacker: 0.603639\t Precision attacker: 0.002650\t recall attacler: 0.005000\t\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss attacker: 0.610700\t Precision attacker: 0.002500\t recall attacler: 0.005000\t\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss attacker: 0.579779\t Precision attacker: 0.002400\t recall attacler: 0.005000\t\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss attacker: 0.668068\t Precision attacker: 0.003050\t recall attacler: 0.005000\t\n",
      "Test Avg. Loss: 0.668798, Accuracy: 63.300000\n",
      "epoch 49\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss attacker: 0.609249\t Precision attacker: 0.002350\t recall attacler: 0.005000\t\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss attacker: 0.613776\t Precision attacker: 0.002450\t recall attacler: 0.005000\t\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss attacker: 0.608317\t Precision attacker: 0.002300\t recall attacler: 0.005000\t\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss attacker: 0.630536\t Precision attacker: 0.002550\t recall attacler: 0.005000\t\n",
      "Test Avg. Loss: 0.668735, Accuracy: 63.290000\n",
      "epoch 50\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss attacker: 0.645024\t Precision attacker: 0.002850\t recall attacler: 0.005000\t\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss attacker: 0.639283\t Precision attacker: 0.002900\t recall attacler: 0.005000\t\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss attacker: 0.584259\t Precision attacker: 0.002250\t recall attacler: 0.005000\t\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss attacker: 0.600214\t Precision attacker: 0.002250\t recall attacler: 0.005000\t\n",
      "Test Avg. Loss: 0.669556, Accuracy: 62.570000\n",
      "epoch 51\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss attacker: 0.604423\t Precision attacker: 0.002300\t recall attacler: 0.005000\t\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss attacker: 0.654914\t Precision attacker: 0.002800\t recall attacler: 0.005000\t\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss attacker: 0.611278\t Precision attacker: 0.002550\t recall attacler: 0.005000\t\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss attacker: 0.593455\t Precision attacker: 0.002450\t recall attacler: 0.005000\t\n",
      "Test Avg. Loss: 0.668359, Accuracy: 62.830000\n",
      "epoch 52\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss attacker: 0.619372\t Precision attacker: 0.002600\t recall attacler: 0.005000\t\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss attacker: 0.587737\t Precision attacker: 0.002450\t recall attacler: 0.005000\t\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss attacker: 0.633202\t Precision attacker: 0.003000\t recall attacler: 0.005000\t\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss attacker: 0.576151\t Precision attacker: 0.002300\t recall attacler: 0.005000\t\n",
      "Test Avg. Loss: 0.670220, Accuracy: 62.980000\n",
      "epoch 53\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss attacker: 0.619989\t Precision attacker: 0.002300\t recall attacler: 0.005000\t\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss attacker: 0.597467\t Precision attacker: 0.002250\t recall attacler: 0.005000\t\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss attacker: 0.587172\t Precision attacker: 0.002350\t recall attacler: 0.005000\t\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss attacker: 0.592781\t Precision attacker: 0.002150\t recall attacler: 0.005000\t\n",
      "Test Avg. Loss: 0.670147, Accuracy: 63.230000\n",
      "epoch 54\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss attacker: 0.639982\t Precision attacker: 0.002600\t recall attacler: 0.005000\t\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss attacker: 0.605697\t Precision attacker: 0.002600\t recall attacler: 0.005000\t\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss attacker: 0.647410\t Precision attacker: 0.002800\t recall attacler: 0.005000\t\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss attacker: 0.582686\t Precision attacker: 0.002150\t recall attacler: 0.005000\t\n",
      "Test Avg. Loss: 0.669797, Accuracy: 63.030000\n",
      "epoch 55\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss attacker: 0.618799\t Precision attacker: 0.002350\t recall attacler: 0.005000\t\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss attacker: 0.653094\t Precision attacker: 0.002750\t recall attacler: 0.005000\t\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss attacker: 0.644248\t Precision attacker: 0.002550\t recall attacler: 0.005000\t\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss attacker: 0.624199\t Precision attacker: 0.002500\t recall attacler: 0.005000\t\n",
      "Test Avg. Loss: 0.669051, Accuracy: 63.160000\n",
      "epoch 56\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss attacker: 0.580327\t Precision attacker: 0.002300\t recall attacler: 0.005000\t\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss attacker: 0.617846\t Precision attacker: 0.002450\t recall attacler: 0.005000\t\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss attacker: 0.581838\t Precision attacker: 0.002450\t recall attacler: 0.005000\t\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss attacker: 0.568077\t Precision attacker: 0.002550\t recall attacler: 0.005000\t\n",
      "Test Avg. Loss: 0.670363, Accuracy: 63.050000\n",
      "epoch 57\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss attacker: 0.655362\t Precision attacker: 0.003000\t recall attacler: 0.005000\t\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss attacker: 0.583113\t Precision attacker: 0.002450\t recall attacler: 0.005000\t\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss attacker: 0.646704\t Precision attacker: 0.002750\t recall attacler: 0.005000\t\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss attacker: 0.643935\t Precision attacker: 0.002700\t recall attacler: 0.005000\t\n",
      "Test Avg. Loss: 0.669040, Accuracy: 63.370000\n",
      "epoch 58\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss attacker: 0.620576\t Precision attacker: 0.002950\t recall attacler: 0.005000\t\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss attacker: 0.617022\t Precision attacker: 0.002500\t recall attacler: 0.005000\t\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss attacker: 0.594661\t Precision attacker: 0.002400\t recall attacler: 0.005000\t\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss attacker: 0.573630\t Precision attacker: 0.002550\t recall attacler: 0.005000\t\n",
      "Test Avg. Loss: 0.668715, Accuracy: 62.940000\n",
      "epoch 59\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss attacker: 0.613748\t Precision attacker: 0.002700\t recall attacler: 0.005000\t\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss attacker: 0.673941\t Precision attacker: 0.002850\t recall attacler: 0.005000\t\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss attacker: 0.601097\t Precision attacker: 0.002450\t recall attacler: 0.005000\t\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss attacker: 0.598999\t Precision attacker: 0.002600\t recall attacler: 0.005000\t\n",
      "Test Avg. Loss: 0.670389, Accuracy: 62.990000\n",
      "epoch 60\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss attacker: 0.613047\t Precision attacker: 0.002350\t recall attacler: 0.005000\t\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss attacker: 0.588953\t Precision attacker: 0.002600\t recall attacler: 0.005000\t\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss attacker: 0.607923\t Precision attacker: 0.002150\t recall attacler: 0.005000\t\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss attacker: 0.604562\t Precision attacker: 0.002300\t recall attacler: 0.005000\t\n",
      "Test Avg. Loss: 0.670562, Accuracy: 63.240000\n",
      "epoch 61\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss attacker: 0.609047\t Precision attacker: 0.002650\t recall attacler: 0.005000\t\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss attacker: 0.586408\t Precision attacker: 0.002400\t recall attacler: 0.005000\t\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss attacker: 0.606140\t Precision attacker: 0.002800\t recall attacler: 0.005000\t\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss attacker: 0.557350\t Precision attacker: 0.002350\t recall attacler: 0.005000\t\n",
      "Test Avg. Loss: 0.670426, Accuracy: 63.230000\n",
      "epoch 62\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss attacker: 0.687136\t Precision attacker: 0.003200\t recall attacler: 0.005000\t\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss attacker: 0.567371\t Precision attacker: 0.002150\t recall attacler: 0.005000\t\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss attacker: 0.623547\t Precision attacker: 0.002700\t recall attacler: 0.005000\t\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss attacker: 0.574257\t Precision attacker: 0.002150\t recall attacler: 0.005000\t\n",
      "Test Avg. Loss: 0.669863, Accuracy: 62.900000\n",
      "epoch 63\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss attacker: 0.539591\t Precision attacker: 0.001900\t recall attacler: 0.005000\t\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss attacker: 0.609153\t Precision attacker: 0.002600\t recall attacler: 0.005000\t\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss attacker: 0.596705\t Precision attacker: 0.002650\t recall attacler: 0.005000\t\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss attacker: 0.573687\t Precision attacker: 0.002500\t recall attacler: 0.005000\t\n",
      "Test Avg. Loss: 0.672161, Accuracy: 62.890000\n",
      "epoch 64\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss attacker: 0.611478\t Precision attacker: 0.002350\t recall attacler: 0.005000\t\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss attacker: 0.597940\t Precision attacker: 0.002150\t recall attacler: 0.005000\t\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss attacker: 0.588196\t Precision attacker: 0.002450\t recall attacler: 0.005000\t\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss attacker: 0.545289\t Precision attacker: 0.001950\t recall attacler: 0.005000\t\n",
      "Test Avg. Loss: 0.670199, Accuracy: 63.590000\n",
      "epoch 65\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss attacker: 0.627668\t Precision attacker: 0.002550\t recall attacler: 0.005000\t\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss attacker: 0.603634\t Precision attacker: 0.002650\t recall attacler: 0.005000\t\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss attacker: 0.581500\t Precision attacker: 0.002100\t recall attacler: 0.005000\t\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss attacker: 0.600081\t Precision attacker: 0.002250\t recall attacler: 0.005000\t\n",
      "Test Avg. Loss: 0.671231, Accuracy: 62.510000\n",
      "epoch 66\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss attacker: 0.597268\t Precision attacker: 0.002350\t recall attacler: 0.005000\t\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss attacker: 0.585165\t Precision attacker: 0.002350\t recall attacler: 0.005000\t\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss attacker: 0.582059\t Precision attacker: 0.002350\t recall attacler: 0.005000\t\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss attacker: 0.655190\t Precision attacker: 0.002650\t recall attacler: 0.005000\t\n",
      "Test Avg. Loss: 0.669861, Accuracy: 63.150000\n",
      "epoch 67\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss attacker: 0.580402\t Precision attacker: 0.002450\t recall attacler: 0.005000\t\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss attacker: 0.632199\t Precision attacker: 0.002750\t recall attacler: 0.005000\t\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss attacker: 0.550221\t Precision attacker: 0.002100\t recall attacler: 0.005000\t\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss attacker: 0.603144\t Precision attacker: 0.002450\t recall attacler: 0.005000\t\n",
      "Test Avg. Loss: 0.671614, Accuracy: 63.040000\n",
      "epoch 68\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss attacker: 0.595460\t Precision attacker: 0.002550\t recall attacler: 0.005000\t\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss attacker: 0.576436\t Precision attacker: 0.002450\t recall attacler: 0.005000\t\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss attacker: 0.628273\t Precision attacker: 0.002750\t recall attacler: 0.005000\t\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss attacker: 0.576595\t Precision attacker: 0.002250\t recall attacler: 0.005000\t\n",
      "Test Avg. Loss: 0.670742, Accuracy: 63.240000\n",
      "epoch 69\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss attacker: 0.582435\t Precision attacker: 0.002650\t recall attacler: 0.005000\t\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss attacker: 0.608699\t Precision attacker: 0.002700\t recall attacler: 0.005000\t\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss attacker: 0.642964\t Precision attacker: 0.002650\t recall attacler: 0.005000\t\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss attacker: 0.616677\t Precision attacker: 0.002500\t recall attacler: 0.005000\t\n",
      "Test Avg. Loss: 0.671459, Accuracy: 63.100000\n",
      "epoch 70\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss attacker: 0.632517\t Precision attacker: 0.002750\t recall attacler: 0.005000\t\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss attacker: 0.574011\t Precision attacker: 0.002150\t recall attacler: 0.005000\t\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss attacker: 0.605930\t Precision attacker: 0.002400\t recall attacler: 0.005000\t\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss attacker: 0.591582\t Precision attacker: 0.002800\t recall attacler: 0.005000\t\n",
      "Test Avg. Loss: 0.673308, Accuracy: 62.690000\n",
      "epoch 71\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss attacker: 0.620459\t Precision attacker: 0.002450\t recall attacler: 0.005000\t\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss attacker: 0.574001\t Precision attacker: 0.001950\t recall attacler: 0.005000\t\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss attacker: 0.587922\t Precision attacker: 0.002400\t recall attacler: 0.005000\t\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss attacker: 0.658384\t Precision attacker: 0.003350\t recall attacler: 0.005000\t\n",
      "Test Avg. Loss: 0.670812, Accuracy: 62.970000\n",
      "epoch 72\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss attacker: 0.584761\t Precision attacker: 0.002400\t recall attacler: 0.005000\t\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss attacker: 0.621887\t Precision attacker: 0.002750\t recall attacler: 0.005000\t\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss attacker: 0.600767\t Precision attacker: 0.002550\t recall attacler: 0.005000\t\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss attacker: 0.584211\t Precision attacker: 0.002650\t recall attacler: 0.005000\t\n",
      "Test Avg. Loss: 0.670728, Accuracy: 62.840000\n",
      "epoch 73\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss attacker: 0.580969\t Precision attacker: 0.002600\t recall attacler: 0.005000\t\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss attacker: 0.598029\t Precision attacker: 0.002650\t recall attacler: 0.005000\t\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss attacker: 0.594734\t Precision attacker: 0.002700\t recall attacler: 0.005000\t\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss attacker: 0.560937\t Precision attacker: 0.002250\t recall attacler: 0.005000\t\n",
      "Test Avg. Loss: 0.672412, Accuracy: 63.310000\n",
      "epoch 74\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss attacker: 0.602200\t Precision attacker: 0.002550\t recall attacler: 0.005000\t\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss attacker: 0.582607\t Precision attacker: 0.002500\t recall attacler: 0.005000\t\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss attacker: 0.631109\t Precision attacker: 0.002300\t recall attacler: 0.005000\t\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss attacker: 0.593336\t Precision attacker: 0.002300\t recall attacler: 0.005000\t\n",
      "Test Avg. Loss: 0.671416, Accuracy: 63.270000\n",
      "epoch 75\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss attacker: 0.614644\t Precision attacker: 0.002450\t recall attacler: 0.005000\t\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss attacker: 0.609889\t Precision attacker: 0.002550\t recall attacler: 0.005000\t\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss attacker: 0.616475\t Precision attacker: 0.002550\t recall attacler: 0.005000\t\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss attacker: 0.580518\t Precision attacker: 0.002000\t recall attacler: 0.005000\t\n",
      "Test Avg. Loss: 0.672258, Accuracy: 62.470000\n",
      "epoch 76\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss attacker: 0.589196\t Precision attacker: 0.002500\t recall attacler: 0.005000\t\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss attacker: 0.597679\t Precision attacker: 0.002600\t recall attacler: 0.005000\t\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss attacker: 0.622141\t Precision attacker: 0.002550\t recall attacler: 0.005000\t\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss attacker: 0.570057\t Precision attacker: 0.001950\t recall attacler: 0.005000\t\n",
      "Test Avg. Loss: 0.671746, Accuracy: 62.730000\n",
      "epoch 77\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss attacker: 0.574576\t Precision attacker: 0.002200\t recall attacler: 0.005000\t\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss attacker: 0.567115\t Precision attacker: 0.002250\t recall attacler: 0.005000\t\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss attacker: 0.606205\t Precision attacker: 0.002500\t recall attacler: 0.005000\t\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss attacker: 0.597612\t Precision attacker: 0.002550\t recall attacler: 0.005000\t\n",
      "Test Avg. Loss: 0.670314, Accuracy: 63.300000\n",
      "epoch 78\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss attacker: 0.593914\t Precision attacker: 0.002950\t recall attacler: 0.005000\t\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss attacker: 0.604587\t Precision attacker: 0.002500\t recall attacler: 0.005000\t\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss attacker: 0.597018\t Precision attacker: 0.002450\t recall attacler: 0.005000\t\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss attacker: 0.586447\t Precision attacker: 0.002550\t recall attacler: 0.005000\t\n",
      "Test Avg. Loss: 0.671958, Accuracy: 63.050000\n",
      "epoch 79\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss attacker: 0.595717\t Precision attacker: 0.002550\t recall attacler: 0.005000\t\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss attacker: 0.579260\t Precision attacker: 0.002600\t recall attacler: 0.005000\t\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss attacker: 0.559111\t Precision attacker: 0.002400\t recall attacler: 0.005000\t\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss attacker: 0.582838\t Precision attacker: 0.002550\t recall attacler: 0.005000\t\n",
      "Test Avg. Loss: 0.671769, Accuracy: 62.970000\n",
      "epoch 80\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss attacker: 0.588726\t Precision attacker: 0.002450\t recall attacler: 0.005000\t\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss attacker: 0.601217\t Precision attacker: 0.002500\t recall attacler: 0.005000\t\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss attacker: 0.607479\t Precision attacker: 0.002850\t recall attacler: 0.005000\t\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss attacker: 0.585065\t Precision attacker: 0.002600\t recall attacler: 0.005000\t\n",
      "Test Avg. Loss: 0.671863, Accuracy: 62.880000\n",
      "epoch 81\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss attacker: 0.609880\t Precision attacker: 0.002550\t recall attacler: 0.005000\t\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss attacker: 0.577838\t Precision attacker: 0.002500\t recall attacler: 0.005000\t\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss attacker: 0.574027\t Precision attacker: 0.002300\t recall attacler: 0.005000\t\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss attacker: 0.591210\t Precision attacker: 0.002650\t recall attacler: 0.005000\t\n",
      "Test Avg. Loss: 0.670639, Accuracy: 63.870000\n",
      "epoch 82\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss attacker: 0.600085\t Precision attacker: 0.002800\t recall attacler: 0.005000\t\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss attacker: 0.584551\t Precision attacker: 0.002650\t recall attacler: 0.005000\t\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss attacker: 0.602093\t Precision attacker: 0.002550\t recall attacler: 0.005000\t\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss attacker: 0.649542\t Precision attacker: 0.002900\t recall attacler: 0.005000\t\n",
      "Test Avg. Loss: 0.670241, Accuracy: 62.890000\n",
      "epoch 83\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss attacker: 0.565471\t Precision attacker: 0.002500\t recall attacler: 0.005000\t\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss attacker: 0.581638\t Precision attacker: 0.002400\t recall attacler: 0.005000\t\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss attacker: 0.591240\t Precision attacker: 0.002200\t recall attacler: 0.005000\t\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss attacker: 0.574920\t Precision attacker: 0.002400\t recall attacler: 0.005000\t\n",
      "Test Avg. Loss: 0.672170, Accuracy: 62.670000\n",
      "epoch 84\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss attacker: 0.599892\t Precision attacker: 0.002550\t recall attacler: 0.005000\t\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss attacker: 0.570407\t Precision attacker: 0.002350\t recall attacler: 0.005000\t\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss attacker: 0.584202\t Precision attacker: 0.002150\t recall attacler: 0.005000\t\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss attacker: 0.587342\t Precision attacker: 0.002550\t recall attacler: 0.005000\t\n",
      "Test Avg. Loss: 0.670631, Accuracy: 63.130000\n",
      "epoch 85\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss attacker: 0.558201\t Precision attacker: 0.002500\t recall attacler: 0.005000\t\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss attacker: 0.604128\t Precision attacker: 0.002700\t recall attacler: 0.005000\t\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss attacker: 0.590906\t Precision attacker: 0.002400\t recall attacler: 0.005000\t\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss attacker: 0.620968\t Precision attacker: 0.002650\t recall attacler: 0.005000\t\n",
      "Test Avg. Loss: 0.672462, Accuracy: 63.590000\n",
      "epoch 86\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss attacker: 0.554059\t Precision attacker: 0.002500\t recall attacler: 0.005000\t\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss attacker: 0.594795\t Precision attacker: 0.002650\t recall attacler: 0.005000\t\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss attacker: 0.601169\t Precision attacker: 0.002650\t recall attacler: 0.005000\t\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss attacker: 0.589427\t Precision attacker: 0.002650\t recall attacler: 0.005000\t\n",
      "Test Avg. Loss: 0.672375, Accuracy: 63.590000\n",
      "epoch 87\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss attacker: 0.583389\t Precision attacker: 0.002450\t recall attacler: 0.005000\t\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss attacker: 0.549146\t Precision attacker: 0.002150\t recall attacler: 0.005000\t\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss attacker: 0.566754\t Precision attacker: 0.002650\t recall attacler: 0.005000\t\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss attacker: 0.595524\t Precision attacker: 0.002550\t recall attacler: 0.005000\t\n",
      "Test Avg. Loss: 0.673623, Accuracy: 63.670000\n",
      "epoch 88\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss attacker: 0.559415\t Precision attacker: 0.002450\t recall attacler: 0.005000\t\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss attacker: 0.591371\t Precision attacker: 0.002450\t recall attacler: 0.005000\t\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss attacker: 0.607000\t Precision attacker: 0.002250\t recall attacler: 0.005000\t\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss attacker: 0.610215\t Precision attacker: 0.002750\t recall attacler: 0.005000\t\n",
      "Test Avg. Loss: 0.672948, Accuracy: 63.200000\n",
      "epoch 89\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss attacker: 0.576976\t Precision attacker: 0.002350\t recall attacler: 0.005000\t\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss attacker: 0.575758\t Precision attacker: 0.002200\t recall attacler: 0.005000\t\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss attacker: 0.616293\t Precision attacker: 0.002700\t recall attacler: 0.005000\t\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss attacker: 0.612680\t Precision attacker: 0.002700\t recall attacler: 0.005000\t\n",
      "Test Avg. Loss: 0.671884, Accuracy: 63.210000\n",
      "epoch 90\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss attacker: 0.575615\t Precision attacker: 0.002400\t recall attacler: 0.005000\t\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss attacker: 0.601631\t Precision attacker: 0.002550\t recall attacler: 0.005000\t\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss attacker: 0.594814\t Precision attacker: 0.001950\t recall attacler: 0.005000\t\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss attacker: 0.609725\t Precision attacker: 0.002450\t recall attacler: 0.005000\t\n",
      "Test Avg. Loss: 0.673263, Accuracy: 63.360000\n",
      "epoch 91\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss attacker: 0.586729\t Precision attacker: 0.002800\t recall attacler: 0.005000\t\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss attacker: 0.600848\t Precision attacker: 0.002750\t recall attacler: 0.005000\t\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss attacker: 0.595649\t Precision attacker: 0.002650\t recall attacler: 0.005000\t\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss attacker: 0.587154\t Precision attacker: 0.002400\t recall attacler: 0.005000\t\n",
      "Test Avg. Loss: 0.673001, Accuracy: 62.560000\n",
      "epoch 92\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss attacker: 0.579163\t Precision attacker: 0.002900\t recall attacler: 0.005000\t\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss attacker: 0.589313\t Precision attacker: 0.002750\t recall attacler: 0.005000\t\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss attacker: 0.648384\t Precision attacker: 0.003050\t recall attacler: 0.005000\t\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss attacker: 0.558379\t Precision attacker: 0.002250\t recall attacler: 0.005000\t\n",
      "Test Avg. Loss: 0.673009, Accuracy: 62.440000\n",
      "epoch 93\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss attacker: 0.617539\t Precision attacker: 0.002550\t recall attacler: 0.005000\t\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss attacker: 0.581401\t Precision attacker: 0.002300\t recall attacler: 0.005000\t\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss attacker: 0.573475\t Precision attacker: 0.002300\t recall attacler: 0.005000\t\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss attacker: 0.601097\t Precision attacker: 0.002550\t recall attacler: 0.005000\t\n",
      "Test Avg. Loss: 0.673762, Accuracy: 63.240000\n",
      "epoch 94\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss attacker: 0.598314\t Precision attacker: 0.002600\t recall attacler: 0.005000\t\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss attacker: 0.552466\t Precision attacker: 0.002200\t recall attacler: 0.005000\t\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss attacker: 0.592036\t Precision attacker: 0.002550\t recall attacler: 0.005000\t\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss attacker: 0.582925\t Precision attacker: 0.002200\t recall attacler: 0.005000\t\n",
      "Test Avg. Loss: 0.672600, Accuracy: 62.660000\n",
      "epoch 95\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss attacker: 0.585987\t Precision attacker: 0.002600\t recall attacler: 0.005000\t\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss attacker: 0.552173\t Precision attacker: 0.002300\t recall attacler: 0.005000\t\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss attacker: 0.589351\t Precision attacker: 0.002350\t recall attacler: 0.005000\t\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss attacker: 0.565158\t Precision attacker: 0.002300\t recall attacler: 0.005000\t\n",
      "Test Avg. Loss: 0.675533, Accuracy: 63.240000\n",
      "epoch 96\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss attacker: 0.583521\t Precision attacker: 0.002700\t recall attacler: 0.005000\t\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss attacker: 0.580739\t Precision attacker: 0.002650\t recall attacler: 0.005000\t\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss attacker: 0.595558\t Precision attacker: 0.002500\t recall attacler: 0.005000\t\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss attacker: 0.561535\t Precision attacker: 0.002400\t recall attacler: 0.005000\t\n",
      "Test Avg. Loss: 0.675035, Accuracy: 63.290000\n",
      "epoch 97\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss attacker: 0.561890\t Precision attacker: 0.002200\t recall attacler: 0.005000\t\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss attacker: 0.566629\t Precision attacker: 0.002350\t recall attacler: 0.005000\t\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss attacker: 0.589356\t Precision attacker: 0.002500\t recall attacler: 0.005000\t\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss attacker: 0.564985\t Precision attacker: 0.002250\t recall attacler: 0.005000\t\n",
      "Test Avg. Loss: 0.673666, Accuracy: 62.730000\n",
      "epoch 98\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss attacker: 0.590723\t Precision attacker: 0.002300\t recall attacler: 0.005000\t\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss attacker: 0.556916\t Precision attacker: 0.002200\t recall attacler: 0.005000\t\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss attacker: 0.572991\t Precision attacker: 0.002650\t recall attacler: 0.005000\t\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss attacker: 0.597824\t Precision attacker: 0.002900\t recall attacler: 0.005000\t\n",
      "Test Avg. Loss: 0.675355, Accuracy: 63.410000\n",
      "epoch 99\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss attacker: 0.542596\t Precision attacker: 0.002100\t recall attacler: 0.005000\t\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss attacker: 0.544569\t Precision attacker: 0.002100\t recall attacler: 0.005000\t\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss attacker: 0.614607\t Precision attacker: 0.002700\t recall attacler: 0.005000\t\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss attacker: 0.539418\t Precision attacker: 0.002000\t recall attacler: 0.005000\t\n",
      "Test Avg. Loss: 0.676416, Accuracy: 62.370000\n"
     ]
    }
   ],
   "source": [
    "FE, INF = get_FE_INF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plotting attacker loss during training \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(train_losses)\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Attacker Loss')\n",
    "plt.title('Attacker Training Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "loss_fn = nn.BCEWithLogitsLoss().cuda()\n",
    "\n",
    "def train(FE_model,INF_model, CF_model, trainloader, current_lr,current_lr_atk,tradoff=0.5 ):\n",
    "    FE_model.train()\n",
    "    INF_model.train()\n",
    "    CF_model.train()\n",
    "    #tradoff=0\n",
    "    \n",
    "    FE_optimizer = optim.Adam(FE_model.parameters(), lr=current_lr, weight_decay=1e-4)\n",
    "    CF_optimizer = optim.Adam(CF_model.parameters(), lr=current_lr, weight_decay=1e-4)\n",
    "    INF_optimizer = optim.Adam(INF_model.parameters(), lr=current_lr_atk, weight_decay=1e-4)\n",
    "    \n",
    "    for i, (images, (labels, privlabels)) in enumerate(trainloader):\n",
    "        if torch.cuda.is_available():\n",
    "            images, labels, privlabels = images.cuda(), labels.cuda(), privlabels.cuda()\n",
    "\n",
    "        # get features from the feature extractor\n",
    "        features = FE_model(images)\n",
    "        \n",
    "        # feed them to the inf model\n",
    "        pred_private_labels = INF_model(features)\n",
    "        loss_INF = loss_fn(pred_private_labels, privlabels.reshape(-1,1).float())\n",
    "\n",
    "        # feed only private images==1 to the classifier\n",
    "        classifier_features = features[privlabels == 1]\n",
    "        output_CF = CF_model(classifier_features)\n",
    "        loss_CF = criterion(output_CF, labels[privlabels == 1])\n",
    "        \n",
    "        # compute loss and backprop\n",
    "        loss = -tradoff * loss_INF + (1. - tradoff) * loss_CF\n",
    "        \n",
    "        FE_optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        FE_optimizer.step()\n",
    "\n",
    "        \n",
    "         # get features from the feature extractor\n",
    "        features = FE_model(images).detach()\n",
    "        INF_optimizer.zero_grad()\n",
    "        CF_optimizer.zero_grad()\n",
    "        \n",
    "        # feed them to the inf model\n",
    "        pred_private_labels = INF_model(features)\n",
    "        loss_INF = loss_fn(pred_private_labels, privlabels.reshape(-1,1).float())\n",
    "        loss_INF.backward()\n",
    "        INF_optimizer.step()\n",
    "\n",
    "       \n",
    "        # feed only private images to the classifier\n",
    "        classifier_features = features[privlabels == 1]\n",
    "        output_CF = CF_model(classifier_features)\n",
    "        loss_CF = criterion(output_CF, labels[privlabels == 1])\n",
    "        loss_CF.backward()\n",
    "        CF_optimizer.step()\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            print('Epoch: {} [{}/{} ({:.0f}%)]\\tLoss Classifier: {:.6f}\\tLoss Attacker: {:.6f}'.format(\n",
    "                i, i * len(images), len(trainloader.dataset),\n",
    "                100. * i / len(trainloader), loss_CF.item(), loss_INF.item()))\n",
    "\n",
    "    return FE_model, INF_model, CF_model       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a directory to save models\n",
    "save_dir = os.path.join(os.getcwd(), 'resnet-0.5')\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# define the file name for each model\n",
    "fe_model_file_defense = os.path.join(save_dir, 'FE_defense.pth')\n",
    "cf_model_file_defense = os.path.join(save_dir, 'CF_defense.pth')\n",
    "inf_model_file_defense = os.path.join(save_dir, 'INF_defense.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_epoch=300\n",
    "lr=0.0001\n",
    "lr_atk=3e-3\n",
    "#lr=0.1\n",
    "tradoff=0.5\n",
    "def get_FE_defense():\n",
    "    #using FE and CF after pretraining them\n",
    "    FE = torch.load(fe_model_file)\n",
    "    #FE=AlexNet_FE()\n",
    "    #CF=AlexNet_predictor()\n",
    "    CF = torch.load(cf_model_file)\n",
    "    INF=torch.load(inf_model_file)\n",
    "    #INF = Attacker()\n",
    "    if torch.cuda.is_available():\n",
    "        FE = FE.cuda()\n",
    "        CF = CF.cuda()\n",
    "        INF = INF.cuda()\n",
    "    try:\n",
    "        for epoch in range(total_epoch):\n",
    "            print(\"epoch %d\" % epoch)\n",
    "            current_lr = adjust_learning_rate(epoch, lr)\n",
    "            current_lr_atk = adjust_learning_rate(epoch,lr_atk)\n",
    "            FE, INF, CF =train(FE,INF, CF, atk_train_dl, current_lr,current_lr_atk, tradoff)\n",
    "            #test_attacker_defense(FE, INF, atk_test_dl,device)\n",
    "    except KeyboardInterrupt:\n",
    "        pass\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        torch.save(FE.module, \"FE_defense.pth\")\n",
    "        torch.save(CF.module, \"CF_defense.pth\")\n",
    "        torch.save(INF.module, \"INF_defense.pth\")\n",
    "    else:\n",
    "        torch.save(FE,fe_model_file_defense)\n",
    "        torch.save(INF,inf_model_file_defense)\n",
    "        torch.save(CF, cf_model_file_defense)\n",
    "    return FE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.001524\tLoss Attacker: 0.646964\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000353\tLoss Attacker: 0.694239\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000823\tLoss Attacker: 0.690124\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000540\tLoss Attacker: 0.705411\n",
      "epoch 1\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000311\tLoss Attacker: 0.715291\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000213\tLoss Attacker: 0.683131\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000450\tLoss Attacker: 0.682555\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.005814\tLoss Attacker: 0.679569\n",
      "epoch 2\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000387\tLoss Attacker: 0.702817\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000501\tLoss Attacker: 0.702071\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000784\tLoss Attacker: 0.681800\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.001206\tLoss Attacker: 0.694205\n",
      "epoch 3\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000442\tLoss Attacker: 0.684383\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000989\tLoss Attacker: 0.666741\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000724\tLoss Attacker: 0.678276\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000208\tLoss Attacker: 0.661063\n",
      "epoch 4\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000313\tLoss Attacker: 0.692608\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000778\tLoss Attacker: 0.686465\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.001046\tLoss Attacker: 0.681404\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.001272\tLoss Attacker: 0.685775\n",
      "epoch 5\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000535\tLoss Attacker: 0.721199\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000243\tLoss Attacker: 0.672906\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000344\tLoss Attacker: 0.687649\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000187\tLoss Attacker: 0.697217\n",
      "epoch 6\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000490\tLoss Attacker: 0.696681\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000206\tLoss Attacker: 0.685690\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000314\tLoss Attacker: 0.687202\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.001917\tLoss Attacker: 0.693460\n",
      "epoch 7\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000494\tLoss Attacker: 0.713630\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000456\tLoss Attacker: 0.690177\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000777\tLoss Attacker: 0.687435\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.001071\tLoss Attacker: 0.699663\n",
      "epoch 8\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000232\tLoss Attacker: 0.676834\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000364\tLoss Attacker: 0.686048\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.002368\tLoss Attacker: 0.685324\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000511\tLoss Attacker: 0.694265\n",
      "epoch 9\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000745\tLoss Attacker: 0.717527\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000513\tLoss Attacker: 0.689819\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.001839\tLoss Attacker: 0.698355\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.001031\tLoss Attacker: 0.673545\n",
      "epoch 10\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000693\tLoss Attacker: 0.690447\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000923\tLoss Attacker: 0.698672\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.001139\tLoss Attacker: 0.692964\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000325\tLoss Attacker: 0.687089\n",
      "epoch 11\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000430\tLoss Attacker: 0.699691\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.001181\tLoss Attacker: 0.693399\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000657\tLoss Attacker: 0.679440\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.001062\tLoss Attacker: 0.680451\n",
      "epoch 12\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000621\tLoss Attacker: 0.701444\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000804\tLoss Attacker: 0.707981\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.001072\tLoss Attacker: 0.690719\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000422\tLoss Attacker: 0.681106\n",
      "epoch 13\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000314\tLoss Attacker: 0.678441\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000797\tLoss Attacker: 0.675534\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000240\tLoss Attacker: 0.685432\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000372\tLoss Attacker: 0.694066\n",
      "epoch 14\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000424\tLoss Attacker: 0.698837\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000338\tLoss Attacker: 0.686430\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000465\tLoss Attacker: 0.699891\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000164\tLoss Attacker: 0.693283\n",
      "epoch 15\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000210\tLoss Attacker: 0.689542\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000503\tLoss Attacker: 0.697515\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000234\tLoss Attacker: 0.692864\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000373\tLoss Attacker: 0.708368\n",
      "epoch 16\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.009830\tLoss Attacker: 0.691340\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000256\tLoss Attacker: 0.669848\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000531\tLoss Attacker: 0.695550\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000526\tLoss Attacker: 0.674314\n",
      "epoch 17\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000422\tLoss Attacker: 0.673744\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.001710\tLoss Attacker: 0.685645\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000223\tLoss Attacker: 0.673134\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000220\tLoss Attacker: 0.690950\n",
      "epoch 18\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000303\tLoss Attacker: 0.693711\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000146\tLoss Attacker: 0.692879\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000217\tLoss Attacker: 0.689763\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000169\tLoss Attacker: 0.693202\n",
      "epoch 19\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000378\tLoss Attacker: 0.681238\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000333\tLoss Attacker: 0.678621\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000653\tLoss Attacker: 0.676706\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000500\tLoss Attacker: 0.687450\n",
      "epoch 20\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000416\tLoss Attacker: 0.692425\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000887\tLoss Attacker: 0.695625\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000281\tLoss Attacker: 0.688863\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000588\tLoss Attacker: 0.677451\n",
      "epoch 21\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000446\tLoss Attacker: 0.703878\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000354\tLoss Attacker: 0.691472\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000258\tLoss Attacker: 0.693353\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000325\tLoss Attacker: 0.686196\n",
      "epoch 22\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000416\tLoss Attacker: 0.696742\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000530\tLoss Attacker: 0.702762\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.001154\tLoss Attacker: 0.691507\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.001314\tLoss Attacker: 0.699132\n",
      "epoch 23\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000276\tLoss Attacker: 0.693510\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000284\tLoss Attacker: 0.688797\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000242\tLoss Attacker: 0.688825\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000428\tLoss Attacker: 0.691452\n",
      "epoch 24\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000334\tLoss Attacker: 0.700088\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000309\tLoss Attacker: 0.695557\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000493\tLoss Attacker: 0.694072\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000174\tLoss Attacker: 0.681224\n",
      "epoch 25\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000450\tLoss Attacker: 0.686772\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000225\tLoss Attacker: 0.691785\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000241\tLoss Attacker: 0.688797\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000433\tLoss Attacker: 0.698804\n",
      "epoch 26\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000268\tLoss Attacker: 0.685600\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000253\tLoss Attacker: 0.697986\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000238\tLoss Attacker: 0.693409\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000503\tLoss Attacker: 0.687426\n",
      "epoch 27\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000269\tLoss Attacker: 0.696171\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000852\tLoss Attacker: 0.694168\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000179\tLoss Attacker: 0.693604\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000270\tLoss Attacker: 0.696291\n",
      "epoch 28\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000273\tLoss Attacker: 0.693552\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000396\tLoss Attacker: 0.690738\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000856\tLoss Attacker: 0.692031\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000277\tLoss Attacker: 0.692836\n",
      "epoch 29\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000196\tLoss Attacker: 0.697264\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000346\tLoss Attacker: 0.693053\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.001025\tLoss Attacker: 0.691333\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000317\tLoss Attacker: 0.689943\n",
      "epoch 30\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000279\tLoss Attacker: 0.694477\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000374\tLoss Attacker: 0.689309\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000698\tLoss Attacker: 0.691567\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000519\tLoss Attacker: 0.685005\n",
      "epoch 31\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000326\tLoss Attacker: 0.694259\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000321\tLoss Attacker: 0.689931\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000371\tLoss Attacker: 0.689820\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000297\tLoss Attacker: 0.692995\n",
      "epoch 32\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000214\tLoss Attacker: 0.694260\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000552\tLoss Attacker: 0.691595\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000591\tLoss Attacker: 0.692629\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000333\tLoss Attacker: 0.694567\n",
      "epoch 33\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000279\tLoss Attacker: 0.690707\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000311\tLoss Attacker: 0.694901\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000397\tLoss Attacker: 0.693586\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000472\tLoss Attacker: 0.687547\n",
      "epoch 34\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.042008\tLoss Attacker: 0.688670\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000423\tLoss Attacker: 0.695484\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000230\tLoss Attacker: 0.686008\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000320\tLoss Attacker: 0.692954\n",
      "epoch 35\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000296\tLoss Attacker: 0.686007\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000252\tLoss Attacker: 0.694825\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000269\tLoss Attacker: 0.688596\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000266\tLoss Attacker: 0.690849\n",
      "epoch 36\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000311\tLoss Attacker: 0.695434\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000462\tLoss Attacker: 0.693912\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000228\tLoss Attacker: 0.692689\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000348\tLoss Attacker: 0.688631\n",
      "epoch 37\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000336\tLoss Attacker: 0.688593\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000445\tLoss Attacker: 0.693251\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000444\tLoss Attacker: 0.698186\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000508\tLoss Attacker: 0.697860\n",
      "epoch 38\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000301\tLoss Attacker: 0.689653\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000331\tLoss Attacker: 0.695870\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000286\tLoss Attacker: 0.698089\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.001723\tLoss Attacker: 0.692624\n",
      "epoch 39\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000432\tLoss Attacker: 0.690860\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000241\tLoss Attacker: 0.693497\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000512\tLoss Attacker: 0.693293\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000414\tLoss Attacker: 0.692874\n",
      "epoch 40\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000653\tLoss Attacker: 0.698669\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000486\tLoss Attacker: 0.692328\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000426\tLoss Attacker: 0.695688\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000566\tLoss Attacker: 0.695463\n",
      "epoch 41\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000396\tLoss Attacker: 0.700847\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000240\tLoss Attacker: 0.697973\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000384\tLoss Attacker: 0.694082\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000507\tLoss Attacker: 0.692571\n",
      "epoch 42\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000352\tLoss Attacker: 0.694303\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000486\tLoss Attacker: 0.689240\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000256\tLoss Attacker: 0.693226\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000272\tLoss Attacker: 0.691863\n",
      "epoch 43\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000265\tLoss Attacker: 0.692119\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000265\tLoss Attacker: 0.691277\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.001478\tLoss Attacker: 0.689090\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000380\tLoss Attacker: 0.690086\n",
      "epoch 44\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000338\tLoss Attacker: 0.692718\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000378\tLoss Attacker: 0.694458\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000500\tLoss Attacker: 0.695300\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000425\tLoss Attacker: 0.689512\n",
      "epoch 45\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000248\tLoss Attacker: 0.690245\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000286\tLoss Attacker: 0.698129\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000243\tLoss Attacker: 0.693605\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000411\tLoss Attacker: 0.691776\n",
      "epoch 46\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000295\tLoss Attacker: 0.695533\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000248\tLoss Attacker: 0.691023\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000505\tLoss Attacker: 0.686950\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000502\tLoss Attacker: 0.690074\n",
      "epoch 47\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000315\tLoss Attacker: 0.691949\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000300\tLoss Attacker: 0.694966\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000752\tLoss Attacker: 0.698723\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000336\tLoss Attacker: 0.693607\n",
      "epoch 48\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000935\tLoss Attacker: 0.696032\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000494\tLoss Attacker: 0.691816\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000409\tLoss Attacker: 0.692577\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000241\tLoss Attacker: 0.690286\n",
      "epoch 49\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000443\tLoss Attacker: 0.693756\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000482\tLoss Attacker: 0.695529\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000334\tLoss Attacker: 0.689112\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000403\tLoss Attacker: 0.691452\n",
      "epoch 50\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000275\tLoss Attacker: 0.692320\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000297\tLoss Attacker: 0.690382\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000772\tLoss Attacker: 0.690779\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000397\tLoss Attacker: 0.694759\n",
      "epoch 51\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000497\tLoss Attacker: 0.693321\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000391\tLoss Attacker: 0.693945\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000359\tLoss Attacker: 0.692032\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000325\tLoss Attacker: 0.692046\n",
      "epoch 52\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000608\tLoss Attacker: 0.693617\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000474\tLoss Attacker: 0.688684\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000289\tLoss Attacker: 0.698395\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000348\tLoss Attacker: 0.693351\n",
      "epoch 53\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000425\tLoss Attacker: 0.694791\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000222\tLoss Attacker: 0.691544\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000438\tLoss Attacker: 0.693389\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000222\tLoss Attacker: 0.692801\n",
      "epoch 54\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000327\tLoss Attacker: 0.691204\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000440\tLoss Attacker: 0.692257\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000303\tLoss Attacker: 0.693251\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000491\tLoss Attacker: 0.696417\n",
      "epoch 55\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000387\tLoss Attacker: 0.692728\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000254\tLoss Attacker: 0.692951\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000324\tLoss Attacker: 0.694537\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000237\tLoss Attacker: 0.692471\n",
      "epoch 56\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000207\tLoss Attacker: 0.692969\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000529\tLoss Attacker: 0.694382\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000266\tLoss Attacker: 0.694560\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000257\tLoss Attacker: 0.693068\n",
      "epoch 57\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000276\tLoss Attacker: 0.691568\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000403\tLoss Attacker: 0.694065\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000444\tLoss Attacker: 0.693458\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000204\tLoss Attacker: 0.692426\n",
      "epoch 58\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000297\tLoss Attacker: 0.693331\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000303\tLoss Attacker: 0.691917\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000521\tLoss Attacker: 0.695009\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000302\tLoss Attacker: 0.694191\n",
      "epoch 59\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000231\tLoss Attacker: 0.694060\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000548\tLoss Attacker: 0.692713\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000255\tLoss Attacker: 0.691912\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000358\tLoss Attacker: 0.693644\n",
      "epoch 60\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000354\tLoss Attacker: 0.693063\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000417\tLoss Attacker: 0.693581\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000365\tLoss Attacker: 0.693585\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000325\tLoss Attacker: 0.691901\n",
      "epoch 61\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000322\tLoss Attacker: 0.695245\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000530\tLoss Attacker: 0.692864\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000372\tLoss Attacker: 0.692818\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000290\tLoss Attacker: 0.692404\n",
      "epoch 62\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000227\tLoss Attacker: 0.693907\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000286\tLoss Attacker: 0.695668\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000322\tLoss Attacker: 0.691847\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000400\tLoss Attacker: 0.692723\n",
      "epoch 63\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000357\tLoss Attacker: 0.691716\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000368\tLoss Attacker: 0.691973\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000301\tLoss Attacker: 0.692547\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000278\tLoss Attacker: 0.694430\n",
      "epoch 64\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000609\tLoss Attacker: 0.692792\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000341\tLoss Attacker: 0.694290\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000231\tLoss Attacker: 0.691223\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000256\tLoss Attacker: 0.691819\n",
      "epoch 65\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000276\tLoss Attacker: 0.693283\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000303\tLoss Attacker: 0.693540\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000308\tLoss Attacker: 0.693191\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000298\tLoss Attacker: 0.692775\n",
      "epoch 66\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000277\tLoss Attacker: 0.694433\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000361\tLoss Attacker: 0.691948\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000222\tLoss Attacker: 0.689829\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000323\tLoss Attacker: 0.693267\n",
      "epoch 67\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000247\tLoss Attacker: 0.692859\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000274\tLoss Attacker: 0.693557\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000287\tLoss Attacker: 0.694580\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000413\tLoss Attacker: 0.692088\n",
      "epoch 68\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000327\tLoss Attacker: 0.693135\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000449\tLoss Attacker: 0.691529\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000253\tLoss Attacker: 0.695219\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000524\tLoss Attacker: 0.694222\n",
      "epoch 69\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000344\tLoss Attacker: 0.693074\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000355\tLoss Attacker: 0.691726\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000403\tLoss Attacker: 0.692804\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000444\tLoss Attacker: 0.694709\n",
      "epoch 70\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000252\tLoss Attacker: 0.691854\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000269\tLoss Attacker: 0.693343\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000352\tLoss Attacker: 0.694071\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000675\tLoss Attacker: 0.695086\n",
      "epoch 71\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000394\tLoss Attacker: 0.691558\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000421\tLoss Attacker: 0.697148\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000243\tLoss Attacker: 0.691440\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000445\tLoss Attacker: 0.693436\n",
      "epoch 72\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000464\tLoss Attacker: 0.692657\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000362\tLoss Attacker: 0.693032\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000510\tLoss Attacker: 0.692444\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000419\tLoss Attacker: 0.692872\n",
      "epoch 73\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000237\tLoss Attacker: 0.694201\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000378\tLoss Attacker: 0.693754\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000225\tLoss Attacker: 0.691629\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000354\tLoss Attacker: 0.694668\n",
      "epoch 74\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000414\tLoss Attacker: 0.694246\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000419\tLoss Attacker: 0.693660\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000416\tLoss Attacker: 0.692614\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000230\tLoss Attacker: 0.693847\n",
      "epoch 75\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000286\tLoss Attacker: 0.693609\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000248\tLoss Attacker: 0.693679\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000281\tLoss Attacker: 0.691481\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000409\tLoss Attacker: 0.694517\n",
      "epoch 76\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000363\tLoss Attacker: 0.692595\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000355\tLoss Attacker: 0.694718\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000244\tLoss Attacker: 0.694549\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000225\tLoss Attacker: 0.695062\n",
      "epoch 77\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000320\tLoss Attacker: 0.692716\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000426\tLoss Attacker: 0.694102\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000345\tLoss Attacker: 0.690956\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000379\tLoss Attacker: 0.691502\n",
      "epoch 78\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000376\tLoss Attacker: 0.694391\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000430\tLoss Attacker: 0.692196\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000275\tLoss Attacker: 0.695314\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000504\tLoss Attacker: 0.693762\n",
      "epoch 79\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000306\tLoss Attacker: 0.694616\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000386\tLoss Attacker: 0.691242\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000452\tLoss Attacker: 0.692902\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000298\tLoss Attacker: 0.694155\n",
      "epoch 80\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000556\tLoss Attacker: 0.692648\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000299\tLoss Attacker: 0.691997\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000413\tLoss Attacker: 0.693023\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000377\tLoss Attacker: 0.693352\n",
      "epoch 81\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000276\tLoss Attacker: 0.693197\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000218\tLoss Attacker: 0.694231\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000410\tLoss Attacker: 0.691956\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000263\tLoss Attacker: 0.694388\n",
      "epoch 82\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000224\tLoss Attacker: 0.691328\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000290\tLoss Attacker: 0.693166\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000261\tLoss Attacker: 0.693412\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000272\tLoss Attacker: 0.693181\n",
      "epoch 83\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000347\tLoss Attacker: 0.692124\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000304\tLoss Attacker: 0.692939\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000353\tLoss Attacker: 0.692169\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000295\tLoss Attacker: 0.691251\n",
      "epoch 84\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000330\tLoss Attacker: 0.693766\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000311\tLoss Attacker: 0.693510\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000330\tLoss Attacker: 0.693655\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000198\tLoss Attacker: 0.693418\n",
      "epoch 85\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000320\tLoss Attacker: 0.694059\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000203\tLoss Attacker: 0.692857\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000318\tLoss Attacker: 0.692991\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000304\tLoss Attacker: 0.692870\n",
      "epoch 86\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000324\tLoss Attacker: 0.690791\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000251\tLoss Attacker: 0.693467\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000342\tLoss Attacker: 0.692685\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000279\tLoss Attacker: 0.693962\n",
      "epoch 87\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000239\tLoss Attacker: 0.693297\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000313\tLoss Attacker: 0.692626\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000365\tLoss Attacker: 0.692168\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000384\tLoss Attacker: 0.693198\n",
      "epoch 88\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000289\tLoss Attacker: 0.692832\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000338\tLoss Attacker: 0.691990\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000539\tLoss Attacker: 0.691013\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000380\tLoss Attacker: 0.694067\n",
      "epoch 89\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000253\tLoss Attacker: 0.692314\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000360\tLoss Attacker: 0.693822\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000282\tLoss Attacker: 0.691842\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000491\tLoss Attacker: 0.693105\n",
      "epoch 90\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000252\tLoss Attacker: 0.692404\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000364\tLoss Attacker: 0.693077\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000383\tLoss Attacker: 0.692293\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000320\tLoss Attacker: 0.693463\n",
      "epoch 91\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000305\tLoss Attacker: 0.693063\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000398\tLoss Attacker: 0.692465\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000272\tLoss Attacker: 0.692259\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000853\tLoss Attacker: 0.691977\n",
      "epoch 92\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000230\tLoss Attacker: 0.692395\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000368\tLoss Attacker: 0.692256\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000277\tLoss Attacker: 0.693323\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000392\tLoss Attacker: 0.694453\n",
      "epoch 93\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000270\tLoss Attacker: 0.694231\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000294\tLoss Attacker: 0.693272\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000263\tLoss Attacker: 0.692445\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000333\tLoss Attacker: 0.693851\n",
      "epoch 94\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000316\tLoss Attacker: 0.694285\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000276\tLoss Attacker: 0.693829\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000318\tLoss Attacker: 0.692580\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000299\tLoss Attacker: 0.693574\n",
      "epoch 95\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000275\tLoss Attacker: 0.691671\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000349\tLoss Attacker: 0.693206\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000331\tLoss Attacker: 0.692404\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000248\tLoss Attacker: 0.691854\n",
      "epoch 96\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000334\tLoss Attacker: 0.693489\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000539\tLoss Attacker: 0.695788\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000437\tLoss Attacker: 0.694636\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000367\tLoss Attacker: 0.692122\n",
      "epoch 97\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000382\tLoss Attacker: 0.694249\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000593\tLoss Attacker: 0.694629\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000281\tLoss Attacker: 0.691036\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000270\tLoss Attacker: 0.693926\n",
      "epoch 98\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000244\tLoss Attacker: 0.692604\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000828\tLoss Attacker: 0.693505\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000281\tLoss Attacker: 0.693604\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000227\tLoss Attacker: 0.694000\n",
      "epoch 99\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000183\tLoss Attacker: 0.693635\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000320\tLoss Attacker: 0.694048\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000330\tLoss Attacker: 0.691994\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000329\tLoss Attacker: 0.692943\n",
      "epoch 100\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000394\tLoss Attacker: 0.692846\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000356\tLoss Attacker: 0.695895\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000333\tLoss Attacker: 0.694392\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000378\tLoss Attacker: 0.694728\n",
      "epoch 101\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000567\tLoss Attacker: 0.695064\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000271\tLoss Attacker: 0.692832\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000275\tLoss Attacker: 0.693357\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000316\tLoss Attacker: 0.693528\n",
      "epoch 102\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000326\tLoss Attacker: 0.693388\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000340\tLoss Attacker: 0.694037\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000588\tLoss Attacker: 0.693373\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000253\tLoss Attacker: 0.693055\n",
      "epoch 103\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000302\tLoss Attacker: 0.692775\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000285\tLoss Attacker: 0.693937\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000287\tLoss Attacker: 0.692631\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000400\tLoss Attacker: 0.694695\n",
      "epoch 104\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000253\tLoss Attacker: 0.692392\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000380\tLoss Attacker: 0.693374\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000344\tLoss Attacker: 0.694350\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000245\tLoss Attacker: 0.692425\n",
      "epoch 105\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000607\tLoss Attacker: 0.694069\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000409\tLoss Attacker: 0.693794\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000283\tLoss Attacker: 0.693252\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000320\tLoss Attacker: 0.692718\n",
      "epoch 106\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000298\tLoss Attacker: 0.692564\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000345\tLoss Attacker: 0.692164\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000340\tLoss Attacker: 0.692912\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000247\tLoss Attacker: 0.692359\n",
      "epoch 107\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000286\tLoss Attacker: 0.693399\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000193\tLoss Attacker: 0.692294\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000330\tLoss Attacker: 0.694647\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000502\tLoss Attacker: 0.692888\n",
      "epoch 108\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000298\tLoss Attacker: 0.693378\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000244\tLoss Attacker: 0.692165\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000286\tLoss Attacker: 0.692531\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000283\tLoss Attacker: 0.692391\n",
      "epoch 109\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000361\tLoss Attacker: 0.692225\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000299\tLoss Attacker: 0.693758\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000308\tLoss Attacker: 0.693515\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000364\tLoss Attacker: 0.693888\n",
      "epoch 110\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000237\tLoss Attacker: 0.692223\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000343\tLoss Attacker: 0.692678\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000235\tLoss Attacker: 0.693035\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000247\tLoss Attacker: 0.692981\n",
      "epoch 111\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000287\tLoss Attacker: 0.692069\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000241\tLoss Attacker: 0.693374\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000253\tLoss Attacker: 0.693882\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000233\tLoss Attacker: 0.693173\n",
      "epoch 112\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000498\tLoss Attacker: 0.692086\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000312\tLoss Attacker: 0.694421\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000299\tLoss Attacker: 0.691460\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000291\tLoss Attacker: 0.690526\n",
      "epoch 113\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000266\tLoss Attacker: 0.693224\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000288\tLoss Attacker: 0.693150\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000505\tLoss Attacker: 0.692361\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000291\tLoss Attacker: 0.693956\n",
      "epoch 114\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000221\tLoss Attacker: 0.693440\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000381\tLoss Attacker: 0.693299\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000397\tLoss Attacker: 0.693911\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000296\tLoss Attacker: 0.694412\n",
      "epoch 115\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000264\tLoss Attacker: 0.691578\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000354\tLoss Attacker: 0.692897\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000418\tLoss Attacker: 0.692804\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000229\tLoss Attacker: 0.693516\n",
      "epoch 116\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000340\tLoss Attacker: 0.693988\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000280\tLoss Attacker: 0.693775\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000408\tLoss Attacker: 0.691302\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000292\tLoss Attacker: 0.692630\n",
      "epoch 117\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000273\tLoss Attacker: 0.692161\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000258\tLoss Attacker: 0.693173\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000309\tLoss Attacker: 0.693302\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000714\tLoss Attacker: 0.694082\n",
      "epoch 118\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000270\tLoss Attacker: 0.694144\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000512\tLoss Attacker: 0.693618\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000341\tLoss Attacker: 0.693922\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000257\tLoss Attacker: 0.693839\n",
      "epoch 119\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000235\tLoss Attacker: 0.691807\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000241\tLoss Attacker: 0.693381\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000249\tLoss Attacker: 0.694477\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000247\tLoss Attacker: 0.691420\n",
      "epoch 120\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000388\tLoss Attacker: 0.692710\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000446\tLoss Attacker: 0.694783\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000236\tLoss Attacker: 0.692962\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000668\tLoss Attacker: 0.693271\n",
      "epoch 121\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000479\tLoss Attacker: 0.693952\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000334\tLoss Attacker: 0.693259\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000449\tLoss Attacker: 0.693456\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000252\tLoss Attacker: 0.693273\n",
      "epoch 122\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000324\tLoss Attacker: 0.693169\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000241\tLoss Attacker: 0.693181\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000378\tLoss Attacker: 0.692673\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000397\tLoss Attacker: 0.692956\n",
      "epoch 123\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000249\tLoss Attacker: 0.690746\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000390\tLoss Attacker: 0.691306\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000258\tLoss Attacker: 0.693123\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000278\tLoss Attacker: 0.694651\n",
      "epoch 124\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000283\tLoss Attacker: 0.693654\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000250\tLoss Attacker: 0.694184\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000268\tLoss Attacker: 0.692540\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000310\tLoss Attacker: 0.693286\n",
      "epoch 125\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000292\tLoss Attacker: 0.692751\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000538\tLoss Attacker: 0.695634\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000266\tLoss Attacker: 0.692588\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000361\tLoss Attacker: 0.692065\n",
      "epoch 126\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000309\tLoss Attacker: 0.691165\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000226\tLoss Attacker: 0.692718\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000250\tLoss Attacker: 0.694026\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000479\tLoss Attacker: 0.693260\n",
      "epoch 127\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000353\tLoss Attacker: 0.691422\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000319\tLoss Attacker: 0.694149\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000307\tLoss Attacker: 0.693003\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000411\tLoss Attacker: 0.693312\n",
      "epoch 128\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000370\tLoss Attacker: 0.691795\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000356\tLoss Attacker: 0.693471\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000359\tLoss Attacker: 0.692203\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000244\tLoss Attacker: 0.693604\n",
      "epoch 129\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000331\tLoss Attacker: 0.692906\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000290\tLoss Attacker: 0.692435\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000373\tLoss Attacker: 0.693647\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000262\tLoss Attacker: 0.695342\n",
      "epoch 130\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000280\tLoss Attacker: 0.693142\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000291\tLoss Attacker: 0.692590\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000359\tLoss Attacker: 0.692723\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000311\tLoss Attacker: 0.692793\n",
      "epoch 131\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000280\tLoss Attacker: 0.695790\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000246\tLoss Attacker: 0.691209\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000372\tLoss Attacker: 0.693618\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000312\tLoss Attacker: 0.691841\n",
      "epoch 132\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000262\tLoss Attacker: 0.694348\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000405\tLoss Attacker: 0.693542\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000283\tLoss Attacker: 0.694054\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000240\tLoss Attacker: 0.693796\n",
      "epoch 133\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000328\tLoss Attacker: 0.694883\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000376\tLoss Attacker: 0.692303\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000326\tLoss Attacker: 0.692937\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000297\tLoss Attacker: 0.692874\n",
      "epoch 134\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000267\tLoss Attacker: 0.694838\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000254\tLoss Attacker: 0.693221\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000246\tLoss Attacker: 0.693284\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000213\tLoss Attacker: 0.692724\n",
      "epoch 135\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000235\tLoss Attacker: 0.693156\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000348\tLoss Attacker: 0.694388\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000270\tLoss Attacker: 0.693682\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000307\tLoss Attacker: 0.692813\n",
      "epoch 136\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000292\tLoss Attacker: 0.692500\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000320\tLoss Attacker: 0.693680\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000293\tLoss Attacker: 0.693920\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000251\tLoss Attacker: 0.691624\n",
      "epoch 137\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000536\tLoss Attacker: 0.693258\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000295\tLoss Attacker: 0.693530\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000272\tLoss Attacker: 0.695024\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000247\tLoss Attacker: 0.693368\n",
      "epoch 138\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000204\tLoss Attacker: 0.693355\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000715\tLoss Attacker: 0.694771\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000332\tLoss Attacker: 0.693615\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000249\tLoss Attacker: 0.692959\n",
      "epoch 139\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000508\tLoss Attacker: 0.693597\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000391\tLoss Attacker: 0.694795\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000327\tLoss Attacker: 0.691581\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000245\tLoss Attacker: 0.692851\n",
      "epoch 140\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000266\tLoss Attacker: 0.693065\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000240\tLoss Attacker: 0.694412\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000309\tLoss Attacker: 0.693184\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000226\tLoss Attacker: 0.692395\n",
      "epoch 141\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000301\tLoss Attacker: 0.693986\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000357\tLoss Attacker: 0.692592\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000286\tLoss Attacker: 0.692047\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000267\tLoss Attacker: 0.693016\n",
      "epoch 142\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000369\tLoss Attacker: 0.693116\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000284\tLoss Attacker: 0.693743\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000315\tLoss Attacker: 0.692525\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000257\tLoss Attacker: 0.693282\n",
      "epoch 143\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000259\tLoss Attacker: 0.692560\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000394\tLoss Attacker: 0.693650\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000213\tLoss Attacker: 0.692955\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000211\tLoss Attacker: 0.693223\n",
      "epoch 144\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000236\tLoss Attacker: 0.693305\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000320\tLoss Attacker: 0.693488\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000315\tLoss Attacker: 0.691107\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000223\tLoss Attacker: 0.695318\n",
      "epoch 145\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000235\tLoss Attacker: 0.693377\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000374\tLoss Attacker: 0.692992\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000286\tLoss Attacker: 0.693981\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000429\tLoss Attacker: 0.692307\n",
      "epoch 146\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000302\tLoss Attacker: 0.693101\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000237\tLoss Attacker: 0.693614\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000382\tLoss Attacker: 0.694767\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000259\tLoss Attacker: 0.692360\n",
      "epoch 147\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000297\tLoss Attacker: 0.692773\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000269\tLoss Attacker: 0.693967\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000304\tLoss Attacker: 0.693459\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000324\tLoss Attacker: 0.693713\n",
      "epoch 148\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000273\tLoss Attacker: 0.692104\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000401\tLoss Attacker: 0.692597\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000251\tLoss Attacker: 0.693099\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000361\tLoss Attacker: 0.693577\n",
      "epoch 149\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000245\tLoss Attacker: 0.694016\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000237\tLoss Attacker: 0.693210\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000197\tLoss Attacker: 0.694119\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000365\tLoss Attacker: 0.693842\n",
      "epoch 150\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000286\tLoss Attacker: 0.692375\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000205\tLoss Attacker: 0.693234\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000212\tLoss Attacker: 0.692716\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000376\tLoss Attacker: 0.693502\n",
      "epoch 151\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000283\tLoss Attacker: 0.693492\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000287\tLoss Attacker: 0.690971\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000259\tLoss Attacker: 0.691486\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000393\tLoss Attacker: 0.692265\n",
      "epoch 152\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000215\tLoss Attacker: 0.693362\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000221\tLoss Attacker: 0.693591\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000336\tLoss Attacker: 0.695453\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000247\tLoss Attacker: 0.693368\n",
      "epoch 153\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000329\tLoss Attacker: 0.693063\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000356\tLoss Attacker: 0.692585\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000250\tLoss Attacker: 0.693095\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000523\tLoss Attacker: 0.693746\n",
      "epoch 154\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000220\tLoss Attacker: 0.693892\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000359\tLoss Attacker: 0.692829\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000307\tLoss Attacker: 0.693129\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000399\tLoss Attacker: 0.693942\n",
      "epoch 155\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000308\tLoss Attacker: 0.694685\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000245\tLoss Attacker: 0.693081\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000384\tLoss Attacker: 0.694164\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000429\tLoss Attacker: 0.692920\n",
      "epoch 156\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.001139\tLoss Attacker: 0.694076\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000442\tLoss Attacker: 0.694115\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000302\tLoss Attacker: 0.694009\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000200\tLoss Attacker: 0.693325\n",
      "epoch 157\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000302\tLoss Attacker: 0.693978\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000502\tLoss Attacker: 0.693281\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000322\tLoss Attacker: 0.692119\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000400\tLoss Attacker: 0.694641\n",
      "epoch 158\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000236\tLoss Attacker: 0.692848\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000251\tLoss Attacker: 0.694584\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000313\tLoss Attacker: 0.694463\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000263\tLoss Attacker: 0.693302\n",
      "epoch 159\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000649\tLoss Attacker: 0.693909\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000299\tLoss Attacker: 0.690885\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000292\tLoss Attacker: 0.693740\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000458\tLoss Attacker: 0.692815\n",
      "epoch 160\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000300\tLoss Attacker: 0.693908\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000312\tLoss Attacker: 0.693384\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000300\tLoss Attacker: 0.692512\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000229\tLoss Attacker: 0.692427\n",
      "epoch 161\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000220\tLoss Attacker: 0.692765\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000291\tLoss Attacker: 0.692848\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000363\tLoss Attacker: 0.693347\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000247\tLoss Attacker: 0.692395\n",
      "epoch 162\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000324\tLoss Attacker: 0.693712\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000215\tLoss Attacker: 0.692850\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000317\tLoss Attacker: 0.693656\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000277\tLoss Attacker: 0.694401\n",
      "epoch 163\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000348\tLoss Attacker: 0.693338\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000441\tLoss Attacker: 0.693687\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000269\tLoss Attacker: 0.692173\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000328\tLoss Attacker: 0.693513\n",
      "epoch 164\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000316\tLoss Attacker: 0.693077\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000233\tLoss Attacker: 0.693000\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000249\tLoss Attacker: 0.692349\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000233\tLoss Attacker: 0.692691\n",
      "epoch 165\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000259\tLoss Attacker: 0.693928\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000253\tLoss Attacker: 0.692088\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000316\tLoss Attacker: 0.692210\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000306\tLoss Attacker: 0.693153\n",
      "epoch 166\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000379\tLoss Attacker: 0.693873\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000202\tLoss Attacker: 0.693272\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000237\tLoss Attacker: 0.692137\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000429\tLoss Attacker: 0.692388\n",
      "epoch 167\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000257\tLoss Attacker: 0.693523\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000361\tLoss Attacker: 0.693458\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000257\tLoss Attacker: 0.693739\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000278\tLoss Attacker: 0.693019\n",
      "epoch 168\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000189\tLoss Attacker: 0.694167\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000216\tLoss Attacker: 0.692423\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000165\tLoss Attacker: 0.692473\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000607\tLoss Attacker: 0.694392\n",
      "epoch 169\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000336\tLoss Attacker: 0.693099\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000402\tLoss Attacker: 0.693400\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000292\tLoss Attacker: 0.692699\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000304\tLoss Attacker: 0.692190\n",
      "epoch 170\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000471\tLoss Attacker: 0.693513\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000339\tLoss Attacker: 0.692223\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000216\tLoss Attacker: 0.693630\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000411\tLoss Attacker: 0.694287\n",
      "epoch 171\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000265\tLoss Attacker: 0.693687\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000268\tLoss Attacker: 0.692980\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000276\tLoss Attacker: 0.694390\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000262\tLoss Attacker: 0.693374\n",
      "epoch 172\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000236\tLoss Attacker: 0.693973\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000280\tLoss Attacker: 0.691957\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000370\tLoss Attacker: 0.693220\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000291\tLoss Attacker: 0.692881\n",
      "epoch 173\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000306\tLoss Attacker: 0.693711\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000300\tLoss Attacker: 0.694560\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000215\tLoss Attacker: 0.692858\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000476\tLoss Attacker: 0.694514\n",
      "epoch 174\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000427\tLoss Attacker: 0.691406\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000277\tLoss Attacker: 0.693030\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000220\tLoss Attacker: 0.692125\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000310\tLoss Attacker: 0.693761\n",
      "epoch 175\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000293\tLoss Attacker: 0.691336\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000330\tLoss Attacker: 0.692346\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000280\tLoss Attacker: 0.692898\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000309\tLoss Attacker: 0.692482\n",
      "epoch 176\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000238\tLoss Attacker: 0.694004\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000340\tLoss Attacker: 0.693033\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000349\tLoss Attacker: 0.693648\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000250\tLoss Attacker: 0.693907\n",
      "epoch 177\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000226\tLoss Attacker: 0.693997\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000348\tLoss Attacker: 0.694184\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000283\tLoss Attacker: 0.691756\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000303\tLoss Attacker: 0.693119\n",
      "epoch 178\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000305\tLoss Attacker: 0.693365\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000312\tLoss Attacker: 0.693984\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000277\tLoss Attacker: 0.692411\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000292\tLoss Attacker: 0.691900\n",
      "epoch 179\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000215\tLoss Attacker: 0.693506\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000340\tLoss Attacker: 0.693643\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000410\tLoss Attacker: 0.693604\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000301\tLoss Attacker: 0.693449\n",
      "epoch 180\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000237\tLoss Attacker: 0.692053\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000285\tLoss Attacker: 0.692494\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000480\tLoss Attacker: 0.693333\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000249\tLoss Attacker: 0.691812\n",
      "epoch 181\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000290\tLoss Attacker: 0.695369\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000326\tLoss Attacker: 0.691720\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000347\tLoss Attacker: 0.690637\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000305\tLoss Attacker: 0.694895\n",
      "epoch 182\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000238\tLoss Attacker: 0.693001\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000260\tLoss Attacker: 0.694010\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000242\tLoss Attacker: 0.693026\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000328\tLoss Attacker: 0.692034\n",
      "epoch 183\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000254\tLoss Attacker: 0.692652\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000374\tLoss Attacker: 0.692119\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000248\tLoss Attacker: 0.692735\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000305\tLoss Attacker: 0.693882\n",
      "epoch 184\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000292\tLoss Attacker: 0.692493\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000259\tLoss Attacker: 0.692448\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000276\tLoss Attacker: 0.693516\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000318\tLoss Attacker: 0.692650\n",
      "epoch 185\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000376\tLoss Attacker: 0.694175\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000385\tLoss Attacker: 0.694204\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000270\tLoss Attacker: 0.692973\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000299\tLoss Attacker: 0.692949\n",
      "epoch 186\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000256\tLoss Attacker: 0.694032\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000220\tLoss Attacker: 0.692359\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000310\tLoss Attacker: 0.693440\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000429\tLoss Attacker: 0.692757\n",
      "epoch 187\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000321\tLoss Attacker: 0.693824\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000274\tLoss Attacker: 0.693477\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000221\tLoss Attacker: 0.692144\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000245\tLoss Attacker: 0.692618\n",
      "epoch 188\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000182\tLoss Attacker: 0.693179\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000329\tLoss Attacker: 0.693313\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000221\tLoss Attacker: 0.694709\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000335\tLoss Attacker: 0.693198\n",
      "epoch 189\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000323\tLoss Attacker: 0.692956\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000228\tLoss Attacker: 0.694925\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000228\tLoss Attacker: 0.694191\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000247\tLoss Attacker: 0.692703\n",
      "epoch 190\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000223\tLoss Attacker: 0.691911\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000195\tLoss Attacker: 0.693059\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000212\tLoss Attacker: 0.694057\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000289\tLoss Attacker: 0.693303\n",
      "epoch 191\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000328\tLoss Attacker: 0.693087\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000303\tLoss Attacker: 0.692150\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000363\tLoss Attacker: 0.692392\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000239\tLoss Attacker: 0.692240\n",
      "epoch 192\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000225\tLoss Attacker: 0.692472\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000220\tLoss Attacker: 0.692673\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000220\tLoss Attacker: 0.691794\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000313\tLoss Attacker: 0.694568\n",
      "epoch 193\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000244\tLoss Attacker: 0.693481\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000363\tLoss Attacker: 0.691993\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000245\tLoss Attacker: 0.693374\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000391\tLoss Attacker: 0.693614\n",
      "epoch 194\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000412\tLoss Attacker: 0.694449\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000350\tLoss Attacker: 0.692556\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000221\tLoss Attacker: 0.691702\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000253\tLoss Attacker: 0.693617\n",
      "epoch 195\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000522\tLoss Attacker: 0.693640\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000356\tLoss Attacker: 0.694269\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000362\tLoss Attacker: 0.692140\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000335\tLoss Attacker: 0.692947\n",
      "epoch 196\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000306\tLoss Attacker: 0.693260\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000271\tLoss Attacker: 0.692852\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000298\tLoss Attacker: 0.692712\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000401\tLoss Attacker: 0.694756\n",
      "epoch 197\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000409\tLoss Attacker: 0.691661\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000313\tLoss Attacker: 0.693019\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000440\tLoss Attacker: 0.692356\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000330\tLoss Attacker: 0.691994\n",
      "epoch 198\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000249\tLoss Attacker: 0.691800\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000250\tLoss Attacker: 0.691512\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000245\tLoss Attacker: 0.691457\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000299\tLoss Attacker: 0.690991\n",
      "epoch 199\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000236\tLoss Attacker: 0.692686\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000416\tLoss Attacker: 0.695203\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000310\tLoss Attacker: 0.689564\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000395\tLoss Attacker: 0.694932\n",
      "epoch 200\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000296\tLoss Attacker: 0.694702\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000254\tLoss Attacker: 0.691284\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000448\tLoss Attacker: 0.694611\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000498\tLoss Attacker: 0.691099\n",
      "epoch 201\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000186\tLoss Attacker: 0.691819\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000549\tLoss Attacker: 0.693028\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000322\tLoss Attacker: 0.692877\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000319\tLoss Attacker: 0.691874\n",
      "epoch 202\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000313\tLoss Attacker: 0.694306\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000351\tLoss Attacker: 0.693728\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000333\tLoss Attacker: 0.693335\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000280\tLoss Attacker: 0.692665\n",
      "epoch 203\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000252\tLoss Attacker: 0.693210\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000256\tLoss Attacker: 0.693261\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000285\tLoss Attacker: 0.691607\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000250\tLoss Attacker: 0.693231\n",
      "epoch 204\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000292\tLoss Attacker: 0.692877\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000246\tLoss Attacker: 0.693219\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000333\tLoss Attacker: 0.692350\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000299\tLoss Attacker: 0.692719\n",
      "epoch 205\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000398\tLoss Attacker: 0.692063\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000241\tLoss Attacker: 0.691775\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000353\tLoss Attacker: 0.691725\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000265\tLoss Attacker: 0.692282\n",
      "epoch 206\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000358\tLoss Attacker: 0.694530\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000321\tLoss Attacker: 0.693949\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000269\tLoss Attacker: 0.693725\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000565\tLoss Attacker: 0.694106\n",
      "epoch 207\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000217\tLoss Attacker: 0.693391\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000430\tLoss Attacker: 0.693332\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000272\tLoss Attacker: 0.691574\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000447\tLoss Attacker: 0.693168\n",
      "epoch 208\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000290\tLoss Attacker: 0.692681\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000380\tLoss Attacker: 0.692143\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000291\tLoss Attacker: 0.694450\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000347\tLoss Attacker: 0.692783\n",
      "epoch 209\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000307\tLoss Attacker: 0.692929\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000269\tLoss Attacker: 0.693780\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000280\tLoss Attacker: 0.694026\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000263\tLoss Attacker: 0.691834\n",
      "epoch 210\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000377\tLoss Attacker: 0.693456\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000214\tLoss Attacker: 0.691336\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000348\tLoss Attacker: 0.693157\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000325\tLoss Attacker: 0.693981\n",
      "epoch 211\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000226\tLoss Attacker: 0.693996\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000428\tLoss Attacker: 0.692553\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000414\tLoss Attacker: 0.693637\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000221\tLoss Attacker: 0.693104\n",
      "epoch 212\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000244\tLoss Attacker: 0.692901\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000247\tLoss Attacker: 0.692968\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000425\tLoss Attacker: 0.695141\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000231\tLoss Attacker: 0.694441\n",
      "epoch 213\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000369\tLoss Attacker: 0.695625\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000280\tLoss Attacker: 0.691916\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000439\tLoss Attacker: 0.692092\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000343\tLoss Attacker: 0.694973\n",
      "epoch 214\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000302\tLoss Attacker: 0.691541\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000275\tLoss Attacker: 0.692812\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000337\tLoss Attacker: 0.691388\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000331\tLoss Attacker: 0.692380\n",
      "epoch 215\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000309\tLoss Attacker: 0.693759\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000331\tLoss Attacker: 0.693692\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000241\tLoss Attacker: 0.693932\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000390\tLoss Attacker: 0.693605\n",
      "epoch 216\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000291\tLoss Attacker: 0.694278\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000243\tLoss Attacker: 0.694006\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000290\tLoss Attacker: 0.692672\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000321\tLoss Attacker: 0.694467\n",
      "epoch 217\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000309\tLoss Attacker: 0.692666\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000258\tLoss Attacker: 0.691604\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000371\tLoss Attacker: 0.691198\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000281\tLoss Attacker: 0.693210\n",
      "epoch 218\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000308\tLoss Attacker: 0.694829\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000234\tLoss Attacker: 0.692217\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000316\tLoss Attacker: 0.692314\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000290\tLoss Attacker: 0.695091\n",
      "epoch 219\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000262\tLoss Attacker: 0.692893\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000289\tLoss Attacker: 0.694956\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000348\tLoss Attacker: 0.693207\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000657\tLoss Attacker: 0.694464\n",
      "epoch 220\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000233\tLoss Attacker: 0.693141\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000890\tLoss Attacker: 0.695105\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000240\tLoss Attacker: 0.692669\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000347\tLoss Attacker: 0.691395\n",
      "epoch 221\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000197\tLoss Attacker: 0.692780\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000460\tLoss Attacker: 0.692055\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000297\tLoss Attacker: 0.692770\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000421\tLoss Attacker: 0.691928\n",
      "epoch 222\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000526\tLoss Attacker: 0.692631\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000269\tLoss Attacker: 0.693026\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000354\tLoss Attacker: 0.693213\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000532\tLoss Attacker: 0.693724\n",
      "epoch 223\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000252\tLoss Attacker: 0.694496\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000500\tLoss Attacker: 0.693137\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000393\tLoss Attacker: 0.693076\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000293\tLoss Attacker: 0.693820\n",
      "epoch 224\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000260\tLoss Attacker: 0.692581\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000233\tLoss Attacker: 0.692948\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000304\tLoss Attacker: 0.693375\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000331\tLoss Attacker: 0.692895\n",
      "epoch 225\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000381\tLoss Attacker: 0.691098\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000542\tLoss Attacker: 0.692439\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000339\tLoss Attacker: 0.692636\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000318\tLoss Attacker: 0.693245\n",
      "epoch 226\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000286\tLoss Attacker: 0.693572\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000292\tLoss Attacker: 0.695166\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000330\tLoss Attacker: 0.692008\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000307\tLoss Attacker: 0.692135\n",
      "epoch 227\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000291\tLoss Attacker: 0.693928\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000298\tLoss Attacker: 0.691875\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000235\tLoss Attacker: 0.692935\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000307\tLoss Attacker: 0.691666\n",
      "epoch 228\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000307\tLoss Attacker: 0.693731\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000218\tLoss Attacker: 0.692704\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000229\tLoss Attacker: 0.692685\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000224\tLoss Attacker: 0.693991\n",
      "epoch 229\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000540\tLoss Attacker: 0.693120\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000399\tLoss Attacker: 0.692429\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000529\tLoss Attacker: 0.694786\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000562\tLoss Attacker: 0.693294\n",
      "epoch 230\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000594\tLoss Attacker: 0.693903\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000341\tLoss Attacker: 0.693202\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000207\tLoss Attacker: 0.693437\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000299\tLoss Attacker: 0.691300\n",
      "epoch 231\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000332\tLoss Attacker: 0.693849\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000254\tLoss Attacker: 0.692644\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000275\tLoss Attacker: 0.693433\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000245\tLoss Attacker: 0.692701\n",
      "epoch 232\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000472\tLoss Attacker: 0.694095\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000305\tLoss Attacker: 0.692795\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000599\tLoss Attacker: 0.693312\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000343\tLoss Attacker: 0.694663\n",
      "epoch 233\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000306\tLoss Attacker: 0.692872\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000307\tLoss Attacker: 0.693842\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000282\tLoss Attacker: 0.691670\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000251\tLoss Attacker: 0.692955\n",
      "epoch 234\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000373\tLoss Attacker: 0.694562\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000307\tLoss Attacker: 0.694410\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000538\tLoss Attacker: 0.694917\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000283\tLoss Attacker: 0.690884\n",
      "epoch 235\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000353\tLoss Attacker: 0.691660\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000258\tLoss Attacker: 0.692906\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000369\tLoss Attacker: 0.691218\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000308\tLoss Attacker: 0.694604\n",
      "epoch 236\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000204\tLoss Attacker: 0.693674\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000324\tLoss Attacker: 0.692698\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000236\tLoss Attacker: 0.691461\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000412\tLoss Attacker: 0.691634\n",
      "epoch 237\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000271\tLoss Attacker: 0.695161\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000279\tLoss Attacker: 0.694223\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000267\tLoss Attacker: 0.694918\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000337\tLoss Attacker: 0.692530\n",
      "epoch 238\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000421\tLoss Attacker: 0.695664\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000305\tLoss Attacker: 0.693763\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000369\tLoss Attacker: 0.695539\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000343\tLoss Attacker: 0.693855\n",
      "epoch 239\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000336\tLoss Attacker: 0.693859\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000297\tLoss Attacker: 0.691477\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000266\tLoss Attacker: 0.691749\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000347\tLoss Attacker: 0.693828\n",
      "epoch 240\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000250\tLoss Attacker: 0.691867\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000305\tLoss Attacker: 0.693593\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000571\tLoss Attacker: 0.693494\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000275\tLoss Attacker: 0.693371\n",
      "epoch 241\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000282\tLoss Attacker: 0.692960\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000267\tLoss Attacker: 0.694125\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000324\tLoss Attacker: 0.692488\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000455\tLoss Attacker: 0.693405\n",
      "epoch 242\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000349\tLoss Attacker: 0.693392\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000462\tLoss Attacker: 0.694577\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000370\tLoss Attacker: 0.692228\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000355\tLoss Attacker: 0.692918\n",
      "epoch 243\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000308\tLoss Attacker: 0.691000\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000330\tLoss Attacker: 0.691738\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000390\tLoss Attacker: 0.692366\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000386\tLoss Attacker: 0.693242\n",
      "epoch 244\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000409\tLoss Attacker: 0.693548\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000690\tLoss Attacker: 0.696105\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000632\tLoss Attacker: 0.692417\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000327\tLoss Attacker: 0.692811\n",
      "epoch 245\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000392\tLoss Attacker: 0.692343\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000366\tLoss Attacker: 0.693971\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000679\tLoss Attacker: 0.692462\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000347\tLoss Attacker: 0.691928\n",
      "epoch 246\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000280\tLoss Attacker: 0.694535\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000192\tLoss Attacker: 0.691593\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000264\tLoss Attacker: 0.693678\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000324\tLoss Attacker: 0.692229\n",
      "epoch 247\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000327\tLoss Attacker: 0.692509\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000211\tLoss Attacker: 0.693289\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000200\tLoss Attacker: 0.693287\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000313\tLoss Attacker: 0.693336\n",
      "epoch 248\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000329\tLoss Attacker: 0.693927\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000265\tLoss Attacker: 0.692401\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000329\tLoss Attacker: 0.692609\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000307\tLoss Attacker: 0.693183\n",
      "epoch 249\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000340\tLoss Attacker: 0.694928\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000208\tLoss Attacker: 0.692791\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000345\tLoss Attacker: 0.692721\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000564\tLoss Attacker: 0.691581\n",
      "epoch 250\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000241\tLoss Attacker: 0.692482\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000361\tLoss Attacker: 0.693604\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000150\tLoss Attacker: 0.692150\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000272\tLoss Attacker: 0.693433\n",
      "epoch 251\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000238\tLoss Attacker: 0.694150\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000451\tLoss Attacker: 0.691554\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000282\tLoss Attacker: 0.691525\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000323\tLoss Attacker: 0.695117\n",
      "epoch 252\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000355\tLoss Attacker: 0.694099\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000274\tLoss Attacker: 0.693985\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000182\tLoss Attacker: 0.692730\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000349\tLoss Attacker: 0.692414\n",
      "epoch 253\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000366\tLoss Attacker: 0.694891\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000348\tLoss Attacker: 0.692836\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000307\tLoss Attacker: 0.693764\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000248\tLoss Attacker: 0.693982\n",
      "epoch 254\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000328\tLoss Attacker: 0.694535\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000260\tLoss Attacker: 0.692549\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000420\tLoss Attacker: 0.695845\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000306\tLoss Attacker: 0.694534\n",
      "epoch 255\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000269\tLoss Attacker: 0.690789\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000445\tLoss Attacker: 0.694350\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000239\tLoss Attacker: 0.693500\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000535\tLoss Attacker: 0.693472\n",
      "epoch 256\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000223\tLoss Attacker: 0.693427\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000274\tLoss Attacker: 0.690817\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000493\tLoss Attacker: 0.693601\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000291\tLoss Attacker: 0.693471\n",
      "epoch 257\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000281\tLoss Attacker: 0.693137\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000363\tLoss Attacker: 0.692153\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000253\tLoss Attacker: 0.692410\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000247\tLoss Attacker: 0.693308\n",
      "epoch 258\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000287\tLoss Attacker: 0.694409\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000321\tLoss Attacker: 0.692596\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000702\tLoss Attacker: 0.692202\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000274\tLoss Attacker: 0.693264\n",
      "epoch 259\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000283\tLoss Attacker: 0.692454\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000238\tLoss Attacker: 0.693159\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000363\tLoss Attacker: 0.693658\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000234\tLoss Attacker: 0.693688\n",
      "epoch 260\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000346\tLoss Attacker: 0.693114\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000293\tLoss Attacker: 0.691916\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000261\tLoss Attacker: 0.692385\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000278\tLoss Attacker: 0.691925\n",
      "epoch 261\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000286\tLoss Attacker: 0.694838\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000174\tLoss Attacker: 0.692388\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000267\tLoss Attacker: 0.692722\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000716\tLoss Attacker: 0.692744\n",
      "epoch 262\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000293\tLoss Attacker: 0.693859\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000292\tLoss Attacker: 0.693469\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000188\tLoss Attacker: 0.694126\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000319\tLoss Attacker: 0.693403\n",
      "epoch 263\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000320\tLoss Attacker: 0.691995\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000430\tLoss Attacker: 0.693531\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000800\tLoss Attacker: 0.693660\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000252\tLoss Attacker: 0.692627\n",
      "epoch 264\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000315\tLoss Attacker: 0.695847\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000287\tLoss Attacker: 0.693475\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000396\tLoss Attacker: 0.693259\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000360\tLoss Attacker: 0.693883\n",
      "epoch 265\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000271\tLoss Attacker: 0.692592\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000284\tLoss Attacker: 0.694243\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000348\tLoss Attacker: 0.693274\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000217\tLoss Attacker: 0.692107\n",
      "epoch 266\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000258\tLoss Attacker: 0.694206\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000179\tLoss Attacker: 0.693713\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000314\tLoss Attacker: 0.692257\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000307\tLoss Attacker: 0.693681\n",
      "epoch 267\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000232\tLoss Attacker: 0.692078\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000278\tLoss Attacker: 0.692009\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000217\tLoss Attacker: 0.695034\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000346\tLoss Attacker: 0.694167\n",
      "epoch 268\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000234\tLoss Attacker: 0.693055\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000262\tLoss Attacker: 0.692637\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000380\tLoss Attacker: 0.692455\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000393\tLoss Attacker: 0.692924\n",
      "epoch 269\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000246\tLoss Attacker: 0.692421\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000394\tLoss Attacker: 0.693962\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000570\tLoss Attacker: 0.693943\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000389\tLoss Attacker: 0.690860\n",
      "epoch 270\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000273\tLoss Attacker: 0.694094\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000248\tLoss Attacker: 0.693862\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000361\tLoss Attacker: 0.692833\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000272\tLoss Attacker: 0.694091\n",
      "epoch 271\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000461\tLoss Attacker: 0.693807\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000278\tLoss Attacker: 0.693678\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000204\tLoss Attacker: 0.692064\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000275\tLoss Attacker: 0.690370\n",
      "epoch 272\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000293\tLoss Attacker: 0.693320\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000283\tLoss Attacker: 0.694267\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000242\tLoss Attacker: 0.693334\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000246\tLoss Attacker: 0.693314\n",
      "epoch 273\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000332\tLoss Attacker: 0.694870\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000278\tLoss Attacker: 0.693800\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000251\tLoss Attacker: 0.692863\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000504\tLoss Attacker: 0.694378\n",
      "epoch 274\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000422\tLoss Attacker: 0.692426\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000273\tLoss Attacker: 0.693193\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000292\tLoss Attacker: 0.691903\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000511\tLoss Attacker: 0.694147\n",
      "epoch 275\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000317\tLoss Attacker: 0.692429\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000284\tLoss Attacker: 0.695141\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000436\tLoss Attacker: 0.693582\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000377\tLoss Attacker: 0.693240\n",
      "epoch 276\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000289\tLoss Attacker: 0.691862\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000212\tLoss Attacker: 0.692795\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000298\tLoss Attacker: 0.692741\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000332\tLoss Attacker: 0.694885\n",
      "epoch 277\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000352\tLoss Attacker: 0.694295\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000231\tLoss Attacker: 0.693574\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000277\tLoss Attacker: 0.692034\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000275\tLoss Attacker: 0.692059\n",
      "epoch 278\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000349\tLoss Attacker: 0.693045\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000294\tLoss Attacker: 0.694018\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000247\tLoss Attacker: 0.693883\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000334\tLoss Attacker: 0.695418\n",
      "epoch 279\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000298\tLoss Attacker: 0.694090\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000245\tLoss Attacker: 0.691695\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000392\tLoss Attacker: 0.694865\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000727\tLoss Attacker: 0.693495\n",
      "epoch 280\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000291\tLoss Attacker: 0.692951\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000224\tLoss Attacker: 0.692542\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000256\tLoss Attacker: 0.693689\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000312\tLoss Attacker: 0.692689\n",
      "epoch 281\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000269\tLoss Attacker: 0.693900\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000417\tLoss Attacker: 0.692788\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000422\tLoss Attacker: 0.694978\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000280\tLoss Attacker: 0.692467\n",
      "epoch 282\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000276\tLoss Attacker: 0.694088\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000314\tLoss Attacker: 0.692738\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000214\tLoss Attacker: 0.691386\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000367\tLoss Attacker: 0.693342\n",
      "epoch 283\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000296\tLoss Attacker: 0.692953\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000337\tLoss Attacker: 0.692846\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000300\tLoss Attacker: 0.692507\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000389\tLoss Attacker: 0.693316\n",
      "epoch 284\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000290\tLoss Attacker: 0.695258\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000265\tLoss Attacker: 0.692500\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000322\tLoss Attacker: 0.694454\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000294\tLoss Attacker: 0.692782\n",
      "epoch 285\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000272\tLoss Attacker: 0.691944\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000212\tLoss Attacker: 0.694724\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000489\tLoss Attacker: 0.691658\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000423\tLoss Attacker: 0.692365\n",
      "epoch 286\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000355\tLoss Attacker: 0.693489\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000293\tLoss Attacker: 0.693106\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000418\tLoss Attacker: 0.692184\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000271\tLoss Attacker: 0.692394\n",
      "epoch 287\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000252\tLoss Attacker: 0.691724\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000402\tLoss Attacker: 0.692897\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000328\tLoss Attacker: 0.693717\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000496\tLoss Attacker: 0.693087\n",
      "epoch 288\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000302\tLoss Attacker: 0.692368\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000209\tLoss Attacker: 0.692617\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000393\tLoss Attacker: 0.692282\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000501\tLoss Attacker: 0.691988\n",
      "epoch 289\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000288\tLoss Attacker: 0.693530\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000280\tLoss Attacker: 0.692794\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000269\tLoss Attacker: 0.692890\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000481\tLoss Attacker: 0.693650\n",
      "epoch 290\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000243\tLoss Attacker: 0.693073\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000345\tLoss Attacker: 0.692051\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000266\tLoss Attacker: 0.692206\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000436\tLoss Attacker: 0.692269\n",
      "epoch 291\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000259\tLoss Attacker: 0.692476\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000231\tLoss Attacker: 0.691166\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000259\tLoss Attacker: 0.692930\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000544\tLoss Attacker: 0.693428\n",
      "epoch 292\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000263\tLoss Attacker: 0.692585\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000583\tLoss Attacker: 0.693819\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000378\tLoss Attacker: 0.692379\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000424\tLoss Attacker: 0.693236\n",
      "epoch 293\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000304\tLoss Attacker: 0.694086\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000497\tLoss Attacker: 0.694239\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000232\tLoss Attacker: 0.692946\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000226\tLoss Attacker: 0.692323\n",
      "epoch 294\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000243\tLoss Attacker: 0.693338\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000325\tLoss Attacker: 0.693839\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000264\tLoss Attacker: 0.692487\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000203\tLoss Attacker: 0.692922\n",
      "epoch 295\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000279\tLoss Attacker: 0.693372\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000264\tLoss Attacker: 0.694126\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000763\tLoss Attacker: 0.693053\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000557\tLoss Attacker: 0.694404\n",
      "epoch 296\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000323\tLoss Attacker: 0.694185\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000288\tLoss Attacker: 0.693978\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000275\tLoss Attacker: 0.692244\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000255\tLoss Attacker: 0.691380\n",
      "epoch 297\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000247\tLoss Attacker: 0.692916\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000280\tLoss Attacker: 0.691735\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000333\tLoss Attacker: 0.692641\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000308\tLoss Attacker: 0.691921\n",
      "epoch 298\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000351\tLoss Attacker: 0.692589\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000318\tLoss Attacker: 0.693272\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000437\tLoss Attacker: 0.691944\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000332\tLoss Attacker: 0.693377\n",
      "epoch 299\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss Classifier: 0.000309\tLoss Attacker: 0.691151\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss Classifier: 0.000311\tLoss Attacker: 0.691494\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss Classifier: 0.000331\tLoss Attacker: 0.693434\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss Classifier: 0.000572\tLoss Attacker: 0.692538\n"
     ]
    }
   ],
   "source": [
    "FE=get_FE_defense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train attacker after applying our defense\n",
    "atk_criterion = nn.BCEWithLogitsLoss().to(device)\n",
    "train_loss = []\n",
    "test_loss = []\n",
    "test_acc = []\n",
    "def train_attacker_defense(FE, INF, data_train_loader, current_lr,device, vis=None):\n",
    "    INF.train()\n",
    "    #FE_optimizer = optim.Adam(FE.parameters(), lr=current_lr, weight_decay=1e-4)\n",
    "    INF_optimizer = optim.Adam(INF.parameters(), lr=current_lr, weight_decay=1e-4)\n",
    "\n",
    "    loss_INF = 0\n",
    "    running_precision=0\n",
    "    running_recall=0\n",
    "    #freezing the FE\n",
    "    freeze(FE)\n",
    "    for i,(X, (y1, y2)) in enumerate(data_train_loader):\n",
    "        #if torch.cuda.is_available():\n",
    "        X, y1,y2= X.to(device), y1.to(device),y2.to(device)\n",
    "\n",
    "        features = FE(X)\n",
    "        # feed them to the inf model\n",
    "        pred_private_labels = INF(features)\n",
    "        #y2=y2.float()\n",
    "        y2 = y2.unsqueeze(1)\n",
    "        loss_INF =atk_criterion(pred_private_labels,y2.float())\n",
    "        precision, recall = get_precision_recall(pred_private_labels,y2)\n",
    "        #FE_optimizer.zero_grad()\n",
    "        INF_optimizer.zero_grad()\n",
    "        loss_INF.backward()\n",
    "        INF_optimizer.step()\n",
    "        #FE_optimizer.step()\n",
    "\n",
    "        running_precision+= precision\n",
    "        running_recall += recall\n",
    "        \n",
    "        if i % 100 == 0:\n",
    "            print('Epoch: {} [{}/{} ({:.0f}%)]\\tLoss attacker: {:.6f}\\t Precision attacker: {:.6f}\\t recall attacler: {:.6f}\\t'.format(\n",
    "                i, i * len(X), len(data_train_loader.dataset),\n",
    "                100. * i / len(data_train_loader), loss_INF.item(),\n",
    "                running_precision/100,\n",
    "                running_recall/100\n",
    "                 ))\n",
    "        running_recall=0\n",
    "        running_precision=0\n",
    "    unfreeze(FE)\n",
    "\n",
    "    return  INF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "INF_test_loss=[]\n",
    "INF_test_acc=[]\n",
    "loss_fn = nn.BCEWithLogitsLoss().to(device)\n",
    "def test_attacker_defense(FE, INF_model, data_test_loader,device):\n",
    "    FE.eval()\n",
    "    INF_model.eval()\n",
    "\n",
    "    avg_loss = 0\n",
    "    avg_acc = 0\n",
    "    counter = 0\n",
    "    #total_samples = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (X,(y1,y2)) in enumerate(data_test_loader):\n",
    "            #if torch.cuda.is_available():\n",
    "            X,y1,y2=X.to(device),y1.to(device),y2.to(device)\n",
    "            features = FE(X)\n",
    "            output = INF_model(features)\n",
    "            #print(output)\n",
    "            y2= y2.unsqueeze(1)\n",
    "            #print(y2)\n",
    "            avg_loss += loss_fn(output, y2.float()).sum()\n",
    "            pred = output.detach() > 0.5\n",
    "            avg_acc += pred.eq(y2.view_as(pred)).sum()\n",
    "            counter += 1\n",
    "            #total_samples +=X.shape[0]\n",
    "            \n",
    "    avg_loss /= counter\n",
    "    avg_loss = avg_loss.detach().cpu().item()\n",
    "    #print(privlabels)\n",
    "    avg_acc = float(avg_acc) / len(data_test_loader)\n",
    "    print('Test Avg. Loss: %f, Accuracy: %f' % (avg_loss, avg_acc))\n",
    "    INF_test_loss.append(avg_loss)\n",
    "    INF_test_acc.append(avg_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_epoch=100\n",
    "lr=0.000003\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "def get_INF_defense():\n",
    "    FE = torch.load(fe_model_file_defense)\n",
    "    #INF= AlexNet_attacker()\n",
    "    INF=torch.load(inf_model_file)\n",
    "    if torch.cuda.is_available():\n",
    "        FE = FE.cuda()\n",
    "        INF = INF.cuda()\n",
    "    try:\n",
    "        for epoch in range(total_epoch):\n",
    "            print(\"epoch %d\" % epoch)\n",
    "            current_lr = adjust_learning_rate(epoch,lr)\n",
    "            INF = train_attacker_defense(FE, INF, atk_train_dl, current_lr, device,vis=None)\n",
    "            test_attacker_defense(FE, INF, atk_test_dl,device)\n",
    "    except KeyboardInterrupt:\n",
    "        pass\n",
    "\n",
    "    return FE,INF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss attacker: 0.757202\t Precision attacker: 0.002650\t recall attacler: 0.005000\t\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss attacker: 0.747085\t Precision attacker: 0.002800\t recall attacler: 0.005000\t\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss attacker: 0.721890\t Precision attacker: 0.002500\t recall attacler: 0.005000\t\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss attacker: 0.700098\t Precision attacker: 0.002250\t recall attacler: 0.005000\t\n",
      "Test Avg. Loss: 0.714098, Accuracy: 51.850000\n",
      "epoch 1\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss attacker: 0.755504\t Precision attacker: 0.002350\t recall attacler: 0.005000\t\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss attacker: 0.715439\t Precision attacker: 0.002450\t recall attacler: 0.005000\t\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss attacker: 0.699373\t Precision attacker: 0.002250\t recall attacler: 0.005000\t\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss attacker: 0.677481\t Precision attacker: 0.002150\t recall attacler: 0.005000\t\n",
      "Test Avg. Loss: 0.711892, Accuracy: 51.190000\n",
      "epoch 2\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss attacker: 0.703327\t Precision attacker: 0.002650\t recall attacler: 0.005000\t\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss attacker: 0.699609\t Precision attacker: 0.002250\t recall attacler: 0.005000\t\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss attacker: 0.734282\t Precision attacker: 0.002600\t recall attacler: 0.005000\t\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss attacker: 0.727173\t Precision attacker: 0.002500\t recall attacler: 0.005000\t\n",
      "Test Avg. Loss: 0.708457, Accuracy: 51.080000\n",
      "epoch 3\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss attacker: 0.665132\t Precision attacker: 0.002200\t recall attacler: 0.005000\t\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss attacker: 0.703564\t Precision attacker: 0.002600\t recall attacler: 0.005000\t\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss attacker: 0.726039\t Precision attacker: 0.002700\t recall attacler: 0.005000\t\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss attacker: 0.755095\t Precision attacker: 0.002700\t recall attacler: 0.005000\t\n",
      "Test Avg. Loss: 0.707319, Accuracy: 51.020000\n",
      "epoch 4\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss attacker: 0.698187\t Precision attacker: 0.002550\t recall attacler: 0.005000\t\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss attacker: 0.742692\t Precision attacker: 0.002350\t recall attacler: 0.005000\t\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss attacker: 0.734074\t Precision attacker: 0.002600\t recall attacler: 0.005000\t\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss attacker: 0.728152\t Precision attacker: 0.002600\t recall attacler: 0.005000\t\n",
      "Test Avg. Loss: 0.707104, Accuracy: 50.890000\n",
      "epoch 5\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss attacker: 0.686628\t Precision attacker: 0.002150\t recall attacler: 0.005000\t\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss attacker: 0.759097\t Precision attacker: 0.002400\t recall attacler: 0.005000\t\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss attacker: 0.694056\t Precision attacker: 0.002450\t recall attacler: 0.005000\t\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss attacker: 0.702019\t Precision attacker: 0.002650\t recall attacler: 0.005000\t\n",
      "Test Avg. Loss: 0.704621, Accuracy: 51.280000\n",
      "epoch 6\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss attacker: 0.663134\t Precision attacker: 0.002400\t recall attacler: 0.005000\t\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss attacker: 0.735639\t Precision attacker: 0.002500\t recall attacler: 0.005000\t\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss attacker: 0.676447\t Precision attacker: 0.002550\t recall attacler: 0.005000\t\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss attacker: 0.726808\t Precision attacker: 0.002450\t recall attacler: 0.005000\t\n",
      "Test Avg. Loss: 0.705285, Accuracy: 50.960000\n",
      "epoch 7\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss attacker: 0.684666\t Precision attacker: 0.002100\t recall attacler: 0.005000\t\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss attacker: 0.706904\t Precision attacker: 0.002350\t recall attacler: 0.005000\t\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss attacker: 0.693954\t Precision attacker: 0.002550\t recall attacler: 0.005000\t\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss attacker: 0.715369\t Precision attacker: 0.002650\t recall attacler: 0.005000\t\n",
      "Test Avg. Loss: 0.704930, Accuracy: 50.890000\n",
      "epoch 8\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss attacker: 0.724378\t Precision attacker: 0.002550\t recall attacler: 0.005000\t\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss attacker: 0.711850\t Precision attacker: 0.002050\t recall attacler: 0.005000\t\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss attacker: 0.684346\t Precision attacker: 0.002300\t recall attacler: 0.005000\t\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss attacker: 0.734794\t Precision attacker: 0.002250\t recall attacler: 0.005000\t\n",
      "Test Avg. Loss: 0.704731, Accuracy: 50.840000\n",
      "epoch 9\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss attacker: 0.705113\t Precision attacker: 0.002150\t recall attacler: 0.005000\t\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss attacker: 0.725044\t Precision attacker: 0.003000\t recall attacler: 0.005000\t\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss attacker: 0.703687\t Precision attacker: 0.002400\t recall attacler: 0.005000\t\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss attacker: 0.706841\t Precision attacker: 0.002700\t recall attacler: 0.005000\t\n",
      "Test Avg. Loss: 0.702788, Accuracy: 50.710000\n",
      "epoch 10\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss attacker: 0.716846\t Precision attacker: 0.002850\t recall attacler: 0.005000\t\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss attacker: 0.681834\t Precision attacker: 0.001750\t recall attacler: 0.005000\t\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss attacker: 0.723143\t Precision attacker: 0.003250\t recall attacler: 0.005000\t\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss attacker: 0.716320\t Precision attacker: 0.002450\t recall attacler: 0.005000\t\n",
      "Test Avg. Loss: 0.704593, Accuracy: 50.770000\n",
      "epoch 11\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss attacker: 0.707810\t Precision attacker: 0.002100\t recall attacler: 0.005000\t\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss attacker: 0.708123\t Precision attacker: 0.002750\t recall attacler: 0.005000\t\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss attacker: 0.709640\t Precision attacker: 0.002450\t recall attacler: 0.005000\t\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss attacker: 0.747354\t Precision attacker: 0.002750\t recall attacler: 0.005000\t\n",
      "Test Avg. Loss: 0.703786, Accuracy: 50.600000\n",
      "epoch 12\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss attacker: 0.668715\t Precision attacker: 0.002450\t recall attacler: 0.005000\t\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss attacker: 0.715850\t Precision attacker: 0.002450\t recall attacler: 0.005000\t\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss attacker: 0.712511\t Precision attacker: 0.002450\t recall attacler: 0.005000\t\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss attacker: 0.730595\t Precision attacker: 0.002700\t recall attacler: 0.005000\t\n",
      "Test Avg. Loss: 0.703594, Accuracy: 50.560000\n",
      "epoch 13\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss attacker: 0.684437\t Precision attacker: 0.002000\t recall attacler: 0.005000\t\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss attacker: 0.674678\t Precision attacker: 0.002350\t recall attacler: 0.005000\t\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss attacker: 0.695034\t Precision attacker: 0.002450\t recall attacler: 0.005000\t\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss attacker: 0.695172\t Precision attacker: 0.002700\t recall attacler: 0.005000\t\n",
      "Test Avg. Loss: 0.702532, Accuracy: 50.450000\n",
      "epoch 14\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss attacker: 0.696024\t Precision attacker: 0.002400\t recall attacler: 0.005000\t\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss attacker: 0.699067\t Precision attacker: 0.002750\t recall attacler: 0.005000\t\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss attacker: 0.704949\t Precision attacker: 0.002400\t recall attacler: 0.005000\t\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss attacker: 0.705847\t Precision attacker: 0.002200\t recall attacler: 0.005000\t\n",
      "Test Avg. Loss: 0.703441, Accuracy: 50.510000\n",
      "epoch 15\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss attacker: 0.692996\t Precision attacker: 0.002450\t recall attacler: 0.005000\t\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss attacker: 0.679170\t Precision attacker: 0.002550\t recall attacler: 0.005000\t\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss attacker: 0.701038\t Precision attacker: 0.002400\t recall attacler: 0.005000\t\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss attacker: 0.706613\t Precision attacker: 0.002500\t recall attacler: 0.005000\t\n",
      "Test Avg. Loss: 0.703707, Accuracy: 50.420000\n",
      "epoch 16\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss attacker: 0.692360\t Precision attacker: 0.002550\t recall attacler: 0.005000\t\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss attacker: 0.714678\t Precision attacker: 0.002550\t recall attacler: 0.005000\t\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss attacker: 0.697122\t Precision attacker: 0.002350\t recall attacler: 0.005000\t\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss attacker: 0.702682\t Precision attacker: 0.002500\t recall attacler: 0.005000\t\n",
      "Test Avg. Loss: 0.703679, Accuracy: 50.470000\n",
      "epoch 17\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss attacker: 0.733243\t Precision attacker: 0.002800\t recall attacler: 0.005000\t\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss attacker: 0.711389\t Precision attacker: 0.002250\t recall attacler: 0.005000\t\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss attacker: 0.723400\t Precision attacker: 0.002750\t recall attacler: 0.005000\t\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss attacker: 0.701919\t Precision attacker: 0.002450\t recall attacler: 0.005000\t\n",
      "Test Avg. Loss: 0.703418, Accuracy: 50.480000\n",
      "epoch 18\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss attacker: 0.701832\t Precision attacker: 0.002650\t recall attacler: 0.005000\t\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss attacker: 0.682976\t Precision attacker: 0.002300\t recall attacler: 0.005000\t\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss attacker: 0.695799\t Precision attacker: 0.002700\t recall attacler: 0.005000\t\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss attacker: 0.694747\t Precision attacker: 0.002250\t recall attacler: 0.005000\t\n",
      "Test Avg. Loss: 0.703233, Accuracy: 50.540000\n",
      "epoch 19\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss attacker: 0.697995\t Precision attacker: 0.002550\t recall attacler: 0.005000\t\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss attacker: 0.722335\t Precision attacker: 0.002550\t recall attacler: 0.005000\t\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss attacker: 0.692370\t Precision attacker: 0.002500\t recall attacler: 0.005000\t\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss attacker: 0.721139\t Precision attacker: 0.002550\t recall attacler: 0.005000\t\n",
      "Test Avg. Loss: 0.703202, Accuracy: 50.490000\n",
      "epoch 20\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss attacker: 0.699302\t Precision attacker: 0.002550\t recall attacler: 0.005000\t\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss attacker: 0.720893\t Precision attacker: 0.002700\t recall attacler: 0.005000\t\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss attacker: 0.703986\t Precision attacker: 0.002450\t recall attacler: 0.005000\t\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss attacker: 0.697252\t Precision attacker: 0.002750\t recall attacler: 0.005000\t\n",
      "Test Avg. Loss: 0.703440, Accuracy: 50.560000\n",
      "epoch 21\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss attacker: 0.680465\t Precision attacker: 0.002400\t recall attacler: 0.005000\t\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss attacker: 0.706511\t Precision attacker: 0.002500\t recall attacler: 0.005000\t\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss attacker: 0.693282\t Precision attacker: 0.002700\t recall attacler: 0.005000\t\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss attacker: 0.676382\t Precision attacker: 0.001800\t recall attacler: 0.005000\t\n",
      "Test Avg. Loss: 0.702916, Accuracy: 50.460000\n",
      "epoch 22\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss attacker: 0.720681\t Precision attacker: 0.002400\t recall attacler: 0.005000\t\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss attacker: 0.701108\t Precision attacker: 0.002250\t recall attacler: 0.005000\t\n",
      "Epoch: 200 [20000/50000 (50%)]\tLoss attacker: 0.680702\t Precision attacker: 0.002600\t recall attacler: 0.005000\t\n",
      "Epoch: 300 [30000/50000 (75%)]\tLoss attacker: 0.712870\t Precision attacker: 0.002750\t recall attacler: 0.005000\t\n",
      "Test Avg. Loss: 0.703336, Accuracy: 50.520000\n",
      "epoch 23\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss attacker: 0.694638\t Precision attacker: 0.002700\t recall attacler: 0.005000\t\n",
      "Epoch: 100 [10000/50000 (25%)]\tLoss attacker: 0.700157\t Precision attacker: 0.002050\t recall attacler: 0.005000\t\n"
     ]
    }
   ],
   "source": [
    "FE,INF = get_INF_defense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train classifier after applying our defense\n",
    "clf_criterion = nn.CrossEntropyLoss().to(device)\n",
    "train_loss = []\n",
    "test_loss = []\n",
    "test_acc = []\n",
    "def train_classifier_defense(FE, CF, data_train_loader, current_lr,device, vis=None):\n",
    "    CF.train()\n",
    "    #FE_optimizer = optim.Adam(FE.parameters(), lr=current_lr, weight_decay=1e-4)\n",
    "    CF_optimizer = optim.Adam(CF.parameters(), lr=current_lr, weight_decay=1e-4)\n",
    "\n",
    "    loss_CF = 0\n",
    "    running_precision=0\n",
    "    running_recall=0\n",
    "    #freezing the FE\n",
    "    freeze(FE)\n",
    "    for i,(X, y) in enumerate(clf_train_dl):\n",
    "        #if torch.cuda.is_available():\n",
    "        X, y= X.to(device), y.to(device)\n",
    "\n",
    "        features = FE(X)\n",
    "        # feed them to the inf model\n",
    "        out_CF=CF(features)\n",
    "        #pred_private_labels= torch.round(pred_private_labels)\n",
    "        #y2=y2.float()\n",
    "        #y = y.unsqueeze(1)\n",
    "        loss_CF =clf_criterion(out_CF,y)\n",
    "        precision, recall = get_precision_recall(out_CF,y)\n",
    "        #FE_optimizer.zero_grad()\n",
    "        CF_optimizer.zero_grad()\n",
    "        loss_CF.backward()\n",
    "        CF_optimizer.step()\n",
    "        #FE_optimizer.step()\n",
    "\n",
    "        running_precision+= precision\n",
    "        running_recall += recall\n",
    "        \n",
    "        if i % 100 == 0:\n",
    "            print('Epoch: {} [{}/{} ({:.0f}%)]\\tLoss classifier: {:.6f}\\t Precision classifier: {:.6f}\\t recall classifier: {:.6f}\\t'.format(\n",
    "                i, i * len(X), len(data_train_loader.dataset),\n",
    "                100. * i / len(data_train_loader), loss_CF.item(),\n",
    "                running_precision/100,\n",
    "                running_recall/100\n",
    "                 ))\n",
    "        running_recall=0\n",
    "        running_precision=0\n",
    "    unfreeze(FE)\n",
    "\n",
    "    return  CF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_clf_defense(fe, clf, clf_test_dl, clf_criterion, device):\n",
    "    fe.eval()\n",
    "    clf.eval()\n",
    "    acc = torchmetrics.Accuracy().to(device)\n",
    "    loss = []\n",
    "    with torch.no_grad():\n",
    "        for (X, y) in clf_test_dl:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            features = fe(X)\n",
    "            clf_y = clf(features)\n",
    "            loss.append(clf_criterion(clf_y, y).item())\n",
    "            acc(clf_y, y)\n",
    "    loss = np.asarray(loss).mean()\n",
    "    print(f'Classifier Loss: {loss} | Classifier Accuracy: {acc.compute()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_epoch=100\n",
    "lr=3e-6\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "def get_clf_defense():\n",
    "    FE = torch.load(fe_model_file_defense)\n",
    "    #CF= AlexNet_predictor()\n",
    "    CF=torch.load(cf_model_file)\n",
    "    if torch.cuda.is_available():\n",
    "        FE = FE.cuda()\n",
    "        CF= CF.cuda()\n",
    "    try:\n",
    "        for epoch in range(total_epoch):\n",
    "            print(\"epoch %d\" % epoch)\n",
    "            current_lr = adjust_learning_rate(epoch, lr)\n",
    "            CF= train_classifier_defense(FE, CF, clf_train_dl, current_lr, device,vis=None)\n",
    "            eval_clf_defense(FE, CF, clf_test_dl, clf_criterion, device)\n",
    "    except KeyboardInterrupt:\n",
    "        pass\n",
    "\n",
    "    return CF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss classifier: 0.219439\t Precision classifier: 0.009609\t recall classifier: 0.009714\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss classifier: 0.039296\t Precision classifier: 0.009690\t recall classifier: 0.009800\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss classifier: 0.033107\t Precision classifier: 0.009833\t recall classifier: 0.009917\t\n",
      "Classifier Loss: 1.3411289219856262 | Classifier Accuracy: 0.8073199987411499\n",
      "epoch 1\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss classifier: 0.032958\t Precision classifier: 0.009941\t recall classifier: 0.009909\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss classifier: 0.071923\t Precision classifier: 0.009784\t recall classifier: 0.009840\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss classifier: 0.002660\t Precision classifier: 0.010000\t recall classifier: 0.010000\t\n",
      "Classifier Loss: 1.346770451784134 | Classifier Accuracy: 0.8081200122833252\n",
      "epoch 2\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss classifier: 0.050213\t Precision classifier: 0.009733\t recall classifier: 0.009882\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss classifier: 0.038191\t Precision classifier: 0.009857\t recall classifier: 0.009917\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss classifier: 0.028461\t Precision classifier: 0.009889\t recall classifier: 0.009950\t\n",
      "Classifier Loss: 1.3407565605640412 | Classifier Accuracy: 0.807919979095459\n",
      "epoch 3\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss classifier: 0.017630\t Precision classifier: 0.010000\t recall classifier: 0.010000\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss classifier: 0.002750\t Precision classifier: 0.010000\t recall classifier: 0.010000\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss classifier: 0.064416\t Precision classifier: 0.009757\t recall classifier: 0.009900\t\n",
      "Classifier Loss: 1.324008514881134 | Classifier Accuracy: 0.8082399964332581\n",
      "epoch 4\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss classifier: 0.028641\t Precision classifier: 0.009917\t recall classifier: 0.009875\t\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\leily\\anaconda3\\envs\\py36\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 100 [10000/50000 (40%)]\tLoss classifier: 0.003024\t Precision classifier: 0.010000\t recall classifier: 0.010000\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss classifier: 0.028221\t Precision classifier: 0.009875\t recall classifier: 0.009833\t\n",
      "Classifier Loss: 1.3156772270202637 | Classifier Accuracy: 0.8083999752998352\n",
      "epoch 5\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss classifier: 0.035392\t Precision classifier: 0.009900\t recall classifier: 0.009917\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss classifier: 0.022343\t Precision classifier: 0.009833\t recall classifier: 0.009889\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss classifier: 0.001269\t Precision classifier: 0.010000\t recall classifier: 0.010000\t\n",
      "Classifier Loss: 1.301691398859024 | Classifier Accuracy: 0.8084400296211243\n",
      "epoch 6\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss classifier: 0.111276\t Precision classifier: 0.009845\t recall classifier: 0.009809\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss classifier: 0.031355\t Precision classifier: 0.009933\t recall classifier: 0.009909\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss classifier: 0.043712\t Precision classifier: 0.009875\t recall classifier: 0.009917\t\n",
      "Classifier Loss: 1.28330832695961 | Classifier Accuracy: 0.8087999820709229\n",
      "epoch 7\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss classifier: 0.085259\t Precision classifier: 0.009923\t recall classifier: 0.009929\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss classifier: 0.014789\t Precision classifier: 0.009947\t recall classifier: 0.009900\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss classifier: 0.079610\t Precision classifier: 0.009809\t recall classifier: 0.009847\t\n",
      "Classifier Loss: 1.2820758764743805 | Classifier Accuracy: 0.8090400099754333\n",
      "epoch 8\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss classifier: 0.001451\t Precision classifier: 0.010000\t recall classifier: 0.010000\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss classifier: 0.065411\t Precision classifier: 0.009756\t recall classifier: 0.009756\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss classifier: 0.018382\t Precision classifier: 0.010000\t recall classifier: 0.010000\t\n",
      "Classifier Loss: 1.263544723033905 | Classifier Accuracy: 0.8085600137710571\n",
      "epoch 9\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss classifier: 0.206299\t Precision classifier: 0.009603\t recall classifier: 0.009589\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss classifier: 0.024818\t Precision classifier: 0.009929\t recall classifier: 0.009833\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss classifier: 0.129508\t Precision classifier: 0.009680\t recall classifier: 0.009718\t\n",
      "Classifier Loss: 1.2564540486335753 | Classifier Accuracy: 0.80867999792099\n",
      "epoch 10\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss classifier: 0.062101\t Precision classifier: 0.009832\t recall classifier: 0.009778\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss classifier: 0.015733\t Precision classifier: 0.010000\t recall classifier: 0.010000\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss classifier: 0.049577\t Precision classifier: 0.009929\t recall classifier: 0.009917\t\n",
      "Classifier Loss: 1.2527196723222733 | Classifier Accuracy: 0.8085200190544128\n",
      "epoch 11\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss classifier: 0.039319\t Precision classifier: 0.009857\t recall classifier: 0.009923\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss classifier: 0.061644\t Precision classifier: 0.009864\t recall classifier: 0.009778\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss classifier: 0.012368\t Precision classifier: 0.010000\t recall classifier: 0.010000\t\n",
      "Classifier Loss: 1.2548225600719451 | Classifier Accuracy: 0.8083199858665466\n",
      "epoch 12\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss classifier: 0.047706\t Precision classifier: 0.009798\t recall classifier: 0.009817\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss classifier: 0.005496\t Precision classifier: 0.010000\t recall classifier: 0.010000\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss classifier: 0.086811\t Precision classifier: 0.009774\t recall classifier: 0.009866\t\n",
      "Classifier Loss: 1.2399549516439439 | Classifier Accuracy: 0.8082399964332581\n",
      "epoch 13\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss classifier: 0.018313\t Precision classifier: 0.010000\t recall classifier: 0.010000\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss classifier: 0.177256\t Precision classifier: 0.009663\t recall classifier: 0.009607\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss classifier: 0.004531\t Precision classifier: 0.010000\t recall classifier: 0.010000\t\n",
      "Classifier Loss: 1.2520425698757172 | Classifier Accuracy: 0.80867999792099\n",
      "epoch 14\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss classifier: 0.041540\t Precision classifier: 0.009826\t recall classifier: 0.009845\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss classifier: 0.003017\t Precision classifier: 0.010000\t recall classifier: 0.010000\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss classifier: 0.102162\t Precision classifier: 0.009709\t recall classifier: 0.009687\t\n",
      "Classifier Loss: 1.2479940853118896 | Classifier Accuracy: 0.8087599873542786\n",
      "epoch 15\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss classifier: 0.008546\t Precision classifier: 0.010000\t recall classifier: 0.010000\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss classifier: 0.062042\t Precision classifier: 0.009826\t recall classifier: 0.009650\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss classifier: 0.002716\t Precision classifier: 0.010000\t recall classifier: 0.010000\t\n",
      "Classifier Loss: 1.2475260481834411 | Classifier Accuracy: 0.8087599873542786\n",
      "epoch 16\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss classifier: 0.052942\t Precision classifier: 0.009809\t recall classifier: 0.009798\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss classifier: 0.021568\t Precision classifier: 0.009917\t recall classifier: 0.009667\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss classifier: 0.036236\t Precision classifier: 0.009750\t recall classifier: 0.009909\t\n",
      "Classifier Loss: 1.2351486818790436 | Classifier Accuracy: 0.8086400032043457\n",
      "epoch 17\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss classifier: 0.002740\t Precision classifier: 0.010000\t recall classifier: 0.010000\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss classifier: 0.133474\t Precision classifier: 0.009806\t recall classifier: 0.009840\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss classifier: 0.045291\t Precision classifier: 0.009923\t recall classifier: 0.009875\t\n",
      "Classifier Loss: 1.242115165233612 | Classifier Accuracy: 0.8086000084877014\n",
      "epoch 18\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss classifier: 0.074538\t Precision classifier: 0.009657\t recall classifier: 0.009662\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss classifier: 0.005560\t Precision classifier: 0.010000\t recall classifier: 0.010000\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss classifier: 0.002121\t Precision classifier: 0.010000\t recall classifier: 0.010000\t\n",
      "Classifier Loss: 1.2461437143087386 | Classifier Accuracy: 0.80867999792099\n",
      "epoch 19\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss classifier: 0.045258\t Precision classifier: 0.009789\t recall classifier: 0.009792\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss classifier: 0.021635\t Precision classifier: 0.009833\t recall classifier: 0.009923\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss classifier: 0.014061\t Precision classifier: 0.009875\t recall classifier: 0.009929\t\n",
      "Classifier Loss: 1.2395217576026916 | Classifier Accuracy: 0.8090400099754333\n",
      "epoch 20\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss classifier: 0.112187\t Precision classifier: 0.009889\t recall classifier: 0.009900\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss classifier: 0.006617\t Precision classifier: 0.010000\t recall classifier: 0.010000\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss classifier: 0.005668\t Precision classifier: 0.010000\t recall classifier: 0.010000\t\n",
      "Classifier Loss: 1.2417864863872528 | Classifier Accuracy: 0.8084400296211243\n",
      "epoch 21\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss classifier: 0.007975\t Precision classifier: 0.010000\t recall classifier: 0.010000\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss classifier: 0.002926\t Precision classifier: 0.010000\t recall classifier: 0.010000\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss classifier: 0.001801\t Precision classifier: 0.010000\t recall classifier: 0.010000\t\n",
      "Classifier Loss: 1.2442853429317475 | Classifier Accuracy: 0.8086400032043457\n",
      "epoch 22\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss classifier: 0.008468\t Precision classifier: 0.010000\t recall classifier: 0.010000\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss classifier: 0.005038\t Precision classifier: 0.010000\t recall classifier: 0.010000\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss classifier: 0.025342\t Precision classifier: 0.009909\t recall classifier: 0.009917\t\n",
      "Classifier Loss: 1.2423199875354767 | Classifier Accuracy: 0.8087599873542786\n",
      "epoch 23\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss classifier: 0.105457\t Precision classifier: 0.009756\t recall classifier: 0.009822\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss classifier: 0.010563\t Precision classifier: 0.010000\t recall classifier: 0.010000\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss classifier: 0.034134\t Precision classifier: 0.009900\t recall classifier: 0.009929\t\n",
      "Classifier Loss: 1.2364339451789856 | Classifier Accuracy: 0.8087599873542786\n",
      "epoch 24\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss classifier: 0.050367\t Precision classifier: 0.009715\t recall classifier: 0.009715\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss classifier: 0.110677\t Precision classifier: 0.009667\t recall classifier: 0.009817\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss classifier: 0.015901\t Precision classifier: 0.009929\t recall classifier: 0.009909\t\n",
      "Classifier Loss: 1.241163547039032 | Classifier Accuracy: 0.80867999792099\n",
      "epoch 25\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss classifier: 0.008243\t Precision classifier: 0.010000\t recall classifier: 0.010000\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss classifier: 0.027264\t Precision classifier: 0.009909\t recall classifier: 0.009875\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss classifier: 0.010828\t Precision classifier: 0.010000\t recall classifier: 0.010000\t\n",
      "Classifier Loss: 1.2402644848823547 | Classifier Accuracy: 0.8087199926376343\n",
      "epoch 26\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss classifier: 0.010197\t Precision classifier: 0.010000\t recall classifier: 0.010000\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss classifier: 0.128015\t Precision classifier: 0.009718\t recall classifier: 0.009714\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss classifier: 0.043814\t Precision classifier: 0.009900\t recall classifier: 0.009938\t\n",
      "Classifier Loss: 1.237305755019188 | Classifier Accuracy: 0.8088399767875671\n",
      "epoch 27\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss classifier: 0.033590\t Precision classifier: 0.009909\t recall classifier: 0.009933\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss classifier: 0.005428\t Precision classifier: 0.010000\t recall classifier: 0.010000\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss classifier: 0.113626\t Precision classifier: 0.009845\t recall classifier: 0.009817\t\n",
      "Classifier Loss: 1.2395090873241426 | Classifier Accuracy: 0.8089200258255005\n",
      "epoch 28\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss classifier: 0.042308\t Precision classifier: 0.009857\t recall classifier: 0.009857\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss classifier: 0.084451\t Precision classifier: 0.009917\t recall classifier: 0.009875\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss classifier: 0.027130\t Precision classifier: 0.009889\t recall classifier: 0.009900\t\n",
      "Classifier Loss: 1.2317379355430602 | Classifier Accuracy: 0.8091599941253662\n",
      "epoch 29\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss classifier: 0.009333\t Precision classifier: 0.010000\t recall classifier: 0.010000\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss classifier: 0.022139\t Precision classifier: 0.009867\t recall classifier: 0.009826\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss classifier: 0.133091\t Precision classifier: 0.009709\t recall classifier: 0.009687\t\n",
      "Classifier Loss: 1.2410226743221282 | Classifier Accuracy: 0.8088799715042114\n",
      "epoch 30\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss classifier: 0.021855\t Precision classifier: 0.009800\t recall classifier: 0.009938\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss classifier: 0.010679\t Precision classifier: 0.010000\t recall classifier: 0.010000\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss classifier: 0.022496\t Precision classifier: 0.009667\t recall classifier: 0.009929\t\n",
      "Classifier Loss: 1.240799421787262 | Classifier Accuracy: 0.8089200258255005\n",
      "epoch 31\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss classifier: 0.060495\t Precision classifier: 0.009798\t recall classifier: 0.009756\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss classifier: 0.093007\t Precision classifier: 0.009808\t recall classifier: 0.009722\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss classifier: 0.028322\t Precision classifier: 0.009857\t recall classifier: 0.009917\t\n",
      "Classifier Loss: 1.237394320011139 | Classifier Accuracy: 0.80867999792099\n",
      "epoch 32\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss classifier: 0.012880\t Precision classifier: 0.010000\t recall classifier: 0.010000\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss classifier: 0.021769\t Precision classifier: 0.009846\t recall classifier: 0.009809\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss classifier: 0.011398\t Precision classifier: 0.010000\t recall classifier: 0.010000\t\n",
      "Classifier Loss: 1.2416541160345078 | Classifier Accuracy: 0.8085200190544128\n",
      "epoch 33\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss classifier: 0.041435\t Precision classifier: 0.009889\t recall classifier: 0.009929\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss classifier: 0.012985\t Precision classifier: 0.009889\t recall classifier: 0.009900\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss classifier: 0.012559\t Precision classifier: 0.009875\t recall classifier: 0.009923\t\n",
      "Classifier Loss: 1.2386735756397247 | Classifier Accuracy: 0.8089600205421448\n",
      "epoch 34\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss classifier: 0.033448\t Precision classifier: 0.009889\t recall classifier: 0.009929\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss classifier: 0.046079\t Precision classifier: 0.009900\t recall classifier: 0.009917\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss classifier: 0.031887\t Precision classifier: 0.009929\t recall classifier: 0.009917\t\n",
      "Classifier Loss: 1.2387999899387359 | Classifier Accuracy: 0.8089200258255005\n",
      "epoch 35\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss classifier: 0.053382\t Precision classifier: 0.009756\t recall classifier: 0.009817\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss classifier: 0.018464\t Precision classifier: 0.009889\t recall classifier: 0.009929\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss classifier: 0.028101\t Precision classifier: 0.009909\t recall classifier: 0.009917\t\n",
      "Classifier Loss: 1.2317082344293595 | Classifier Accuracy: 0.8086000084877014\n",
      "epoch 36\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss classifier: 0.025128\t Precision classifier: 0.009857\t recall classifier: 0.009923\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss classifier: 0.004343\t Precision classifier: 0.010000\t recall classifier: 0.010000\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss classifier: 0.026360\t Precision classifier: 0.009917\t recall classifier: 0.009923\t\n",
      "Classifier Loss: 1.2358775987625121 | Classifier Accuracy: 0.8087999820709229\n",
      "epoch 37\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss classifier: 0.017375\t Precision classifier: 0.009900\t recall classifier: 0.009909\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss classifier: 0.076022\t Precision classifier: 0.009764\t recall classifier: 0.009784\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss classifier: 0.055448\t Precision classifier: 0.009929\t recall classifier: 0.009900\t\n",
      "Classifier Loss: 1.230699929714203 | Classifier Accuracy: 0.8087199926376343\n",
      "epoch 38\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss classifier: 0.005358\t Precision classifier: 0.010000\t recall classifier: 0.010000\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss classifier: 0.179402\t Precision classifier: 0.009729\t recall classifier: 0.009756\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss classifier: 0.028443\t Precision classifier: 0.009857\t recall classifier: 0.009938\t\n",
      "Classifier Loss: 1.2429319875240326 | Classifier Accuracy: 0.8087999820709229\n",
      "epoch 39\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss classifier: 0.002775\t Precision classifier: 0.010000\t recall classifier: 0.010000\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss classifier: 0.049508\t Precision classifier: 0.009923\t recall classifier: 0.009875\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss classifier: 0.038716\t Precision classifier: 0.009875\t recall classifier: 0.009944\t\n",
      "Classifier Loss: 1.231682993412018 | Classifier Accuracy: 0.8087199926376343\n",
      "epoch 40\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss classifier: 0.004735\t Precision classifier: 0.010000\t recall classifier: 0.010000\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss classifier: 0.107391\t Precision classifier: 0.009757\t recall classifier: 0.009854\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss classifier: 0.004059\t Precision classifier: 0.010000\t recall classifier: 0.010000\t\n",
      "Classifier Loss: 1.2432240941524506 | Classifier Accuracy: 0.8087999820709229\n",
      "epoch 41\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss classifier: 0.089638\t Precision classifier: 0.009693\t recall classifier: 0.009718\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss classifier: 0.097786\t Precision classifier: 0.009590\t recall classifier: 0.009673\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss classifier: 0.036886\t Precision classifier: 0.009917\t recall classifier: 0.009667\t\n",
      "Classifier Loss: 1.2339591274261474 | Classifier Accuracy: 0.80867999792099\n",
      "epoch 42\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss classifier: 0.068512\t Precision classifier: 0.009952\t recall classifier: 0.009889\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss classifier: 0.002761\t Precision classifier: 0.010000\t recall classifier: 0.010000\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss classifier: 0.041943\t Precision classifier: 0.009833\t recall classifier: 0.009909\t\n",
      "Classifier Loss: 1.2404453954696655 | Classifier Accuracy: 0.8087999820709229\n",
      "epoch 43\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss classifier: 0.047261\t Precision classifier: 0.009792\t recall classifier: 0.009826\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss classifier: 0.002486\t Precision classifier: 0.010000\t recall classifier: 0.010000\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss classifier: 0.016812\t Precision classifier: 0.010000\t recall classifier: 0.010000\t\n",
      "Classifier Loss: 1.235992208957672 | Classifier Accuracy: 0.8089600205421448\n",
      "epoch 44\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss classifier: 0.044021\t Precision classifier: 0.009817\t recall classifier: 0.009700\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss classifier: 0.017959\t Precision classifier: 0.009900\t recall classifier: 0.009917\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss classifier: 0.057497\t Precision classifier: 0.009784\t recall classifier: 0.009838\t\n",
      "Classifier Loss: 1.233687792301178 | Classifier Accuracy: 0.8087599873542786\n",
      "epoch 45\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss classifier: 0.002696\t Precision classifier: 0.010000\t recall classifier: 0.010000\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss classifier: 0.060084\t Precision classifier: 0.009875\t recall classifier: 0.009929\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss classifier: 0.074812\t Precision classifier: 0.009923\t recall classifier: 0.009909\t\n",
      "Classifier Loss: 1.2341418023109436 | Classifier Accuracy: 0.8087599873542786\n",
      "epoch 46\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss classifier: 0.001268\t Precision classifier: 0.010000\t recall classifier: 0.010000\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss classifier: 0.064044\t Precision classifier: 0.009833\t recall classifier: 0.009857\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss classifier: 0.014863\t Precision classifier: 0.010000\t recall classifier: 0.010000\t\n",
      "Classifier Loss: 1.2360245289802552 | Classifier Accuracy: 0.8087999820709229\n",
      "epoch 47\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss classifier: 0.029062\t Precision classifier: 0.009875\t recall classifier: 0.009917\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss classifier: 0.019091\t Precision classifier: 0.009933\t recall classifier: 0.009889\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss classifier: 0.025160\t Precision classifier: 0.009929\t recall classifier: 0.009889\t\n",
      "Classifier Loss: 1.233989354133606 | Classifier Accuracy: 0.8086000084877014\n",
      "epoch 48\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss classifier: 0.021761\t Precision classifier: 0.010000\t recall classifier: 0.010000\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss classifier: 0.003794\t Precision classifier: 0.010000\t recall classifier: 0.010000\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss classifier: 0.030164\t Precision classifier: 0.009917\t recall classifier: 0.009923\t\n",
      "Classifier Loss: 1.2342378840446473 | Classifier Accuracy: 0.8089200258255005\n",
      "epoch 49\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss classifier: 0.059933\t Precision classifier: 0.009917\t recall classifier: 0.009900\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss classifier: 0.001291\t Precision classifier: 0.010000\t recall classifier: 0.010000\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss classifier: 0.053904\t Precision classifier: 0.009800\t recall classifier: 0.009889\t\n",
      "Classifier Loss: 1.2368866963386536 | Classifier Accuracy: 0.8088799715042114\n",
      "epoch 50\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss classifier: 0.011146\t Precision classifier: 0.010000\t recall classifier: 0.010000\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss classifier: 0.027648\t Precision classifier: 0.009875\t recall classifier: 0.009889\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss classifier: 0.047975\t Precision classifier: 0.009818\t recall classifier: 0.009792\t\n",
      "Classifier Loss: 1.2365949590206147 | Classifier Accuracy: 0.8089200258255005\n",
      "epoch 51\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss classifier: 0.005780\t Precision classifier: 0.010000\t recall classifier: 0.010000\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss classifier: 0.017539\t Precision classifier: 0.010000\t recall classifier: 0.010000\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss classifier: 0.032591\t Precision classifier: 0.009909\t recall classifier: 0.009929\t\n",
      "Classifier Loss: 1.2334227427244187 | Classifier Accuracy: 0.8091599941253662\n",
      "epoch 52\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss classifier: 0.019665\t Precision classifier: 0.010000\t recall classifier: 0.010000\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss classifier: 0.109633\t Precision classifier: 0.009690\t recall classifier: 0.009856\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss classifier: 0.006635\t Precision classifier: 0.010000\t recall classifier: 0.010000\t\n",
      "Classifier Loss: 1.23221812748909 | Classifier Accuracy: 0.8085600137710571\n",
      "epoch 53\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss classifier: 0.018055\t Precision classifier: 0.010000\t recall classifier: 0.010000\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss classifier: 0.026109\t Precision classifier: 0.009784\t recall classifier: 0.009817\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss classifier: 0.070344\t Precision classifier: 0.009535\t recall classifier: 0.009546\t\n",
      "Classifier Loss: 1.231526566028595 | Classifier Accuracy: 0.8087999820709229\n",
      "epoch 54\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss classifier: 0.135164\t Precision classifier: 0.009709\t recall classifier: 0.009700\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss classifier: 0.001796\t Precision classifier: 0.010000\t recall classifier: 0.010000\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss classifier: 0.052996\t Precision classifier: 0.009847\t recall classifier: 0.009750\t\n",
      "Classifier Loss: 1.2304692298173905 | Classifier Accuracy: 0.8087199926376343\n",
      "epoch 55\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss classifier: 0.037609\t Precision classifier: 0.009900\t recall classifier: 0.009900\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss classifier: 0.005249\t Precision classifier: 0.010000\t recall classifier: 0.010000\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss classifier: 0.001603\t Precision classifier: 0.010000\t recall classifier: 0.010000\t\n",
      "Classifier Loss: 1.2301252596378327 | Classifier Accuracy: 0.80867999792099\n",
      "epoch 56\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss classifier: 0.053230\t Precision classifier: 0.009923\t recall classifier: 0.009857\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss classifier: 0.012430\t Precision classifier: 0.010000\t recall classifier: 0.010000\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss classifier: 0.014822\t Precision classifier: 0.010000\t recall classifier: 0.010000\t\n",
      "Classifier Loss: 1.2330699605941773 | Classifier Accuracy: 0.8091199994087219\n",
      "epoch 57\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss classifier: 0.003632\t Precision classifier: 0.010000\t recall classifier: 0.010000\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss classifier: 0.010668\t Precision classifier: 0.010000\t recall classifier: 0.010000\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss classifier: 0.117689\t Precision classifier: 0.009735\t recall classifier: 0.009770\t\n",
      "Classifier Loss: 1.2304867440462113 | Classifier Accuracy: 0.8087599873542786\n",
      "epoch 58\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss classifier: 0.077439\t Precision classifier: 0.009761\t recall classifier: 0.009661\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss classifier: 0.015022\t Precision classifier: 0.010000\t recall classifier: 0.010000\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss classifier: 0.004093\t Precision classifier: 0.010000\t recall classifier: 0.010000\t\n",
      "Classifier Loss: 1.234256441116333 | Classifier Accuracy: 0.8090000152587891\n",
      "epoch 59\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss classifier: 0.149246\t Precision classifier: 0.009784\t recall classifier: 0.009766\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss classifier: 0.021673\t Precision classifier: 0.009933\t recall classifier: 0.009889\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss classifier: 0.023604\t Precision classifier: 0.009917\t recall classifier: 0.009923\t\n",
      "Classifier Loss: 1.2342457338571549 | Classifier Accuracy: 0.8087199926376343\n",
      "epoch 60\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss classifier: 0.027171\t Precision classifier: 0.009909\t recall classifier: 0.009933\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss classifier: 0.134033\t Precision classifier: 0.009616\t recall classifier: 0.009604\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss classifier: 0.029271\t Precision classifier: 0.009800\t recall classifier: 0.009909\t\n",
      "Classifier Loss: 1.2299574882984161 | Classifier Accuracy: 0.80867999792099\n",
      "epoch 61\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss classifier: 0.007446\t Precision classifier: 0.010000\t recall classifier: 0.010000\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss classifier: 0.069182\t Precision classifier: 0.009580\t recall classifier: 0.009746\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss classifier: 0.122130\t Precision classifier: 0.009792\t recall classifier: 0.009840\t\n",
      "Classifier Loss: 1.2307865779399871 | Classifier Accuracy: 0.8089200258255005\n",
      "epoch 62\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss classifier: 0.024251\t Precision classifier: 0.009875\t recall classifier: 0.009909\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss classifier: 0.039327\t Precision classifier: 0.009875\t recall classifier: 0.009923\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss classifier: 0.086856\t Precision classifier: 0.009690\t recall classifier: 0.009817\t\n",
      "Classifier Loss: 1.2356936359405517 | Classifier Accuracy: 0.8089200258255005\n",
      "epoch 63\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss classifier: 0.050551\t Precision classifier: 0.009857\t recall classifier: 0.009833\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss classifier: 0.030503\t Precision classifier: 0.009889\t recall classifier: 0.009929\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss classifier: 0.012224\t Precision classifier: 0.010000\t recall classifier: 0.010000\t\n",
      "Classifier Loss: 1.2277796211242675 | Classifier Accuracy: 0.8087199926376343\n",
      "epoch 64\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss classifier: 0.005491\t Precision classifier: 0.010000\t recall classifier: 0.010000\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss classifier: 0.008150\t Precision classifier: 0.010000\t recall classifier: 0.010000\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss classifier: 0.086606\t Precision classifier: 0.009929\t recall classifier: 0.009800\t\n",
      "Classifier Loss: 1.2268235692977905 | Classifier Accuracy: 0.8087599873542786\n",
      "epoch 65\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss classifier: 0.003895\t Precision classifier: 0.010000\t recall classifier: 0.010000\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss classifier: 0.011641\t Precision classifier: 0.009750\t recall classifier: 0.009917\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss classifier: 0.011639\t Precision classifier: 0.010000\t recall classifier: 0.010000\t\n",
      "Classifier Loss: 1.2284479897022247 | Classifier Accuracy: 0.8085200190544128\n",
      "epoch 66\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss classifier: 0.022845\t Precision classifier: 0.009917\t recall classifier: 0.009900\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss classifier: 0.029370\t Precision classifier: 0.009875\t recall classifier: 0.009900\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss classifier: 0.046143\t Precision classifier: 0.009909\t recall classifier: 0.009933\t\n",
      "Classifier Loss: 1.2373492487668991 | Classifier Accuracy: 0.8090000152587891\n",
      "epoch 67\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss classifier: 0.055791\t Precision classifier: 0.009746\t recall classifier: 0.009880\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss classifier: 0.055451\t Precision classifier: 0.009923\t recall classifier: 0.009900\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss classifier: 0.029781\t Precision classifier: 0.009944\t recall classifier: 0.009944\t\n",
      "Classifier Loss: 1.2247048727273941 | Classifier Accuracy: 0.80867999792099\n",
      "epoch 68\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss classifier: 0.061719\t Precision classifier: 0.009736\t recall classifier: 0.009517\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss classifier: 0.039721\t Precision classifier: 0.009889\t recall classifier: 0.009900\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss classifier: 0.055854\t Precision classifier: 0.009812\t recall classifier: 0.009795\t\n",
      "Classifier Loss: 1.2272731945514679 | Classifier Accuracy: 0.8083999752998352\n",
      "epoch 69\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss classifier: 0.033734\t Precision classifier: 0.009889\t recall classifier: 0.009875\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss classifier: 0.098400\t Precision classifier: 0.009900\t recall classifier: 0.009889\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss classifier: 0.025321\t Precision classifier: 0.009909\t recall classifier: 0.009929\t\n",
      "Classifier Loss: 1.2273038601875306 | Classifier Accuracy: 0.80867999792099\n",
      "epoch 70\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss classifier: 0.035384\t Precision classifier: 0.009944\t recall classifier: 0.009909\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss classifier: 0.055943\t Precision classifier: 0.009798\t recall classifier: 0.009798\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss classifier: 0.003662\t Precision classifier: 0.010000\t recall classifier: 0.010000\t\n",
      "Classifier Loss: 1.232253553390503 | Classifier Accuracy: 0.8090400099754333\n",
      "epoch 71\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss classifier: 0.045090\t Precision classifier: 0.009667\t recall classifier: 0.009687\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss classifier: 0.055753\t Precision classifier: 0.009689\t recall classifier: 0.009808\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss classifier: 0.028453\t Precision classifier: 0.009900\t recall classifier: 0.009917\t\n",
      "Classifier Loss: 1.2325906467437744 | Classifier Accuracy: 0.8088799715042114\n",
      "epoch 72\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss classifier: 0.004000\t Precision classifier: 0.010000\t recall classifier: 0.010000\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss classifier: 0.062702\t Precision classifier: 0.009808\t recall classifier: 0.009764\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss classifier: 0.042197\t Precision classifier: 0.009923\t recall classifier: 0.009889\t\n",
      "Classifier Loss: 1.229243135213852 | Classifier Accuracy: 0.8088799715042114\n",
      "epoch 73\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss classifier: 0.082566\t Precision classifier: 0.009798\t recall classifier: 0.009823\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss classifier: 0.036384\t Precision classifier: 0.009875\t recall classifier: 0.009923\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss classifier: 0.087206\t Precision classifier: 0.009909\t recall classifier: 0.009933\t\n",
      "Classifier Loss: 1.230068605184555 | Classifier Accuracy: 0.8088399767875671\n",
      "epoch 74\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss classifier: 0.027548\t Precision classifier: 0.009857\t recall classifier: 0.009889\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss classifier: 0.034353\t Precision classifier: 0.009900\t recall classifier: 0.009929\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss classifier: 0.048112\t Precision classifier: 0.009833\t recall classifier: 0.009923\t\n",
      "Classifier Loss: 1.2328989942073822 | Classifier Accuracy: 0.8088799715042114\n",
      "epoch 75\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss classifier: 0.002540\t Precision classifier: 0.010000\t recall classifier: 0.010000\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss classifier: 0.002488\t Precision classifier: 0.010000\t recall classifier: 0.010000\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss classifier: 0.015023\t Precision classifier: 0.010000\t recall classifier: 0.010000\t\n",
      "Classifier Loss: 1.2285248249769212 | Classifier Accuracy: 0.8086400032043457\n",
      "epoch 76\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss classifier: 0.028957\t Precision classifier: 0.009889\t recall classifier: 0.009889\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss classifier: 0.058213\t Precision classifier: 0.009789\t recall classifier: 0.009775\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss classifier: 0.027844\t Precision classifier: 0.009941\t recall classifier: 0.009909\t\n",
      "Classifier Loss: 1.2255652669668198 | Classifier Accuracy: 0.8082799911499023\n",
      "epoch 77\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss classifier: 0.019570\t Precision classifier: 0.009900\t recall classifier: 0.009917\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss classifier: 0.008018\t Precision classifier: 0.010000\t recall classifier: 0.010000\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss classifier: 0.028209\t Precision classifier: 0.009784\t recall classifier: 0.009789\t\n",
      "Classifier Loss: 1.2352385852336885 | Classifier Accuracy: 0.8088399767875671\n",
      "epoch 78\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss classifier: 0.042835\t Precision classifier: 0.009909\t recall classifier: 0.009875\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss classifier: 0.058145\t Precision classifier: 0.009909\t recall classifier: 0.009875\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss classifier: 0.063179\t Precision classifier: 0.009830\t recall classifier: 0.009822\t\n",
      "Classifier Loss: 1.2315118370056153 | Classifier Accuracy: 0.8086000084877014\n",
      "epoch 79\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss classifier: 0.010066\t Precision classifier: 0.010000\t recall classifier: 0.010000\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss classifier: 0.013552\t Precision classifier: 0.010000\t recall classifier: 0.010000\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss classifier: 0.003514\t Precision classifier: 0.010000\t recall classifier: 0.010000\t\n",
      "Classifier Loss: 1.2339917855262756 | Classifier Accuracy: 0.8090000152587891\n",
      "epoch 80\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss classifier: 0.062472\t Precision classifier: 0.009757\t recall classifier: 0.009766\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss classifier: 0.029597\t Precision classifier: 0.009857\t recall classifier: 0.009909\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss classifier: 0.004745\t Precision classifier: 0.010000\t recall classifier: 0.010000\t\n",
      "Classifier Loss: 1.2292624864578248 | Classifier Accuracy: 0.8085200190544128\n",
      "epoch 81\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss classifier: 0.007240\t Precision classifier: 0.010000\t recall classifier: 0.010000\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss classifier: 0.047904\t Precision classifier: 0.009733\t recall classifier: 0.009800\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss classifier: 0.039528\t Precision classifier: 0.009857\t recall classifier: 0.009900\t\n",
      "Classifier Loss: 1.230021978378296 | Classifier Accuracy: 0.80867999792099\n",
      "epoch 82\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss classifier: 0.021943\t Precision classifier: 0.009941\t recall classifier: 0.009875\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss classifier: 0.001844\t Precision classifier: 0.010000\t recall classifier: 0.010000\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss classifier: 0.020768\t Precision classifier: 0.009929\t recall classifier: 0.009917\t\n",
      "Classifier Loss: 1.230406017422676 | Classifier Accuracy: 0.8087999820709229\n",
      "epoch 83\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss classifier: 0.013729\t Precision classifier: 0.010000\t recall classifier: 0.010000\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss classifier: 0.039805\t Precision classifier: 0.009778\t recall classifier: 0.009795\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss classifier: 0.034640\t Precision classifier: 0.009775\t recall classifier: 0.009775\t\n",
      "Classifier Loss: 1.2307014710903168 | Classifier Accuracy: 0.8085600137710571\n",
      "epoch 84\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss classifier: 0.028688\t Precision classifier: 0.009875\t recall classifier: 0.009909\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss classifier: 0.012200\t Precision classifier: 0.010000\t recall classifier: 0.010000\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss classifier: 0.005917\t Precision classifier: 0.010000\t recall classifier: 0.010000\t\n",
      "Classifier Loss: 1.229772523999214 | Classifier Accuracy: 0.80867999792099\n",
      "epoch 85\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss classifier: 0.074775\t Precision classifier: 0.009929\t recall classifier: 0.009909\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss classifier: 0.001876\t Precision classifier: 0.010000\t recall classifier: 0.010000\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss classifier: 0.005827\t Precision classifier: 0.010000\t recall classifier: 0.010000\t\n",
      "Classifier Loss: 1.2261382043361664 | Classifier Accuracy: 0.8087999820709229\n",
      "epoch 86\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss classifier: 0.040443\t Precision classifier: 0.009900\t recall classifier: 0.009875\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss classifier: 0.003965\t Precision classifier: 0.010000\t recall classifier: 0.010000\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss classifier: 0.020751\t Precision classifier: 0.009929\t recall classifier: 0.009917\t\n",
      "Classifier Loss: 1.2289173090457917 | Classifier Accuracy: 0.8087599873542786\n",
      "epoch 87\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss classifier: 0.017479\t Precision classifier: 0.009900\t recall classifier: 0.009900\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss classifier: 0.053025\t Precision classifier: 0.009832\t recall classifier: 0.009806\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss classifier: 0.048729\t Precision classifier: 0.009742\t recall classifier: 0.009812\t\n",
      "Classifier Loss: 1.229154135107994 | Classifier Accuracy: 0.80867999792099\n",
      "epoch 88\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss classifier: 0.010417\t Precision classifier: 0.010000\t recall classifier: 0.010000\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss classifier: 0.028985\t Precision classifier: 0.009833\t recall classifier: 0.009909\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss classifier: 0.019679\t Precision classifier: 0.009941\t recall classifier: 0.009923\t\n",
      "Classifier Loss: 1.2299156683683394 | Classifier Accuracy: 0.8086400032043457\n",
      "epoch 89\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss classifier: 0.047125\t Precision classifier: 0.009947\t recall classifier: 0.009909\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss classifier: 0.030821\t Precision classifier: 0.009840\t recall classifier: 0.009775\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss classifier: 0.012351\t Precision classifier: 0.010000\t recall classifier: 0.010000\t\n",
      "Classifier Loss: 1.2325952483415603 | Classifier Accuracy: 0.8084400296211243\n",
      "epoch 90\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss classifier: 0.017021\t Precision classifier: 0.010000\t recall classifier: 0.010000\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss classifier: 0.009088\t Precision classifier: 0.010000\t recall classifier: 0.010000\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss classifier: 0.064109\t Precision classifier: 0.009752\t recall classifier: 0.009731\t\n",
      "Classifier Loss: 1.2300230768918992 | Classifier Accuracy: 0.80867999792099\n",
      "epoch 91\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss classifier: 0.069886\t Precision classifier: 0.009714\t recall classifier: 0.009741\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss classifier: 0.023159\t Precision classifier: 0.009933\t recall classifier: 0.009929\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss classifier: 0.040755\t Precision classifier: 0.009857\t recall classifier: 0.009909\t\n",
      "Classifier Loss: 1.2301454998254775 | Classifier Accuracy: 0.8085600137710571\n",
      "epoch 92\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss classifier: 0.163629\t Precision classifier: 0.009731\t recall classifier: 0.009742\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss classifier: 0.002942\t Precision classifier: 0.010000\t recall classifier: 0.010000\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss classifier: 0.026186\t Precision classifier: 0.009923\t recall classifier: 0.009941\t\n",
      "Classifier Loss: 1.2311164484024049 | Classifier Accuracy: 0.8083599805831909\n",
      "epoch 93\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss classifier: 0.011168\t Precision classifier: 0.010000\t recall classifier: 0.010000\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss classifier: 0.019779\t Precision classifier: 0.009857\t recall classifier: 0.009909\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss classifier: 0.059942\t Precision classifier: 0.009778\t recall classifier: 0.009806\t\n",
      "Classifier Loss: 1.2319425786733627 | Classifier Accuracy: 0.8091199994087219\n",
      "epoch 94\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss classifier: 0.031207\t Precision classifier: 0.009889\t recall classifier: 0.009857\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss classifier: 0.085614\t Precision classifier: 0.009657\t recall classifier: 0.009706\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss classifier: 0.004009\t Precision classifier: 0.010000\t recall classifier: 0.010000\t\n",
      "Classifier Loss: 1.232742963075638 | Classifier Accuracy: 0.8086400032043457\n",
      "epoch 95\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss classifier: 0.095725\t Precision classifier: 0.009750\t recall classifier: 0.009727\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss classifier: 0.003302\t Precision classifier: 0.010000\t recall classifier: 0.010000\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss classifier: 0.023926\t Precision classifier: 0.009929\t recall classifier: 0.009900\t\n",
      "Classifier Loss: 1.2230286049842833 | Classifier Accuracy: 0.80867999792099\n",
      "epoch 96\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss classifier: 0.022405\t Precision classifier: 0.010000\t recall classifier: 0.010000\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss classifier: 0.043722\t Precision classifier: 0.009909\t recall classifier: 0.009929\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss classifier: 0.005651\t Precision classifier: 0.010000\t recall classifier: 0.010000\t\n",
      "Classifier Loss: 1.2262924036979674 | Classifier Accuracy: 0.8085200190544128\n",
      "epoch 97\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss classifier: 0.049093\t Precision classifier: 0.009875\t recall classifier: 0.009947\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss classifier: 0.037172\t Precision classifier: 0.009900\t recall classifier: 0.009917\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss classifier: 0.034134\t Precision classifier: 0.009929\t recall classifier: 0.009875\t\n",
      "Classifier Loss: 1.227302881360054 | Classifier Accuracy: 0.8087199926376343\n",
      "epoch 98\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss classifier: 0.003186\t Precision classifier: 0.010000\t recall classifier: 0.010000\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss classifier: 0.015835\t Precision classifier: 0.009889\t recall classifier: 0.009833\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss classifier: 0.020924\t Precision classifier: 0.009875\t recall classifier: 0.009933\t\n",
      "Classifier Loss: 1.2294057161808014 | Classifier Accuracy: 0.8083199858665466\n",
      "epoch 99\n",
      "Epoch: 0 [0/50000 (0%)]\tLoss classifier: 0.031321\t Precision classifier: 0.009857\t recall classifier: 0.009889\t\n",
      "Epoch: 100 [10000/50000 (40%)]\tLoss classifier: 0.066477\t Precision classifier: 0.009775\t recall classifier: 0.009838\t\n",
      "Epoch: 200 [20000/50000 (80%)]\tLoss classifier: 0.005447\t Precision classifier: 0.010000\t recall classifier: 0.010000\t\n",
      "Classifier Loss: 1.22883247256279 | Classifier Accuracy: 0.8084400296211243\n"
     ]
    }
   ],
   "source": [
    "cf= get_clf_defense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py36",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0535f4291a054084da48c46367c126edeb89562b3cd08e9220bc1032d175bf03"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
